{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 100 market cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "url = \"https://api.coingecko.com/api/v3/coins/markets?vs_currency=usd\"\n",
    "response = requests.get(url)\n",
    "\n",
    "data = json.loads(response.content)\n",
    "top100 = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top100.to_csv('top_100_cmc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top100 = pd.read_csv('top_100_cmc.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ccxt binance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ccxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = ccxt.binance()\n",
    "ex.options['maxRetriesOnFailureDelay'] = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from_ts = ex.parse8601('2010-01-01 00:00:00')\n",
    "# ohlcv = ex.fetch_ohlcv('BTC/USDT', '1d', since=from_ts, limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ccxt\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Define the time range\n",
    "end_date = datetime.now().isoformat()\n",
    "end_ts = ex.parse8601(end_date)\n",
    "\n",
    "# Function to fetch OHLCV data in batches\n",
    "def fetch_ohlcv_in_batches(exchange, symbol, timeframe, since, limit):\n",
    "    all_ohlcv = []\n",
    "    while since < end_ts:\n",
    "        ohlcv = exchange.fetch_ohlcv(symbol, timeframe, since=since, limit=limit)\n",
    "        if not ohlcv:\n",
    "            break\n",
    "        all_ohlcv.extend(ohlcv)\n",
    "        since = ohlcv[-1][0] + 1  # Increment since to the last timestamp + 1\n",
    "\n",
    "        \n",
    "    return all_ohlcv\n",
    "\n",
    "def ohlcv_to_df(ohlcv):\n",
    "    df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "    df.set_index('timestamp', inplace=True)\n",
    "    return df\n",
    "\n",
    "# Fetch data\n",
    "# ohlcv = ohlcv_to_df(fetch_ohlcv_in_batches(ex, 'BTC/USDT', '1d', start_ts, 1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2017-08-17 00:00:00'\n",
    "start_ts = ex.parse8601(start_date)\n",
    "ohlcvs = {}\n",
    "\n",
    "for sym in list(top100['symbol']):\n",
    "        print(f'fetching {sym}')\n",
    "        try:\n",
    "            ohlcv_df = ohlcv_to_df(fetch_ohlcv_in_batches(ex, f'{sym.upper()}/USDT', '1d', start_ts, 1000)) \n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {sym} - {e}\")\n",
    "\n",
    "        ohlcvs[sym] = ohlcv_df\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlcvs['aave'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save & Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_dict_to_pickle(data_dict, filename):\n",
    "    \"\"\"\n",
    "    Save a dictionary with DataFrame values to a pickle file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_dict : dict\n",
    "        Dictionary with string keys and DataFrame values.\n",
    "    filename : str\n",
    "        The path to the file where the data will be saved.\n",
    "    \"\"\"\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(data_dict, f)\n",
    "\n",
    "save_dict_to_pickle(ohlcvs, 'input.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def load_dict_from_pickle(filename):\n",
    "    \"\"\"\n",
    "    Load a dictionary with DataFrame values from a pickle file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "        The path to the file from which the data will be loaded.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    data_dict : dict\n",
    "        Dictionary with string keys and DataFrame values.\n",
    "    \"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        data_dict = pickle.load(f)\n",
    "    return data_dict\n",
    "\n",
    "# Example usage\n",
    "ohlcvs = load_dict_from_pickle('input.pkl')\n",
    "# print(ohlcvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove irrelevant token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in list(ohlcvs.keys()):\n",
    "    if k in ['steth',\n",
    "            'weeth',\n",
    "            'ezeth',\n",
    "            'reth',\n",
    "            'meth',\n",
    "            'eeth',\n",
    "            'rseth']:\n",
    "        del ohlcvs[k]\n",
    "\n",
    "    if 'usd' in k:\n",
    "        del ohlcvs[k]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using MPF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mplfinance as mpf\n",
    "mpf.plot(ohlcvs['eth'], type='line', volume=True, style='yahoo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=[go.Candlestick(x=ohlcvs['eth'].index,\n",
    "                open=ohlcvs['eth'].open, high=ohlcvs['eth'].high,\n",
    "                low=ohlcvs['eth'].low, close=ohlcvs['eth'].close)])\n",
    "\n",
    "fig.update_layout(title='OHLCV Data',\n",
    "                   xaxis_title='Date',\n",
    "                   yaxis_title='Price',\n",
    "                   xaxis_rangeslider_visible=False)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resample Adjusted Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close = pd.DataFrame()\n",
    "\n",
    "# Loop through the dictionary and combine the data into the new DataFrame\n",
    "for ticker, df in ohlcvs.items():\n",
    "    close[ticker] = df['close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_prices(close_prices:pd.DataFrame, freq='M'):\n",
    "    \"\"\"\n",
    "    Resample close prices for each ticker at specified frequency.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    close_prices : DataFrame\n",
    "        Close prices for each ticker and date\n",
    "    freq : str\n",
    "        What frequency to sample at\n",
    "        For valid freq choices, see http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    prices_resampled : DataFrame\n",
    "        Resampled prices for each ticker and date\n",
    "    \"\"\"\n",
    "    \n",
    "    return close_prices.resample(freq).last()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_close = resample_prices(close)\n",
    "monthly_close.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Log Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_returns(prices):\n",
    "    \"\"\"\n",
    "    Compute log returns for each ticker.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    prices : DataFrame\n",
    "        Prices for each ticker and date\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    log_returns : DataFrame\n",
    "        Log returns for each ticker and date\n",
    "    \"\"\"\n",
    "    previous_prices = prices.shift(periods = 1)\n",
    "    \n",
    "    return np.log(prices / previous_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_close_returns = compute_log_returns(monthly_close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_close_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shift Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_returns(returns, shift_n):\n",
    "    \"\"\"\n",
    "    Generate shifted returns\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    returns : DataFrame\n",
    "        Returns for each ticker and date\n",
    "    shift_n : int\n",
    "        Number of periods to move, can be positive or negative\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    shifted_returns : DataFrame\n",
    "        Shifted returns for each ticker and date\n",
    "    \"\"\"\n",
    "    \n",
    "    return returns.shift(periods = shift_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_returns = shift_returns(monthly_close_returns, 1)\n",
    "lookahead_returns = shift_returns(monthly_close_returns, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(prev_returns, top_n):\n",
    "    \"\"\"\n",
    "    Select the top performing crypto\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    prev_returns : DataFrame\n",
    "        Previous shifted returns for each ticker and date\n",
    "    top_n : int\n",
    "        The number of top performing crypto to get\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    top_crypto : DataFrame\n",
    "        Top crypto for each ticker and date marked with a 1\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    top_crypto = pd.DataFrame(index = prev_returns.index, columns = prev_returns.columns)\n",
    "    for index, row in prev_returns.iterrows():\n",
    "        top_crypto.loc[index] = row.isin(row.nlargest(top_n)).astype(np.int64)\n",
    "        \n",
    "    return top_crypto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_bottom_n = 20\n",
    "df_long = get_top_n(prev_returns, top_bottom_n)\n",
    "df_short = get_top_n(-1*prev_returns, top_bottom_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top(df, name, top_n=10):\n",
    "    print('{} Most {}:'.format(top_n, name))\n",
    "    print(', '.join(df.sum().sort_values(ascending=False).index[:top_n].values.tolist()))\n",
    "\n",
    "print_top(df_long, 'Longed crypto')\n",
    "print_top(df_short, 'Shorted crypto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_returns(df_long, df_short, lookahead_returns, n_crypto) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute expected returns for the portfolio, assuming equal investment in each long/short stock.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_long : DataFrame\n",
    "        Top crypto for each ticker and date marked with a 1\n",
    "    df_short : DataFrame\n",
    "        Bottom crypto for each ticker and date marked with a 1\n",
    "    lookahead_returns : DataFrame\n",
    "        Lookahead returns for each ticker and date\n",
    "    n_crypto: int\n",
    "        The number of crypto chosen for each month\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    portfolio_returns : DataFrame\n",
    "        Expected portfolio returns for each ticker and date\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    return (df_long - df_short) * lookahead_returns / n_crypto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_portfolio_returns = portfolio_returns(df_long, df_short, lookahead_returns, 2*top_bottom_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_portfolio_returns_by_date = expected_portfolio_returns.T.sum().dropna()\n",
    "portfolio_ret_mean = expected_portfolio_returns_by_date.mean()\n",
    "portfolio_ret_ste = expected_portfolio_returns_by_date.sem()\n",
    "portfolio_ret_annual_rate = (np.exp(portfolio_ret_mean * 12) - 1) * 100\n",
    "\n",
    "print(\"\"\"\n",
    "Mean:                       {:.6f}\n",
    "Standard Error:             {:.6f}\n",
    "Annualized Rate of Return:  {:.2f}%\n",
    "\"\"\".format(portfolio_ret_mean, portfolio_ret_ste, portfolio_ret_annual_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def analyze_alpha(expected_portfolio_returns_by_date):\n",
    "    \"\"\"\n",
    "    Perform a t-test with the null hypothesis being that the expected mean return is zero.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    expected_portfolio_returns_by_date : Pandas Series\n",
    "        Expected portfolio returns for each date\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    t_value\n",
    "        T-statistic from t-test\n",
    "    p_value\n",
    "        Corresponding p-value\n",
    "    \"\"\"\n",
    "    t_stastic, p_value = stats.ttest_1samp(expected_portfolio_returns_by_date, 0)\n",
    "    return t_stastic, p_value / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_value, p_value = analyze_alpha(pd.to_numeric(expected_portfolio_returns_by_date.values, errors='coerce'))\n",
    "print(\"\"\"\n",
    "Alpha analysis:\n",
    " t-value:        {:.3f}\n",
    " p-value:        {:.6f}\n",
    "\"\"\".format(t_value, p_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rugi dong :v"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
