## 001.Mean Variance Overview and in Excel

### 001. Overview of Mean Variance

This module is the first of three modules, where we'll be walking through the maintheoretical ideas behind mean variance portfolio selection.We'll first define what a portfolio is. We'll talk about what the return and riskof a portfolio is going to be. We're going to define what an efficientfrontier is. We're going to define how an efficientfrontier changes when there is a risk-free asset and how all of that leads up to thecapital asset pricing market. The overview of what we're going to betalking about here is that we're going to define assets.We're going to define portfolios. We're going to define how to measurerandom returns in assets and portfolios. And for the mean-variance optimization asthe name suggests, we're going to quantify the random asset and portfolio returns bytheir mean and variance. We're going to define something calledmean-variance optimal portfolios or mean-variance efficient portfolios.We're going to define something called the efficient frontier, and the portfoliosthat lie on this efficient frontier and how does one compute them.Along the way We're also going to talk about Sharpe ratio and Sharpe optimalportfolios. We're going to define something called amarket portfolio, and after defining the market portfolio, we'll get to somethingcalled the Capital Asset Pricing Model. These are the various modules that we'regoing to be walking through in this bigger topic of mean variance optimization.So what's the goal here? What I really want to do is I've got acertain amount of money and I want to split it among various assets that areavailable for investment. I'm going to caracterize and asset by itsprice. More often than not I'll be interested inreturns on these assets I'm going to invest in them today, I'm going to sellthem tomorrow and Whatever difference is the return that I make on it.And I would like to maximize this return in some appropriate sense.I'm going to define the random gross return on a particular asset to be simplythe price one time step later. The time step could be a quarter, could bea year, could be six months. So it's p t plus 1 divided by p t.The net return is simply r t minus 1. It's going to be p t plus 1 minus p tdivided by p t. I want to point out that both r t, andlittle r t are random quantities. These are random because the price at timet plus 1 is random. Price at time t, which is right now, isknow, but the price at time t plus 1 is random, and therefore these returns aregoing to be random. I've got d different assets, and I want tosplit an amount, capital W, that I'm going to assume is strictly positive.This is the capital that I have, and I want to split it over the d assets that Ihave. W sub i will be the total dollar amountthat I've invested in asset i. If w i is greater than 0, I'm going to saythat that's a long investment. If w i is less than 0, it's going to be ashort investment. For the purposes of modeling, we allow wto be both positive or negative. Our sub w will be The net rate of returnor net return on the position w. By position I mean, the wealth and thevarious assets. So what is the definition?It's simply the total value of this 1 times detonator.Which is the gross returns of each of the assets times the amount of money which wasput into those assets. Minus the initial values, which is sum ofthe w's divided by the initial value which is capital w.If you do the math, this 1 could be subtracted from ri.And you end up getting, this is going to be the net return.Little rit, wi, divided by the sum of the wi's.Rearrange them a little bit, and you end up getting that the net return on positionw is the net return on each of the assets rit, which is a random quantity times widivided by capital W. So what is important for the net return isnot the absolute amount of wealth that is invested, but the relative amount, or thefraction of the total wealth that is invested in a particular asset.So instead of worrying about positions, we just have to consider a portfolio vector.So x is a portfolio vector. It could be positive or negative.Xi's represent the fraction invested in a particular asset.So some of the xi's must be equal to 1. One thing that I want to point out here isI, I've been talking about time t. In reality the return that you get,whether it's a gross return or the net return changes over time.The random properties change over time. The actual values that are realized changeover time. But in this set of modules we are going tobe looking at a very myopic investment strategy.I'm sitting at a particular time t. I only want to invest at time T plus one.When we get into more advance topics, we're going to talk about how to extendthis idea into a multi-period optimization.People are interested in multi-period optimization because at the end of the daythey want to save money for retirement, they want to save money for buying a houseand so one, which is not a one period problem but a multi-period problem.A multi-period problem is not simply a concatination of one period problemsbecause the space over which you can optimize becomes much larger when you lookat multi-period problem. But in this set of modules we're going tobe concerned only with one period of optimization, one quarter, one era, and soon. So how does one deal with randomness?The return on the portfolio R's of X is going to be defined as R I, X I.And notice over here I've dropped the R I, the time in the R I, because I'm focusingmainly on myopic optimization. This is a random return.Why is it random? Because the each of the returns, each ofthe net returns, R I's are going to be random.How does one quantify these returns? Should I simply look at the, maximize theexpected value? Is that the right thing to do?Should one be worried about the spread around the mean?So the expected value or the mean value tells you what happens when you repeatedlyinvest. Most of us don't have the ability torepeatedly invest. If we go bankrupt, our investment is over.You don't have the ability to return from bankruptcy then you might have to worryabout what happened to the spread around the mean.How does one quantify the spread around the mean is going to be a question thatwe'll have to deal with. The way we are going to do this in theseset of modules is we're going to talk about the mean and we're going to quantifythe spread around the mean by the variance.So the d, the values defining the asset returns are going to be the mean returnwhich is the expected value of the net return, the variance of the asset returnwhich is simply the variance of the random variables.Notice the mu I's and the sigma I's are assumed to be independent of time, again.Either the market itself is stationary or we are only interested in myopicinvestment therefore we don't have to worry about time.The covariance between the asset return is the covariance between a random return anda particular asset i and a asset j. Correlation again it's between two assetsand there's a relationship between covariance and In correlation.Covariance is nothing but the correlation times the volatility of asset I and thevolatility of asset d. All parameter are assumed to be constantover time. Now, I'm going to characterized the randomreturn that I get on a portfolio by looking at the expected return on theportfolio. And the variance of the return on theportfolio. So the expected return on a portfolio x,Mu sub x, is going to be expected return on the net return of that portfolio r subx, by using linearity of expectations. We end up getting that this is nothing butthe expected return on each of the assets times the fraction invested in that asset,xi. So it's just mu i times xi, sum from Igoing from Y to D. The variance of the return again, just bythe expression, it's the sum of R I time X I, the variance of this random variable.And if you expand it out it becomes the covariance of R I and R J times X I, X J.Here's just a simple example to try to work you through it.So I have 2 assets with normally distributed returns with mean mew andvariance sigma squared. So R1 is one asset it has a mean 1, and ithas a variance 0.1. R 2 is another asset, it has a mean 2, ithas a variance 0.5. The correlation between these two assetsis -0.25. If it translates this statement into thoseparameters, mu 1 is 1, mu 2 is 2, sigma 1 squared is 0.1, sigma 2 squared is 0.5.Sigma 1 2 is which is the covariance between r 1 and r 2.Is going to be the correlation whose number is right here, times Sigma 1, Sigma2 you plug in the answers you end up getting it's .0559.In the 2 asset market, portfolios are very easy to define.Remember portfolios were the fractions invested.So if I invest fraction x in asset 1. And since the fraction invested in asset1, and the fraction invested in asset 2 must add up to 1.I should invest 1 minus x in asset 2. Later on, we will see how we can use thisx1 minus x to try to do efficient portfolio selection between these 2assets. Plugging it then into the formula, theexpected return on this portfolio is going to be sum of mu i xi 1 through d, 2assets, the first asset has x, its expected return is 1 so it's 1 times x,the second asset has 1 minus x, its expected return is 2, so the totalexpected return that you get on this portfolio is x plus 2 times 1 minus x.What is the variance associated with the return of this portfolio?The formula is Sigma i j x i j, x i x j summed from i equals 1 through d, whichcan be equally written as sum of i going from 1 through d Sigma i squared, x isquared plus 2 times j greater than i Sigma i j x i x j, plugging it in, .1which is a variance of the first asset times the investment in the first assetsquared. .5, which is the variance of the secondasset, times the investment in the second asset squared.Two times the variance, covariance between the two assets, which is just computedhere, times the investment in the first asset and investment in the second asset.This exact thing can be generalized to multiple assets, and that is what we'll doin later modules. Okay, the first thing that we want to talkabout is that diversification, or thinking about the spread around the means, isimportant because it reduces uncertainty. So let's consider a very contrived market.I have D different assets, all of them have the same expected return, mu, all ofthem have the same volatility, sigma. And the correlation between the assets is,is equal to 0. So each of the assets is basicallyidentical, and now let's think about 2 different portfolios.In one portfolio, x, I invest everything in asset 1.In the other portfolio, I equally distribute my initial dollar over all theassets, so in every asset, I invest 1 over d.Both of these are portfolios. The expected return of the first, of thefirst portfolio which is x, is simply the expected return of asset one which is mu.The expected return on the other portfolio, y, which equally invests in allthe assets, is going to be the average of the returns of all the assets, since eachof them has the same return mu, the average is also going to be mu.So if we were just looking at the expected value, the two of these, these twoportfolios cannot be differentiated. They both give me the same expected value.We should be as happy investing in X as we should be investing in Y.But if we are as we should be interested in reducing incertainty, perhaps these 2portfolios are different. So if you look at the variance of thereturns of the portfolios, what do you get?Sigma x squared Which is the radiance of portfolio x.We know that, that just invests in asset 1.So it's nothing but volatility squared, sigma squared.What happens to the variance of portfolio y?If you plug in the formula, every one of them has over d invested in it.So it's 1 over d squared, sigma squared. There are b terms.So ultimately you get that the variance associated portfolio wide sigma squaredover d. Think about d of the order of 100.Okay, I'm interested in the s and p 500 index.So in the one case, I get volatility sigma square.In the other case my volatility has dropped down 100 fold.So just by diversifying between assets, identical assets, now I have been able toreduce my volatility a lot. The mean-variance portfolio selectionproblem, in the end, generalizes this idea.Here I'm taking a very simple. Problem All the assets have the samereturn. All the assets have the same variability,and I know that equal spreading is the best thing.Now what I want to do it sprea, move this idea to, to a case where the mean returnsare not the same, variances are not the same, the covariance may not be equal tozero. How does one think about this problem?How does one compute efficient portfolios meaning portfolios that have A good meaninvariance properties is going to be the main focus of these sets of modules.So, in 1954, Markowitz proposed a portfolio selection strategy.In his model, he suggested that the return.And the return has been put in quotes. I wanted to read this more as the benefitcoming from a portfolio, to be the expected return of that portfolio.And risk associated with that portfolio to be the volatility of that portfolio.And what he suggested was that these are the 2 quantities that are going to beinteresting to investors. They would want to increase their returnand decrease their risk. So what I'm plotting over here are thereturns on some random portfolios. In the, in the next module I'm going toshow you a spreadsheet which shows you how these random returns were generated.I have, I have 8 different assets, the details of which will be in thespreadsheet. I've randomly generated positions on these8 assets, figured out what the return is going to be, figured out what theirvolatility is going to be and then plotted a point.So all of these blue dots, Dots, are actually verious portfolios randomlygenerated. And the efficient frontier, this line overhere, is genearted by the following procedure.We pick particular value of relativity, of risk, and try to compute the largestreturn that you can get on a portfolio. Here that has risk no larger thanparticular bound. So let's say sigma bar is the bound here.Figure out a portfolio. Compute a portfolio.And I'll show you the spreadsheet, how these portfolios are computed.Which has the largest return, with risk not exceeding sigma bar.And that point will be right here. And similarly, you take different valuesof these sigmas, compute out what is the maximum return that you are going to get,and this blue line is generated by computing the maximum return for a givenvalue of risk. That frontier Is called the efficientfrontier. Why is it a frontier?Because all portfolios, all feasible portfolios must lie below.This is all the part that is feasible. For any portfolio that you choose, itsrisk and its return values must be below the line.All of this space is unachievable. You cannot create a portfolio whose returnand risk point lies in that region. Why is that?Just the way it's computed. I take the value of sigma, which is therisk, I compute the maximum possible return that I can get, and that's how Iget this point. This return up here is not achievable.So everything above the frontier is not achievable.Everything below the frontier, below or equal to the frontier is achievable, but Iwould never want to be below the frontier. If I have a point over here, its risk issome quantity over here. Let's called it sigma 1.My frontier tells me that I can create another portfolio, a different portfoliofrom the one that generated that point, whose return is going to be right here.It's going to be on the frontier. So I would never want this portfolio.I only want portfolios that lie on the frontier.Above the frontier, unachievable Below the frontier inefficient.Right at the frontier is the place where I want to be.So the question that we will answer in the next few modules, is, how does onecharacterize this efficient frontier? How does one compute efficient.Or sometimes I'm going to call it optimal portfolios.Portfolios that lie on this efficient frontier.There are three different ways in which you can compute.The mean variance optimal frontier, that line that I showed you before, which tellsyou the maximum return for a particular value of risk.One way is to minimize risk for a target return.You can set the target return that you want.You want to make sure that the expected value on the portfolio has to be greaterthan or equal to R. And among all portfolios that satisfythat, you want to minimize the variance, or minimize the volatility, which is EQ1.If you expand this optimization problem, you can write it as sum of XI is equal to1. So this is a portfolio constraint.And here you're saying that the expected return on that portfolio must be greaterthan equal to r. And this expression here just expands outwhatever is written over there. And for those of you who are,mathematically sophisticated, this expression is nothing but the vector xtranspose, a matrix of covariance times x. And what is this matrix?It's sigma 1 squared, sigma 1 2, sigma 1 3 and so on.Sigma 2 1, Sigma 2 squared and so on. So this is the variance-covariance matrix.And this expression there is simply x transposed variance-covariance matrixtimes x. An equivalent way to get the entirefrontier is going to be to maximize return for a given value of risk, maximize mu ofx such that sigma squared of x is below some target number sigma bar squared.If you write this in terms of the x i's it becomes some of the x i's must be equal to1, again the portfolio constraint. X transpose sigma x, ir sigma ijxij summedmust be less than or equal to sigma bar and you want to maximize the expectedreturn. There is yet a third way of trying to getthe entire frontier. And that is, to maximize a risk adjustedreturn. So maximize over portfolios, x.Mu of x, the expected return minus tau, which is for the risk aversion parameter,sigma X squared. So the risk aversion parameter is alwaysgreater than zero. You don't like risks, therefore you wantto subtract from the extracted return a certain quantity that depends upon risk.If you again this expression, you get a sum of XI is equal, from XI must be equalto one, which is the portfolio constraint. This is just mu of x and that is sigma xsquared and that's the tau there. What do I mean by saying all these threewill generate the same frontier? There are parameters and there are threeparameters in all of this, all of these formulations, r, sigma bar squared andtau. And as you Crank up these parameters fordifferent values of these parameters you will write out the same curve.

### 002. Introduction to Mean Variance in Excel

In this module, I'm going to show you how to construct portfolios in Excel,how do you compute random portfolios, their returns,their volatilities and to plotthe efficient frontier corresponding to the data in one of the worksheets.And what are we going to do is set up the optimization problem that we talked aboutin the theoretical modules and show you how you can compute the efficient frontiers,and the efficient portfolios on these frontiers using a solver optimization program.In this particular spreadsheet,I'm going to have eight different asset classes: US Bonds, International Bonds,US Large Cap Growth,US Large Cap Value,US Small Cap Growth,Small Cap Value, International Developed Equities and International Emerging Equities.And the mean returns for these different assets are 3.5,1.75, -6.39 and so on.And these are all in percentages.This matrix down here is the variance-covariance matrix.So the variance of US Bond with itself is 0.001.So this quantity is the variance.The volatility of the bonds is definedas the square root of this quantity and the variance times 100.So it's 3.17%.The covariance between US Bonds and International Bond is 0.0013.The variance of International Bonds is 0.0073.Written in percentages, the volatility is 8.53%.So all I've done here is I've taken the diagonal quantity,took the square root of it and multiplied by 100.I'm going to use this spreadsheet to randomly generate portfolios and thentry to find out what the returns andvariances or returns and volatilities of that portfolios are going to be.And as we walk through this mean variance optimization module,I'm also going to tell you how to compute the efficient frontier,how do you compute efficient frontier when there is a risk free rate and so on.So here's just placeholders for the portfolios x1 through x8.And each of these portfolios' values arecurrently being generated from a random distribution.So this is randomly generated.And since x1 through x8 is a portfolio,all I've done is I've taken x8 and written that to be one minus the sum of x1 through x7.That just guarantees to me that this entire thing sums to one,and this quantity here is just a double check.It's summing all the components from x1 through x8,and it's indeed equal to one for the random value that has been generated here.What is the rate of return on this portfolio?It's simply the sum product ofall the components here multiplied by the mean return over there.Mean returns are in percentages.The portfolios here are just in straight numbers,and therefore, the number that you end upgetting here is actually rate of return in percentages.What about volatility?Volatility of the portfolio is simply100 times the square root of the variance of the portfolio.How do you compute the variance of the portfolio?You have to take this.It's going to be Sigma_IJ,which is the covariance of asset I with asset J,times x_I times x_J,summed over IJ going from 1 through 8.Take the square root of that and multiply by 100.Now, a mathematically concise way of doing this,and we'll see this later on in the modules,is to take this vector X, take its transpose,multiply it to the covariance matrix and then left multiply with the same quantity.So if you look at this, what I'm doing is I'm taking this vector,I'm taking its transpose andmultiplying it to the matrix which is the variance-covariance matrix.If I do that multiplication,I get a vector which is a column vector.I multiply it again by row vector.I get a number,which is the variance of the portfolio.I take its square root and multiply it by 100.And I end up getting the volatility.So that's how the volatility numbers are computed.So what I want to show you over here,all I'm doing in this particular case is randomly generating portfolios.So if I do have nine,a new portfolio comes up there.It has an associated return value, associated volatility value.Again, here's another sample, volatility return.I'm going to do it one more to hope to get a positive return note.There. We get a positive return of 13.67%,but the volatility associated with that is 41.23%.So these volatility numbers and the random returns wasrandomly generated by creating a portfolio,looking at what the random return is,looking at what the volatility is,and all I did was put them in increasing order and plotted these red dots here.Now, what I want to show you is how I computed this efficient frontier.The frontier which tells me what isthe maximum possible return for a given value of volatility.In the module on mean variance analysis,we said that the frontier can be computed in three different ways:either by maximizing the return for a given value of volatility or risk,or minimizing volatility for a given value of return,or maximizing the risk adjusted return.In this particular case,our volatility numbers are given.And for each value of volatility that are randomly generated,I want to compute the maximum possible return.And I'm going to show you now in Excel how to compute that using solver.So we're going to go back to the data sheet. Here's the data sheet.And remember, I showed you that this cell here B22,this particular cell actually has the value ofthe mean return for a particular portfolio, randomly generated portfolios.Here is the volatility for the given portfolio.And what I want to do is make sure thatthis volatility number is less thansum budget that I'm going to specify in this orange cell.And I also want to make sure that the quantities that Ichoose for x1 through x8 is actually a portfolio,which means that if I sum them up,which is what is the numbers in this cell,it must equal one.So orange cells are data that I'm going to provide.This one here simply says that it's a portfolio.This 85.94 is a risk budget that has been given a particular random risk budget.So let's clear this for the moment,and let's try to compute what is going to happen.So I'm just going to clear the contents.Don't worry about this value here because it's zeros, it doesn't like it.And I'm going to show you how to set up an optimization problem to solve it.So here's solver.I'm going to set an objective.I want to maximize the cell B22,which is the net return in percentage.I want to maximize that quantity by changing the portfolio values.These are numbers B20 through I20, x1 through x8.And I want a constraint which says that the volatility number that I'm computing in cellB24 must be less than equal to the budget that I'm going to specify in cell D24,which is what this constraint down here is.The next constraint, J20 equal to L20,simply says that J20,which is the sum must equal one,which is the number that I'm going to specify over there.This is not the constraints.The values involved here are nonlinear.Remember, the volatility is a square divided by square root,and so I'm going to choose an optimization algorithm which is GRG nonlinear,solve and wait for the answer.So it's cranking numbers.It's going up. You say okay.You ended up getting that the maximum possible return that you couldget for a risk budget of 85.94 is 58.25.And in order to receive this value, 58.25,this is the fraction that you need to invest, 5.02.You are to take a leverage of five times up there.Short International Bonds, shorts US Large Cap Value,short US Small Cap Value and so on for this particular set of data.So like I said, I don't want you to think that these are representative numbers.These are just some numbers taken from a paper.And if you look at this particular data set,the optimum return for that particular risk level,let me go back, 85.94.The randomly generated bond was -8.73.The best possible return is 58.25,which is exactly what we just computed.So next thing I want to show is that in many cases,you might want to just have long positions,not short positions and go to the solver.And here I'm going to just click 'make unconstrained variables non-negative.'For those of you who are watching this,I want you to pause this for a moment andthink to yourself whether the number that I'm going to get,the maximum return that I'm going to get at this point is going to belarger than 58.25 or smaller.And the way I want you to think about is that the constraints,I'll put more constraints and what should that do to the maximum value.So let's solve it and see what you end up getting.So the maximum possible return that you canget if you decide to give yourself a budget of 85.94,and you say that the only thing that you can do is go long on all the assets,is you're going to go to the US Bonds and put all your money there.You're not allowed to short so you cannot increase the investment in US bonds,and you just take the return of that which is 3.15%and take the volatility which is 3.17%.So it's within the budget,but you were not able to use all the budget.So you can only use the budget if you're allowed to have short positions. Okay.

## 002.Efficient Frontier

### 003. Efficient Frontier

In this module, we are going to define the efficient frontier for a mean versionportfolio selection problem. We are going to walk through how tocompute the efficient frontier for a 2-asset market, and then for a generald-asset market. And the main punchline is that the d-assetmarket is no different from a 2-asset market.If you remember what we said was for a given level of risk, the efficientfrontier gives you the maximum possible return.So, this is the efficient frontier, this, this particular point corresponds to thereturn of a portfolio, which is an efficient portfolio, or it's a frontierportfolio, all of these things are synonymous.It's a, it's a portfolio that for a given level of risk, gives you the maximumreturn, or another way to look at the same point is that for a given value of return,this portfolio gives you the minimum risk. So, any investor wanting to hold a certainamount of risk or wanting to hold a certain amount of return, will want to beon this efficient frontier. And in this module, we're going to walkyou through the calculation of how this, this particular curve is computed.We're going to work with a very simple example first, just of two assets, tworisky assets. And then, in the later part of the module,we'll show you that, that is the most general.In fact, if you have any number of assets, you will end up using only two mutualfunds to construct the efficient frontier. So, here's my problem.I want to do mean-variance optimal portfolio selection for a 2-asset market.Asset 1 has mean return mu 1, it has variance sigma 1 squared.Asset 2 has mean return mu 2 and variance sigma 2 squared, and the correlationbetween the two assets is rho. What's nice about a 2-asset market is thatthe portfolio constraint is very simple to write.A portfolio, remember, was the fractions invested in the different assets.So, in a 2-asset market, there's only one unknown x.Suppose, x is the fraction that you invest in asset 1, then 1 minus x will be theamount you will invest in asset 2. And therefore, the return of thisportfolio x1 minus x is going to be the mu 1 times x because that's the amount thatyou invest in asset 1, mu 2 times 1 minus x because that's the amount that youinvest in asset 2. What is the variance of this portfolio?It's going to be sigma 1 squared times x squared, that's the variance coming fromasset 1, sigma 2 squared times 1 minus x squared which is the variance coming fromasset 2 plus 2 times rho sigma 1 sigma 2. And if you go back, this is nothing butthe covariance sigma 1, 2 between the two assets, times x, the amount invested inasset 1, times 1 minus x, the amount invested in asset 2.It's very simple. It's one-dimensional in the sense that theonly thing, only unknown is x. And that's why 2-asset markets are veryeasy to describe. So, I want to solve minimize riskformulation for the mean-variance portfolio selection problem.So, what I want to do is specify a target return.And then, find a portfolio that achieves the target return, but has the minimumrisk corresponding to that target return. This is the return of the portfoliothat's, this is mu of x. We wanted that to be greater than or equalto r. Here, we are saying that this is exactlyequal to r. So, there's a difference between thesetwo. We wanted it to be greater than or equalto r, and we are now wanting it to be equal to r.The reason we made it equal to r because it's now, it's very easy to compute.One equation, one unknown, I can solve for x.I can plug that x into the form, into the expression for the variance, and I'll getthe efficient frontier. But this fact that I wanted equal to rwill come and affect us in the final solution and we'll have to reinterpretwhat that means. So for now, let me erase all of these sothat it becomes clear what we are trying to do.What we're saying is, among all those portfolios that give me a return exactlyequal to r, find me one which has the minimum variance.For a 2-asset market, this becomes trivial because there's only one unknown x, and Ican solve for it. So, there's only one portfolio that givesme the desired return r. And what's the value of x?It's simply r minus mu 2 divided by mu 1 minus mu 2.You simply solve this one-dimensional equation and you'll get the answer.So, I know the portfolio x that is going to give me the target return, I'm going toplug it into the equation for the variance.So, if x is r minus mu 2 times mu 2 minus mu 1, 1 minus x, which is the amount thatyou invest in asset 2, is going to be mu 1 minus r divided by mu 1 minus mu 2.You can just do the algebra and it'll turn out to be right.So, what I've done in this line, is that here I've just set x, so it's sigma 1squared x squared. Here I, put in 1 minus x so it's sigma 2squared 1 minus x squared. This is x, this is 1 minus x.If you plug in the answers, you'll exactly get this expression.If you expand it out, you'll end up getting that sigma r squared is ar squaredplus br plus c. So, these are just numbers that depend onsigma 1, mu 1, and rho, and sigma 2, mu 2, and so on but these are numbers, r is theonly unknown. So, what does this tell me?It tells me two things. If I know the target return r that I wantto get to, the variance, the minimum variance corresponding to that targetreturn is explicitly given by a formula. In fact, it's by, given by a parabola.So, what am I drawing here? I'm taking the value of r, and how wasthis computed? I plugged this value of r into thatformula. I calculated out what sigma 1, sigma rsquared is going to be, took a square root of that.That's going to be volatility. So, I'm plotting r in percentages here.I'm plotting volatility in percentages. And this is exactly for the same set ofassets that I showed you on the spreadsheet.When we are down to this module, I'm going to go back and show you how to do the samecomputation on the spreadsheet. I compute out what sigma r is going to be,it's going to be this number and I'm going to plug this for all possible values of r.Notice on this slide, I'm plotting two different curves, one in blue, one is red.The red curve is not efficient. If you take a point here, this has areturn of minus 2%. It has a volatility of, let's say,approximately 8%. We can get another portfolio with the samerisk level, 8%, with much higher return. This particular portfolio up here has thesame risk level, 8%, and has much higher return than this minus 2.So, this entire red curve, in fact, is not efficient and that is what we marked out,it says, it's inefficient. So, why did we end up getting it?We ended up getting it because when we set up the optimization problem, we insistedthat the target return should be exactly equal to the return that I specify.If I had made it greater than or equal to, and you have specified a return minus 2,the optimization problem would have discover that for that particular targetreturn, the best portfolio, best risk is this 8%, but for the same 8%, I can giveyou a much higher return and therefore this bottom line would never haveappeared. The bottom line appeared only because ofthe equality constraints. It's sometimes convenient to put theequality constraints because we can solve the optimization problem simply, but lateron, we'll have to come back and then argue that certain parts of the curve cannot beefficient. Alright.Now, I want to extend it to a d asset problem, and see how far can I push it.So, here's a mean-variance problem that I want to solve.Same thing, I want to minimize my variance, but now here's the expressionfor the variance. It's the covariance matrix sigma ij timesxi and xj. I need to make sure that the x's that Iconsider is a portfolio, so the sum of the x's is equal to 1.And again, as before, instead of putting greater than or equal to r here, I amputting equal to r, for the same reason because I have equality constraints and Ican solve this more efficiently. In the prerequisite modules for nonlinearoptimization, we had introduced this idea of Lagrange multipliers.The problem with this optimization problem is that it has two constraints and I don'tknow how to deal with these constraints effectively.So, the easiest way to do it is to construct something called the Lagrangianand the way to construct the Lagrangian is to take the objective function.So, this box here is just the objective function, take the constraints.So, this particular constraint is the target return constraint except that ther, which is on the right-hand side, I said, is equal to minus r inside thebracket. This constraint is the constraint thatsays that the some of the x's should be equal to 1, that is, they must be aportfolio. And again, the 1 on the right-hand side, Imoved it into the left-hand side with the minus 1 and then I multiply it by twomultipliers, u and v, which I call the Lagrange multipliers.Now, having put the constraints into the objective by multiplying by the Lagrangemultipliers, I'm going to completely ignore the constraints.I'm going to say that this is now an unconstrained problem.And we know that for the optimal solution of an unconstrained problem, we have tocompute its gradient and set it equal to 0.Now, this particular objective function, assuming that u and v for the moment arejust multipliers, they are not unknowns. The, the decision is in terms of these x'sand there are b of different x's so I have to take the partial derivative of thisexpression with respect to all of them, and set it equal to 0.If you take the partial derivative with respect to i, you'll get two times sigmaij, xj, that's the derivative that's coming from this term.You'll get v times mu i, which is a term that is coming from here, and minus u,which is the term that's coming from there and then set it equal to 0.I'll have one equation for all i's going from 1 through d.So, I get d equations from here. I have two other equations from here.I need to make sure that my portfolio satisfies the target return.And I need to make sure that it satisfy, it's a portfolio.So, I have two equations here, I have d equations here, and how many unknowns do Ihave? I have actually d plus 2 unknowns.Why the 2 extra unknowns? The 2 Lagrange multipliers, u and v.So, here are the original set of unknowns, here are the new unknowns that Iintroduced, I have d plus 2 unknowns, d plus 2 equations I can solve.And in the next slide, I'll show you how to set up the linear equations to solveit. Here, I'm going to encapsulate this storyinto a theorem which says that a portfolio x is mean-variance optimum, if and only ifits feasible, it satisfies the constraints, and there exists u and v.Multipliers u and v would satisfy these constraints star, which satisfy all ofthese gradient conditions. And this will become important in a fewslides. Alright, so here, all I've done is I'vetaken these equations that are there, these d equations, and the extra twoconditions on the portfolios, and set them up as one large matrix.So, up here, all of these equations are the gradient equations.This equation is the target return equation.This equation is the portfolio equation. So, there are d plus 2 equations here, dplus 2 unknowns. All these zeros corresponds to thegradient conditions that they must all be zero, this r is, of course, the targetreturn, and this 1 is the fact that it's the portfolio 1.So, that's some vector b this is some, I'm just calling this matrix A and we, justsimple Linear Algebra tells me that if I take all of these portfolios this vector,I can compute it by simply taking the inverse of A and multiplying it to thisvector b. Done.In the rest of this module, what I want to do is give you a little bit more structureof what do these portfolios look like. Is there any interesting structuralproperties underneath, which we'll use later to derive something like the capitalasset pricing model? So, we got to walk through a couple ofslides, which will end up showing something called the two fund theorem.The two fund theorem says, that the entire efficient frontier can be generated byjust looking at two portfolios or two mutual funds.So suppose we fix two different target returns, r1 and r2, and I go and solve forthe optimum solution for r1. What do I mean by solving from the optimumsolution? I go to this set of equations, plug in r1over here and compute the optimum portfolio.That's port, optimum portfolio, I'm going to label it as x superscript 1.And when I solve for that portfolio and also compute out the correspondingLagrange multipliers, v and u, I'm calling them in this light, v1 and u1.I take the other return r2, do the same thing.The optimum portfolio, I'm going to label it as x superscript 2 and the Lagrangemultiplier as v2 and u2. Okay, now, we take any target return rthat we want. I'm going to arbitrarily create for youanother position y and argue to you that this position y, in fact, is the optimalsolution for that new target return. And here's how it's going to beconstructed. You take a target return and you choose anumber beta, which is r minus r1 divided by r2 minus r1.And if you remember back, we, in the 2-asset market, the x was simply r minusmu 1 divided by mu 2 minus mu 1. So, this should somehow give you an ideathat we are going back slowly to this 2-asset market, which is effectively whatthis two fund theorem says. I'm going to create a new position y.I don't know whether it's a portfolio for now.And the way I'm going to construct this y is I'm going to take 1 minus beta timesx1, which I know, and beta times x2. I'm going to add them up.This will give me some positions in all the b assets.And let's walk through and see what, what happens.The first thing that I'm going to do is compute out the sum of all the componentsof y. Sum of this yi is nothing but 1 minusbeta, the sum of the corresponding coefficients of x1.Beta times the corresponding coefficients of x2.X is a, x1 is a portfolio, x2 is a portfolio.So this sum is equal to 1, that sum is equal to 1.1 minus beta times 1 plus beta times 1 if you add it up, you get 1.So, after this calculation, we know that this y, which was just a position rightnow, is now a portfolio. It's a set of numbers that adds up to one.Now, let's calculate out what is the expected return on this portfolio y.That's mu i times yi, expand it out again, it's 1 minus beta times mu i times x1 i.Sum from i equals 1 to d, beta times the sum of mu i times x2 i sum from 1 is to d.This one, remember, x1 is feasible for a target return, and so it's actually equalto r1. This quantity is feasible for a targetreturn r2, so it's equal to r2. So, it's 1 minus beta times r1 plus betatimes r2. Plug in the value of beta that it wascomputed, you get exactly equal to r. And if you connect back to theone-dimensional or the 2-asset case, this is exactly saying 1 minus x times mu 1plus x times mu 2, must equal r, which is exactly the equation that we solved there.Now, we are going to argue in the next slide, that this y, in fact, is optimum.And how are we going to do that? I am going to use the theorem which saysif I can find multipliers u and v for which the equations hold, then y must beoptimal, because y is feasible, it is a portfolio, it has a right target return ifI can find u multipliers such that all the gradient conditions hold, it must be theoptimal portfolio. So, I know v1 and v2.So, I take a guess, and say that the v variable corresponding to this newposition is just the same multiplication. 1 minus beta times v1, beta times v2.1 minus beta times u1, beta times u2 is going to be u.Here's my sigma ijy, ij minus v mu i minus u.This is the gradient condition that corresponds to asset i.So, this is the partial derivative of the Lagrangian with respect to the asset i.I plug in the values for what y, this is nothing but a plug in for what yj is goingto be. Here, I'm plugging in my guess value of v.Here, I'm plugging in my guess value of u. You rearrange them.Take all the 1 minus beta terms together. You end up getting something that justdepends on the asset 1, the multipliers, v1 and u1.But x1 was optimum, therefore, all of this bracket must be equal to 0.Similarly, if you collect terms for beta, you'll get terms that correspond to x2.But x2 was optimum, so therefore, this must be equal to 0.1 minus beta times 0 plus beta times 0, gives you zero.So, I have constructed for you multipliers, v and u, v and u, such thatall the gradient conditions hold. Therefore, y must be optimal for thetarget return r. And we have this theorem which says, thatall efficient port, portfolios, all the portfolios that are there on the efficientfrontier can be constructed by diversifying between any two efficientportfolios with different expected returns.The only condition that we needed on x1 and x2 is that they have differentreturns. So, everybody, whoever is going to beinvesting in this market, they're happy if I just give them two mutual funds and say,okay, you just invest what you like on these two mutual funds.So, why are there so many mutual funds in the market?There are over 6,000 of them floating around.Why are they there? You might want to pause your video herefor a second and think about it. So, the reason those different mutualfunds are there is because we're assuming in the background here that all theinvestors have the same expected return, mu, and have the same covariance matrixsigma. What do I mean by they have?Meaning they estimate what is going to happen in the future by the same meanvector and the same covariance matrix. That's never going to be true.So, even if they are all mean-variance investors, they might have differentestimates, which means that their efficient frontiers would look different,which means that a portfolio or a mutual fund which will be efficient for oneinvestor may be completely inefficient for another investor.There's also no reason to believe that everybody is a mean-variance investor.This is another topic that we are going to talk about towards the very end of thismodule. And so, although this, this theorem isvery interesting and important and, in fact, led to the development of theindustry as a whole you should take it with a, a grain of salt that there is agap between what theory is and what practice its going to be.Alright, returning back to the theory. The theorem says that all efficientportfolios being constructed by diversifying between two efficientportfolios which means effectively, it's a 2-asset market.If I'm talking about investors, they don't need more, anything more than two assets.And therefore, since y star can be written as a combination of x1 and x2, all I'vedone is rearranged terms. I took the r outside, I put x2 minus x1divided by r2 minus r here. Call this a new position g, call this anew position h. So therefore, every component can berewritten as r times gi plus hi. Plug it into the expression for varianceand you'll end up getting again that the efficient frontier has a same structure asa 2-asset efficient frontier. And therefore, we'll just end this moduleby showing you that the efficient frontier looks the same.Again, the same story. This bottom is enef, inefficient.And the reason we had this because instead of putting target greater than or equal tor, we set target equal to r. And this, this equal to ends up givingthis the inefficient frontier at the bottom and we'll stop.

## 003.Mean Variance with a Risk-free Asset and Risk-free Frontier in Excel

### 004. Mean Variance with a Risk-free Asset

In this module, we are going to walk you through how to construct the efficientfrontier for a market with a risk free asset.We're going to see that we're going to define a new portfolio called a SharpOptimal Portfolio. That's going to play a very important rolein this module as well as in the next module on capital asset pricing module.So, we have a new asset. It pays a net return rf, with no risk.It's completely deterministic. And we're going to label this asset as x0.And again, I want to construct the efficient frontier.But this time, I'm going to use a different formulation of the mean-varianceoptimal portfolio selection problem to construct the efficient frontier.If you go back two modules, we had set up three different ways of doing efficientfrontiers. One was by maximizing the return for agiven value of risk, another was to minimize the risk for a given value ofreturn. And a third one was to maximize arisk-adjusted return. And that's the formulation that I'm goingto use. So here's my return, r f times x0 is thereturn on the zero asset, which is the risk-free asset, and this is stuff that wehave seen before. Mu i times xi sum from i equal to 1through d is the return on the risk-free asset.This here, is the variance of my return. And the thing that I want you to focus onthe fact is that here the indexes go form i equals 1 to d.So, i equals 0 is absent. And why is this absent?Because i equal to 0 corresponds to the asset that gives me a deterministicreturn, it doesn't have a variance. Down here is a risk aversion parameter.And we also know that the entire frontier can be computed by just taking differentvalues of tau. As you go from tau, tau must be greaterthan equal to zero. It cannot take negative values.But as you crank up the tau, from tao equal to zero to tau equal to infinity,the entire efficient frontier is going to be computed.What's down here? Just a portfolio constraint.Now I have d plus 1 assets. And therefore, the fractions invested inthis d plus 1 asset must be equal to 1. So x0 plus, so I can solve for one ofthese using that. And it is what I'm going to do in the nextcalculation. One thing to keep in mind is that thisentire mean variance calculation is meaningful only for target returns r thatare greater than equal to rf. Again, I would like you pause here andconvince yourself that you will never want to consider a return less than rf.Alright. So now, we have this equation that relatesx0 to the other x's. So, I'm just solving for it.I'm substituting x0 equal 1 minus the sum of the x's and plugging it back into thisequation. The nice thing is that this equation doesnot involve x0 at all so it remains the same.The other ones do involve x0. So, what I've done is that this one getsmultiplied by rf, so that's that one over there.These minus xi's also get multiplied by rf so they are sitting over there.So it's mu i minus rf times xi. So, one thing that immediately falls outof this calculation without looking further into what happens to the efficientfrontier and so forth is that the relevant quantity.When you have a risk-free asset in the market, the relevant return that you'reinterested in is the excess return on the asset.So mu hat i, which will play a role later on, is mu i minus rf.It's the excess return on asset i. It's the returning excess of the risk-freerate and that is what going to determine what the portfolio is going to be.We have an expression, now let's just optimize it.This time we are lucky because this expression that we have here has noconstraints, no constraints on x. Why?Because there was only one constraint which was a portfolio constraint and weused that constraint to set the value of x0.So, we just take the derivative with respect to all the xi's and set it equalto 0. If you take the derivative of the firstterm, you'll get mu hat i. If you take the derivative from the secondterm, you'll get minus 2 tau, sum of j going from 1 through d sigma ij times xj,and that must be equal to 0. So, d equations, d unknowns, I can solve.What I've done is rearrange this equation in a matrix form.I said 2 tau times this matrix V, x, this is a vector of x must be equal to mu hat.You invert it, and you end up getting that for a given value of risk aversion tau.So, the only thing that I'm trying to emphasize here is that x is a function ofthe risk aversion parameter. So, you give me the risk aversionparameter, and I will compute out what is going to happen to the portfolio.So, it's going to be 1 over 2 tau V inverse mu hat.So, what is the family of frontier portfolios?Remember, I said that all the frontier can be generated by changing the value of tau.So, the family of portfolios that sit on the frontier are simply x'd out.But this x'd out was only the risky part of the portfolio.So, what is the amount that was invested in the risk-free part of the portfolio?It's just 1 minus the sum of all the components.So, this is essentially x0 tau, the amount that you invested the risk-free asset, xtau is exactly that. And this is called the risky part of theportfolio, the risky portfolio. And as you crank up your tau for allvalues of tau going greater than or equal to zero, you'll get a family ofportfolios. All of these portfolios are going to siton the efficient frontier. That's great, but again, we're going to doan exercise very similar to the two frontier.I want to understand the structure of this frontier better.So, let's focus just on the risky asset in the frontier portfolio.X is 1 over 2 tau v inverse mu hat. This is just a risky position, thereforeit does not add up to one. So, the first thing that I'm going to tryto do is construct another portfolio, meaning that components add up to 1 fromthis position which doesn't add up to 1. And the easiest way to do it is to take aposition x, because if they don't add up to 1, and divide it by the sum of thecomponents. And call a new position s star.But now, if you look at the sum of s star i, i going from 1 through d, that isnothing going to be the sum of i going from 1 through d of xi divided by sum of igoing from 1 to d of xi. They will cancel and you will end upgetting the sum of this components of this vector s star is equal to 1.So, s star in fact, is a portfolio. So, what's special about this portfolio isif you plug in the value of x for any value of the risk of urgent parameter tou.So, x is 1 over 2 tau, we inverse mu hat. In the denominator, I'm adding it up bythe same, same position, so you get 1 over 2 tau here.So, the 2 tau's cancel. Which means that if I look at the riskypositions that an investor is holding for any value of the risk aversion parameter,tau, and construct a corresponding portfolio, meaning normalize it, so thatits components add up to one, I get the same portfolio as star.It doesn't depend on tau. Which means that I can look at theefficient portfolios are reparametrize them, think of them differently.Essentially, what everybody is doing is taking a certain amount of their dollar x0and putting it into a risk-free asset and the remaining about 1 minus x0 is theamount that they are investing in s star. Everybody in, investing in the sameportfolio s star. So, the family of frontier portfolio nowis very simple. Put the money into the risk-free, take therest of the dollars and put it in, invest it into s star.So, we end up getting this theorem which says that all efficient portfolios in themarket with a risk-free asset can be constructed by diversifying between therisk less asset and the single mutual fund, s star.And in the next few slides, we're going to try to give you more structure as to whatis this portfolio, s star. Before we get there, let's just constructthe risk, the efficient frontier in a market with the risk-free asset.Everybody invest in s star. Let mu s star be the expected return onthis portfolio and sigma s star denote the volatility of the portfolio.And the return on the generic portfolio is going to be x0 times the risk-free rateplus one minus x0 times the return on this portfolio s star.And the volatility will simply be 1 minus x0 times sigma s star.Why? Because a risk-free asset does not haveany volatility associated with it. So, let's take two points.The point down here, which has no risk, zero volatility, and will give you areturn rf. Zero volatility will correspond to x0equal to 1. 1 minus x0 is equal to 0.And therefore mu of x, that portfolio will have a return rf.Take another point over here, which corresponds to the portfolio s star.That corresponds to volatility s star, which means x0 is equal to 0.And mu x therefore turns out to be just mu s star.Now, if you look at this curve as I changed my x0, it will trace a straightline. And therefore the efficient frontier willsimply be a straight line that goes from the point that corresponds to therisk-free asset, goes to the point that corresponds to this special portfolio, sstar, and it's a straight line. And because if you can get a return rfwith no risk, you will always want to demand a higher return than rf if you areasked to take a risky position. So, that's going to be the efficientfrontier. Now, what we want to ask is how does thisefficient frontier relate to the frontier with only risky assets?And is there and economic interpretation for this very special portfolio s star?So, here's what's going to happen. Here's the, the green line here is theefficient frontier with the risk-free asset in place.It's that straight line that we talked about.I know that the point sigma s star mu s star belongs to that efficient frontier.Now, rf0, this is the point that corresponds to a risk-free asset, alsobelongs to it and that's a straight line. And this blue line denotes whatever is thefrontier that corresponds to just a risky asset.So, my claim is that s star must be an efficient portfolio, efficient riskyportfolio. Meaning that it must lie on that.Suppose it's not. This is the counter-factual.That maybe s star is actually here. Here, we know that the efficient frontierfor a market with the risk-free asset must go to s star.So, the efficient frontier will look something like that.But that cannot be the efficient frontier. Why not?Because all of these points lie within the efficient frontier, for just the riskyassets. So I can, if you give me a point overhere, which has a particular amount of risk, I can give you a better return.So, holding this point here cannot be efficient.And therefore, whatever that s star is, it cannot be at a point such that thestraight line that goes through s star. Enters the region which is feasible butnot efficient. And yet, s star is a portfolio of just arisky asset, and therefore it must be somewhere in the region that is feasible.It cannot be in sight. It cannot be on the boundary such that theline goes through it. Therefore, the only thing it can do isthat the line must be tangent. And that's exactly the picture that'sdrawn here. So, let me just clean up the story here.For the moment, I'm going to clean up my drawings so that you can go back to seeingwhat the picture is. So now, I know that this s star, whateverit is, must lie, must be such that it's tangent to the efficient frontier, right?Everything that's in the efficient frontier, everything that's down here, canbe computed by diversifying between risky assets.So no, now I want to understand what is go, how this s star is going to becomputed. So, let's look at this angle, theta.My claim is that s star is a portfolio that maximizes this angle or equivalentlymaximizes the tangent of that angle. Let's write out what the expression forthe tangent of that angle is. Take any, any point, any feasibleportfolio here for the moment. So, just do fixed ideas.Let's say here's a particular point that corresponds to a particular portfolio,it's volatility is sigma x and it's return is mu x.So, what is the corresponding angle there? Let's call this angle sum theta of x.The tangent of that I take the y-value. Y-value is just mu x minus rf, which iswhat is written over here. This expression is noting but mu x minusrf. What is the x-value?Which is nothing but sigma x. So, the angle that is cast over here byany portfolio which has volatility sigma x and return mu x, the tangent of that angleis simply the excess return of that portfolio divided by the variance or thevolatility of that portfolio. This particular s star portfolio is theone that maximizes this angle. So, it maximizes the ratio of the expectedexcess return to volatility. This has a name.The Sharpe Ratio of a portfolio or an asset is the ratio of the expected excessreturn to its volatility. The Sharpe optimal portfolio is aportfolio that maximizes the Sharpe ratio. The portfolio s star is just arguedmaximizes the tangent of that angle. The tangent of the angle is the Sharperatio. Therefore, s star is a Sharpe optimalportfolio. Everybody in a market which a risk-freeasset diversifies between the risk-free asset and the Sharpe optimal portfolio.The name Sharpe comes from the fact that this was, that this portfolio wasidentified by Bill Sharpe, who got a Nobel Prize together with Markowitz and Lintner.Alright, the last bit. Now, the investment in the very riskyassets are in fixed proportions. All the investors in a mean-variancemarket are diversifying between the riskless asset and this particular Sharpeoptimal portfolio. And therefore, the demand for thedifferent assets will be perfect synchrony to each other.And which means that if the demands are proportional, then the price and thereturns should be correlated. This should be just a one-dimensionalquantity that should just tell me what the returns on all the asset in the market isgoing to be. Why?Because everybody holds the same portfolio.This inside will lead to the capital asset pricing model in the next module.

### 005. Risk-free Frontier in Excel

In this module, I'm going to show you how to compute an efficient frontier with arisk-free asset in Excel. And then using the solutions from thisoptimization problem, I'm going to show you how to construct a sharp optimumportfolio. And from the sharp optimum portfolio, I'mgoing to show you how to compute the capital asset pricing model, and thesecurity market line that. That goes with the capital asset pricingmodel. We're going to work mainly with twoworksheets. One of them is labeled Risk Free Frontier;this is where we're going to do the calculation for the Risk Free Frontier.And the other one is labeled Sharpe Portfolio; this is where we're going to doa calculation for the soft, Sharpe Optimal Portfolio and.This security market line. We're going to work with the same 8 assetclasses that we had introduced in the previous Excel module.Here are the expected returns on these eight risky asset classes.Here are the variance, covariance elements for the eight risky assets.I've also listed the volatility but we won't be directly using it.Now In my portfolio there actually nine positions.The eight risky positions from before and another position x zero.Which is the position that I'm going to be holding in the risk free asset.Now all of these nine positions should add up to be equal to one Which is what isthere in this gray cell. This simply adds up the 9 positions fromB21 through J21. The orange cell here is a constrained cellthat we're going to be using. When we set up the solver for optimizingfor the efficient portfolio. The misc free rate that I'm going to beusing in this problem is 1.5 %. I'm going to be using the risk adjustedreturn formulation for constructing in the efficient frontier and in that formulationI need the risker version parameter which is, given over here, that's 0.1.This cell just gives you the return on the portfolio.It you click on that cell, you will see just some product of the risky positionstimes their expected return plus the risk free rate times the position that I'mholding in the risk-free asset. The expression for validity is the samefrom before. I take the risky positions and multiplythat by the variance, covariance take the square root multiply that by 100 in orderto represent the volatility in percentages.This orange cell now lists the objective that I'm trying to maximize this is goingto be the expected return on my entire portfolio that is including both the riskfree part and the risky part. And I'm going to subtract from it the riskfree aversion parameter tau times the variance, which is only associated withthe risk free part. If you click on that one, you will noticeyou will get its B27, which is the return on the portfolio minus tau, which is therisk aversion parameter times probability squared.And this is what I want to maximize, with the constraint that the position that Ihold in both the risk-free and the risky asset should add up to one.That is it must be a portfolio. So now let's go to solver.If you go to solver, here's the optimization problem that has been set up.The objective is the orange cell B31. I'm going to maximize that by changing theposition that I am holding, subject to the constraint that T21, which is the sum ofthe positions, must equal M21, which is just.Set to be equal to one. You solve this, and you end up gettingthat the optimum position is what is listed over here right now.I put 32% of my initial dollar in the risk-free asset, and the remaining.68 percent is the dollar amount that I'm going to be spending in the risky assets.So in the module, in the theoretical module we said that no matter what tau isthe only thing that the investors are going to do is select a certain amount toput in the risk free asset. Take the remaining amount and put it intoone particular portfolio that I was calling the sharp optimal portfolio.So in this work sheet I'm going to numerically show you that this is indeedwhat happens. So in the rows b 34 through 39, what Ihave done Is I've taken the risky positions.So here, the green cell here, is simply a repeat of the risky positions.It's B21 all the way up through I21. This is, this is the position that's therein the last risky asset. I'm taking the sum of those positions, sohere's just some of the whiskey positions and remember the codes the total sayingrisk[UNKNOWN] must add up to one I know that I put 32 cents of my initial dollarsinto the risk three assets and therefore 68 cents what must be sitting in the riskyasset is exactly what this number is. I'm going to take these risky positionsgoing to normalize them by the sum to get a portfolio.And this is the sharpe optimal portfolio. I'm going to run this optimization againto convince you that no matter what tau is the optimal portfolio, the sharp optimalportfolio that I end up getting from the calculations exactly the same portfolio.So lets do that and then I'll go forward and show what happens with the sharperatio and so on. Okay, so I'm going to change the taoperameter to something larger. So let's say we may get to .2.So in the risk inversion parameter tao goes up.I don't like risk and therefor I'll Tend to put more money into the risk-freeasset. So this 0.32 should go up.But the portfolio that, of the risky asset that I'm going to hold should remain thesame. The only thing that should change is theamount of dollars that I put into the risky asset versus the risk free asset.So let's do this optimization. We'll call solver again.Click on solve. It crank up and now it gives you ananswer. So instead of 32%, now we are putting 66%of your initial dollar into the risk free asset because your risk aversion parameterwent up. 34% is the amount that you're going to putin the risky assets. The risky asset positions have changed.But once you normalize it by the sum of the position of the risky asset, you againget back the same portfolio. These numbers have not changed.So here I'm numerically verifying for you what I theoretically told you, that allthat people are going to do in a market where there is free asset, is to diversifybetween the risk free asset and the Sharpe Optimal Portfolio.Now let's just do some calculations on the Sharpe Optimal.Portfolio. Here I'm listing the excess return on thesharpe optimal portfolio. I simply take the positions in the sharpeoptimal portfolio multiplying them by the expected return on the various aspects andsubtracting from their, form that sum the risk free rate.Here is the volatility, same expression as before.And the ratio of the excess return to volitility is the sharp ratio.So the sharp ratio for this market turns out to be .76.So the point of this particular worksheet was to show you how to construct theoptimazation problem for a market with a risk, Risk free asset.Argue to you numerically, that the Sharp optimal portfolio always remains the sameregardless of what Tau is. In the next worksheet I'm going to repeatsome of these calculations. And then show you how to compute asecurity market. See is again the same story.I have the assets and now I'm ignoring completely all the calculations that wehad done and shown you, going to show you a direct way of getting to the sharpeoptimal portfolio. Here's the risk free rate, here now arethe excess return. Mu hats as I'm going to call them in my,text modules which is as simply take the expected return and subtract the risk freerate. So that's what I'm doing over here.In order the calculate the Sharpe optimal portfolio, I know that the position thatI'm going to hold are going to be V inverse mu_hat.So the quantity over here is just in-, v inverse mu_hat, that's the calculationthat is being done here. If you click on this, it's going to be theinverse of this matrix times mu_hat that will give you the answer.So that's the positions, still not a portfolio.I take the sum of those positions. And I end up getting 1364.93.I divide out by this sum to get a portfolio.And the portfolio that you end up getting, exactly the same one that we saw in therisk-free frontier version. Mean excess return volatility is theoptimum Sharpe ratio to be 0.76. Now what I've done here is computed thebetas. What is the BETA?Beta is the correlation between the asset, and the shop optimal portfolio.If you work through the calculations, what it's going to be doing is taking thecorresponding, the rule of the variance, co-variance matrix, or equal.Equivalently the column of the variance co-variance matrix corresponding to thatparticular asset and multiplying it to the sharpe optimal portfolio.So if you look at this cell what has been done is its taken the column, I take thesharpe optimal portfolio, multiply them together that'll give me the co-variancebetween the particular asset and the sharpe optimal portfolio.Divided by the volatility of the shop optimal portfolio, that gives you thebeta. Now why am I doing this with respect tothe shop optimal portfolio whereas in the notes I'm going, I was telling you thatthe beta is defined in terms of the market portfolio?This is because I've already argued to you in the theoretical part of the module thatthe shop optimal portfolio is in fact the market portfolio.And therefore in the theoretical calculation that we want to do in thissheet. I might, might as well replace the Sharpoptimal portfolio for the market portfolio, that's what I've done.I've computed the beta by looking at the covariance.Of the particular asset and the shop optimal portfolio divided by thevolatility of the shop optimal portfolio. These are the not, these are the differentbetas, some of them are positvely correlated, some of them are negativelycorrelated. Here is a positive correlation.Positive and all of these are negatively correlated to the market.What do I do in the next line? I look at the implied return, how do Ilook at the in-flight attorney nine use the security market line's.You click on any one of them. If you look at the excess return must beequal to the excess return of the sharp optical portfolio or equal to the marketportfolio times the beta of the assets so the implied returns should simply be B33which is the beta times the excess return in the market or equally in thisparticular case the excess returned shopped optimal portfolio.I'm going to compare that with the excess return that I'd previously computed Soit's 1.65. If you look at this error this is going tobe what is the applied return, minus the excess return.And that's what I'm putting in this cell down below.And it turns out that for this particular market, all these numbers turn out to bezero. For those of you who have been carefullylooking at my numbers that I plotted in the text module you'll see that for assetone and asset seven it doesn't follow the line exactly but here you're getting allthe values to be equal to zero.the difference between these two is thoughtfulI showed you in the notes were based off of Matlab in math lab has a higherprecision than Excel It actually brings up an interesting question.If the precision of the program that you're using to compute numbers can make adifference between whether a particular asset is efficient or inefficient.That's a very non-robust or fragile way of thinking about mean variance portfolioselection. It tells you that mean variance portfolioselection, in some way when you implement it, you have to be very careful.You have to make sure that numerical errors don't play a role, you have to makesure that the statistical estimation errors don't play a role.And that's something that we're going to come to in the modules that refer to thepractical Details of mean variance portfolio selection.There's one thing else that I w-, I want to mark out here before we leave thisexcel module. If you look at the sharp optimalportfolios, some of them are positive components, 1.25 0.12, 0.2, 0.04.But then they have negative components. Minus .11, minus .05, minus .1 and so on.Now, I have argued to you if the markets are in equilibrium, if everybody's a meanvariance optimizer, then everybody holds a sharp optimal portfolio and therefore themarket portfolio is a Sharpe Optimum portfolio.Now if everybody constructs their portfolio using the sharp optimalportfolio then everybody is going to short in this particular case internationalbonds and say US small cab growth. If everybody shorts these 2 assets themarket can never be in equilibrium. So here is an example of data.Which gives you a Sharpe Optimum portfolio that cannot market in equilibrium and ifthis data is representative of the market you could easily argue that one of thebasic assumptions besides capital asset pricing model which is that the marketshould be in equilibrium is violated..

## 004.Capital Asset Pricing Model

### 006. Capital Asset Pricing Model

In this module, we're going to bring together all the results that we havegenerated from mean variance portfolio selection from market with a risk-freeasset. And use that to define a model thatconstructs prices for assets. And this model is going to be called aCapital Asset Pricing Model. So, in order to connect the Sharp optimalportfolio. There's something that's happening in themarket. Let's define a new portfolio.And the portfolio that I'm going to define is something called a market portfolio.The market portfolio is defined as the portfolio where you take the Ci.And then you normalize it by the sum of all the capitalization.So, the i-th component of the market portfolio is simply Ci divided by the sumof all the Cj's, so these all add up to 1. In fact, they are all greater than equalto 00 as well. Let mu m denote the expected net return onthe market portfolio. It's simply mu I times XMI summed, of Igoing from 1 to D. And let sigma M denote the volatility ofthe market portfolio, as before it's this quadratic function, take the square root.Now let's connect up how this market portfolio relates to what investors aredoing. Suppose all investors in the market hadmean variance optimizers. And all of them will invest in the Sharpoptimal portfolio as starred. Let w super k denote the wealth of thek-th investor. Let x0 k denote the fraction of the wealththat the k-th investor puts into the risk free asset.Then the total capitalization of the i-th risky asset is simply going to be the wk,the wealth of the k-th Investor 1 minus x0 k.This is the fraction that is going into the risky assets.Times s star i, why s star i? Because I'm looking at the capitalizationover of just the i at asset. And what are the summation k over?This is over all investors. The thing that I want to do focus on, isthe fact that this, this summation here, over all investors, doesn't depend on thes star. So, if I write it differently.I can simply take that s star i, and pull it out of the bracket.So, this s star i, I can pull it out of the bracket and just write it over there.What does that mean? That means that if I do this calculationto compute the market portfolio, I will get that the market portfolio is nothingbut the Sharpe optimal portfolio. This should not be a surprise.Everybody's investing in the same Sharpe optimal portfolio, and therefore thecapitalization should be completely related to the Sharpe optimal portfolio.If I re-normalize the capitalization to get the portfolio, I should get back theSharpe optimal popular portfolio. This is great, why is this important?This is important because the sharpe optimal portfolio depends upon expendedreturns, depends on covariances. These are quantities that are hard tocompute. On the other hand xm is a marketportfolio. They're relatively easier to computer.I can go and calculate out the values of the various capitalization.And it'll give me a portfolio that will have, will have some insight about theefficient frontiers. Okay, now we want to go further and seewhat that means. So, capital market line is another namefor the efficient frontier. Now what we're going to do is remember inthe last module we showed that the efficient frontier was a line that goesfrom the risk free asset through the shop optimal portfolio and all the way through.Now, it's a line that goes form the risk free asset through the market portfolioand all the way through. This efficient frontier is going to be theexcess return on the market portfolio, divided by the volatility of the marketportfolio. Previously, we had computed this slope asthe excess return on the sharp optimum portfolio, divided by the volatility ofthe sharp optimum portfolio. It's also the maximum achievable shoppingoperation. This quantity is also frequently calledthe price of risk. Everything that is efficient, must lie onthis line. And if you take on a certain amount ofrisk, this capital market line tells you what is the, that you must demand.It can be used to compared projects. Here's a simple example, suppose the priceof a share of an oil pipeline venture is $875 right now.It's expected to yield $1000 in one year, but the volatility is 40%.It's very high volatility. The current interest rate is 5%, theexpected return, rate of return or the net return on the market portfolio is going tobe mu M equal to 17%. The volatility of the market portfoliosigma M equals 12%. The question is, is this oil pipelineworth considering? Should one invest in it?Another way of asking the same question is, is this oil pipeline venture on theefficient frontier? Because if it's not, I should not beinterested in it. So what's the return that I get, what isthe net return that I get on this oil pipeline venture?It's 1000 divided by 875 minus 1, it's approximately 14%, what is the return thatI should demand for taking on the volatility?Sigma is the volatility of this oil venture, this is the slope of the capitalmarket line. The capital market line starts off fromthe point RF. Just to remind you, it's a straight line,starts from the point RF and has a slope M.So if I look at some point sigma, I should demand this return, which I'm labeling asR bar in order for it to be efficient. Plug in the numbers.Rf is given. R, r, this shouldn't be on rm.But mu m, mu m is given. Sigma n is given.If you plug in all of this, then in order to take on the risk of 40%.You should be compensated at a rate of return or a net rate of return of 45%,which is way higher than the 14% that the oil venture is giving.Therefore, the oil venture is not efficient and should not be considered.Now what we want to do is take this idea that the market portfolio is there and tryto inffer asset returns from the market returns.So the way we going to do it is think about the fact that every asset is in facta portfolio. If you look at the j at asset, it's aportfolio. It just corresponds to investing the onedollar in the j at asset, and nothing everywhere else.For now let's consider, the set of portfolios that I could generate bydiversifying between the j at asset. Okay, and the market portfolio.So I put an amount gamma into the j at asset and amount one minus gamma into themarket portfolio. The return on this portfolio is going tobe mu gamma, is an expression that gives you gamma here, is the volatility of theportfolio, gamma squared. This is the, this is the volatility that'scoming from asset j, this is from the market.This is of course volatility that's coming from the market and the portfolio.So what have I plotted on this first? I plotted the green line, which is theefficient frontier with the risky asset. The blue line, which is the efficientfrontier, frontier with only risky asset. And then this dotted black line is theefficient frontier. It's the frontier that is generated bydiversifying between the J asset and the market portfolio.So this dotted line must lie below the efficient frontier of just a risky assetbecause the market portfolio is just a risky asset, the j at asset is just arisky asset, so everything that's going to be here is going to be below that.But now what happens? Notice that for gamma equal to 0, this,the dot, the red dot belongs to the efficient frontier corresponding to thisblack line, because gamma equal to 0 gives you the market portfolio.The market portfolio is an efficient front, an efficient portfolio.It also lies on the efficient frontier of a market with a risk-free asset.So all of these three curves are tangent at the same point.I know the slope of the green line. That I, also know that the same slope mustbe equal to the slope of the blue line must also be equal to the slope of thisdotted black line and I am going to use that to compute what the returns are goingto be. The firmer the market, the capital marketline is clearly noted; just mu r divided by r j divided by sigma.Now we want to compute the slope of the frontier generated by the asset j in themarket portfolio sigma M. So that's the slope of this, this blackdotted line that I want to compute. So D mu over D sigma.But I don't know how to directly compute it, so I take, take this chain rule andwrite it as d mu gamma divided by D gamma, D sigma gamma divided by B gamma.Why do I put this mu gamma and sigma gamma here because these are functions of gamma.The D gammas cancel, I get back the same thing, but this is something I cancompute. This expression is exactly equal to this.This denominator is a much more complicated expression, and this is theexpression that you end up getting. You're not going to be responsible forcomputing out what that expression is. This is only for the derivation that Iwant here. If you compute all these expressions andsubstitute gamma equal to zero, which is the point that responds to the marketportfolio. You'll get an expression that this ratiois just mu J minus mu N, divided by sigma JM minus, sigma M squared over sigma M.If you equate the slope, this slope that you get, to that slope, you end up gettingand rearrange the results. You end up getting that the excess returnon the j at asset, this is nothing but mu hat j.Must be equal to the excess return on the market, mu hat m.And they are related by a quantity which is the covariance.This is the covariance of the return on the j at asset, with the return on themarket divided by the median of the return of the market.And that is called a beta of asset j and this full pricing formula is called theCapital Asset Pricing Model. Towards the end of the last module, I saidthat returns in this market should be determined by just one return becausethere's only one portfolio everybody is investing.And this theorem says exactly that return on any asset, the excess return on anyasset is determined by just an excess return on the market portfolio.This one thing determines everything. Now let's connect this story, becausethere's a beta floating around. It seems like it should be connected tolinear regression. So let's connect it to linear regressionand see what we end up getting. So suppose we take the random excessreturn. So Rj here will denote the random excessreturn on asset g, not the expected return and regress it on the excess marketreturn, which is Rm minus Rf. Here's the regression formula.On the left hand side is the even variable that I'm trying to regress.On the right hand side is the variable r minus r f on which I'm trying to regressit. Alpha is the intercept, beta is thecoefficient, and this is the residual noise.The coefficient beta is exactly the beta that we computed sigma i m square dividedby sigma m squared. The in, intercept alpha j, there's anexpression for it. It's simply going to be the expectedreturn on the asset to get expectation on this side, to get expectation on thatside, subtract it, whatever you get, that's going to be the alpha, because theexpectation on the residual noise is zero. So mu j minus rf minus beta mu m minus rf.Residual sigma epsilon j and r m minus r f are uncorrelated.The correlation between them is 0, so all of this is just regression theory.I've not added any financial economics or financial engineering there.Now I'm going to add it in. I know that capital asset pricing model istrue. What does that mean?That means that this difference is exactly equal to 0, which means that the alpha jon every asset is equal to zero. And the effective relations here that Iend up getting is at the random return on asset j, excess return on random J is betatimes the random excess on the market plus epsilon j.So now let's look at the variance. The variance of this quantity is nothingbut the variance of just the f of j because Rf is a constant.Epsilon j and the excess return are uncorrelated, so therefore you end upgetting beta squared, variance of rm minus Rf, which is nothing but the variance ofthe market, plus the variance of the residual.Now let's, for a moment, compare this expression.So here's the expression for risk. The expression for return says mu hat j,which expected return on asset j must be beta times new hat m.You are taking two components of risk here.The total risk to your portfolio has two components, has one component whichcorrelates with the market because of the beta And that's called, market risk.The rest, the leftover risk, is called residual risk.And if you look at what return that you're getting for that amount of risk it justdepends on the market risk, just the beta part.The residual part you don't get compensated for it.What does that tell you? It tell you that this residual risk shouldsomehow be diversifiable by looking at a, a properly diversified asset we should beable to get rid of this. Because if we couldn't get rid of it andwe had to take on this risk. The market should have compensated us,for, for taking on this risk. But the market does not, which means thatthis residual risk is diversifiable. The market risk is not, here's another wayof looking at what CAPM tells you. We did that in the capital asset pricingmodel, via the capital market line. Here's another way of looking at theinside accounts from the capital asset pricing model.This is called a security market. This says that if I plot the historicalreturns of an asset, with respect to this other quantity.I should get a straight line, why? Because we just said that mu j, must beequal to rf plus the beta of that particular asset, times mu m minus rf.So this shouldn't be rm, but mu m and therefore we expect to get a straightline. And if you dig the 8 asset classes thatwere there in the spreadsheet that was given to you and [unknown] out thequantity over here. And in a separate module, I'm going toshow you how to compute this line using the data in the spreadsheet.You'll end up getting that this is exactly, that those assets fall prettymuch under straight line. The line there's one asset that fallsbelow. What does this insight tell you?You might want to pose the video here for a moment to try to understand what is,what is the information over here? The story is, all of these assets aregoing to be on the straight line, because they are all efficient.The 7th asset, and, to some extent, the 1st asset, is inefficient.And therefore, it falls below the security market line.You only want to hold those assets that fall on the line, or sometimes above theline. So why the discrepancy?Because mean, cap m and mean variance is not always true.So the security market line can be used to identify inefficient assets, and assetsthat might be mispriced. The assumption that are underlying CAPMare all investors have identical information.Not true, all investors are mean variant optimizers or at least their returns arenormal. Not true, the markets are in equilibrium.Again, not true, all of these assumptions are not true, and therefore you don'texpect that all the asset should fall in the security market line.Many of them will, but some might lie below, some might lie above.And so, how does one leverage deviations from the security market line?There are two ways of looking at it. One way is to compute the Alpha forparticular asset. Remember We said a few slides before thatif CAPM is true, the alpha is equal to 0. If alpha is positive, it means that, thatasset is, has been mispriced low. And therefore, we should buy it.Because we expect to get higher than expected returns from that asset.Alpha is negative means that mis, asset that as it has been mispriced high, and wemust short sell it. Because later on the return will catch upand will make a difference. So alpha, alpha positive will correspondto this space. Alpha negative will correspond to thisspace. So alpha positive here alpha negativehere, we don't like the asset down here we need to short them.The asset over here we like them we have to hold them long.Another way of getting to the same concept of alpha is to look at the sharp ratio ofa stock. We remember a few slides before we havesaid that the market portfolio gives you the highest Sharpe ratio and therefore thesecurities market line corresponds to the highest slope.Now, if the assumptions behind CAPM are not true the there might be instances,short periods of time where things are not in equilibrium for example where someasset might be mispriced and may actually have a higher sharpe ratio In the market.Those assets we want to hold long. Those assets with sharp ratios below, wewant to short. The final slide here I want to show youhow to use CAPM as a pricing formula. Suppose there is payoff from an investmentin one year, is some random quantity x. And I want to compute what the fair priceof this investment is, then there net return from this investment is simply xover p. The beta of x is the covariance of rx withrm and sigma m squared. If you plug in the expression, you willget, there is a covariance of the pay of x with rm divided by the variance of themarket times 1 over p. So this p is actually unknown, we aretrying to compute out what the price is going to be.Supposed CAPM holds, then mu x, which is the expected return must lie on thesecurity market, that line. So mu X must be equal to RF, plus beta ofthat payoff X, RF minus RF. I plug in the formula.I have one unknown P. I have one equation.I solve for it by rearranging terms, I end up getting that P must be equal to theexpected value of the payoff, discounted back, which kind of makes sense.This is what you would have said, even if you didn't know CAPM, take the expectedvalue of the payoff, discount it one period before, one year before, at therisk free rate. Plus another term which correlates withreturns on the market. And this again, this shouldn't be Rm butMu M. It's going to be the expected return onthe market. But the thing that I want you to focus onis the fact that the price goes up, when the correlation, of the payoff is negativewith the, with respect to the market return.Which means that if the payoff is such, that, it pays on, in, in situations wherethe market is low. Then the price that somebody can demandfor that payoff turns out to be high. Does that make sense?You might want to pause and think for a moment.So in situations where the market return gives you a very high return, there's verylow demand for this particular asset. If it's positively correlated with themarket, the asset will not have a very high demand because I could simply investin the market portfolio and then do not take on any of the residual risks.So it's efficient for me to just put my money into the market portfolio.On the other hand, if there is a particular asset that gives me returns insituations where the market gives me low returns, which means that the payoff frompartic-, this particular asset is negatively correlated with the market,then I might want to hold that asset, which means that the demand for that assetis going to be high, which means that the price that the seller could demand isgoing to be higher. And that explains why negative correlationwith the market results in a higher price for that particular asset stop here.

## 005.Implementation Difficulties

### 007. Implementation Difficulties with Mean Variance

In this module, we're going to walk through and identify some im,implementation difficulties with mean-variance portfolio selection.We're going to walk through 3 main ideas, one, what happens when there are parameteraddress. Two, what happens when you have to takenegative positions and you want to avoid short positions.And three, what happens when variance is not really the best measure for risk.There are many aspects of the implementation details of mean-variancethat one could focus on. We chose to focus on the three mostimportant ones. First, has to do with parameterestimation. The parameters that go into amean-variance portfolio selection problem in practical situations is never known.The true mean vector and the true covariance matrix of the assets isunknown. All we have is historical data, and wewill have to estimate these parameters using these historical returns.And as a consequence, we end up making statistical errors.For the mean vector, the data is often sufficient, but when you start estimatingthe covariance matrix, the data is never sufficient.The reason is, that this covariance matrix has ordered d squared independentparameters. In order to have sufficient data toestimate these d squared parameters, you have to collect returns over a very longperiod, and over this long period, the market parameters shift.So, you sort of are playing a game where you can never able to get enough data toestimate these parameters sufficiently. Moreover, the portfolio that you computeto allow to be very sensitive to estimation errors and we'll focus on thisin one of the modules. We're going to show you why this happens,how you could correct for it, and what are the current state of the art on takingestimates and constructing portfolios from them.They're also going to focus on how does one get negative exposures in the Excelmodule, that goes with the mean-variance theoretical module which showed you thatvery often, the optimal portfolio has short positions.Taking on short positions is very dangerous particularly because it has anunlimited downside. You can lose a lot of money because theprice could suddenly jump very high and you end up losing a lot of money on theshort positions and it's for this reason that it's not very often allowed forwealth managers. One way to get negative exposure is to usea leverage exchange traded fund, or a leveraged ETF.But if you use leveraged ETFs, you have to be very careful.And in one of the modules, we're going to focus on how do ETFs work, what are thedifficulties associated with ETFs, how should you interpret the returns of ETFs?Finally, we're going to talk about whether variance itself is a good measure forrisk. Mean-variance portfolio selection focuseson variance as a risk measure or equivalently volatility as the riskmeasure. Does it make sense to use this riskmeasure? What, what are the limitations ofvariance? What can you do to mitigate some of theselimitations is going to be the focus of another module.In this module, we will mainly focus on the issues associated with parameterestimation. And the starting point of this module isthat the true parameters that we are after, which is the mean vector and thecovariance matrix of the assets is never known.And we are going to use historical returns to compute estimates for mean var, meanreturn, and the covariance matrix. And the easiest way to do that is toestimate the mean return by the sample average of the returns over some period N.Once you have the sample average for the mean, you can compute the covariancematrix by just substituting instead of the true mean, the estimated mean, to get anestimate for what the variance is. What I've done on this plot that goes onthis slide is I simulated the returns using the mean vector and the covariancematrix given in the spreadsheet that goes with these modules, I simulated 60 monthsof data. And using those 60 months of data, Iestimated the mean. Each of these green dots on this plot arean estimated value of the mean using one particular simulation of 60 months worthof data. I'm only plotting the estimated mean forasset 1 and asset 2. The point that I want you to focus on isthat the estimated mean can often be very far away from the true mean.The true mean has been plotted on this plot with a red square.Here's where the true mean is. This is a valid estimated mean generatedfrom 60 months of data. And as you can notice, it's very, very faraway from what the true mean is going to be.What we do know is that if I estimate the mean and I construct the 95% confidenceinterval around it, so here is one particular value of the estimated mean,here is the 95% confidence interval around it.And because we are talking about two assets, this interval becomes an ellipse.It's a 95% confidence ellipse. Then, with probability 0.95, the true meanlies in the ellipse. So, in this particular case, the true meanbarely makes itself into the 95% ellipse. So, the question you should ask yourselfis, does parameter error matter? And in this slide, I want to tell you thatparameter error is often very serious for mean-variance portfolio selection.And what I'm describing on this is the same experiment that I described in thelast slide, taken one step further. I estimated the mean and the covariancematrix using 60 months of data. So, I take one sample from all those greendots that I showed you in that slide. I have a mean vector.I have a covariance matrix. So, I can construct an efficient frontierusing that data. I'm going to call that the estimatedfrontier. So, the green line here on this slide,this one, is the estimated frontier. It's the frontier that has been computedusing an estimate for the mean and estimate for the covariance matrix.The blue line is the true frontier. This is the frontier corresponding to theunknown true mean and the unknown true covariance matrix.The red line is, is labelled the realized frontier.What that means is I take a frontier portfolio, on the green estimatedfrontier, compute the true mean return on that portfolio and the true volatility ofthe portfolio and plot it. And the line that I get from doing that isthe red line. So, this diamond here actually gets movedto this diamond when you replace the estimated mean with the true mean and theestimated covariance matrix with the true covariance matrix.And as you can notice, there is a big gap between what the estimated return on thatportfolio is going to be and what the true return on that portfolio is.The estimated return is around 6.4%, and the true return, or the realized return ifyou were to use that portfolio in the market, would be close to 4.4%, a good 2%drop. Why does this happen?Is this generic or did it happen just for one of the samples?In this slide, I'm plotting the estimated frontiers corresponding to 5 differentsimulation runs. I simulated 60 months of data 5 differenttimes, computed the estimated mean, the estimated covariance matrix and I'veplotted the corresponding estimated frontier.The green lines on this plot are five different estimated frontiers and as youcan see, these frontiers are extremely unstable.Not only are the frontiers unstable, the difference between the frontiers and theestimated frontiers and the realized frontiers can also be very large.So, we want to understand why this happens.Why is there such a big gap between what happens in the estimated frontier and whatis actually realized? Why is the estimated frontier so unstableand is there anything that we can do to remove this gap and remove thisinstability? Why is parameter error so serious?In order to understand this, let's walk through a very simple example.Suppose I have two identical assets with mean mu and covariance sigma squared andcorrelation equal to 0, then the optimal investment for these 2 assets would be totake half a position in asset 1 and a half a position in asset 2.That's what would give you the least volatility.Suppose now that the estimate for these returns are slightly off their truevalues. So, I estimate the return on asset 1 to beslightly larger than the true value so it's mu plus epsilon.I estimate the mean return on asset to be slightly smaller than the true value, muminus epsilon. So, on average, I'm making zero error.On average, the estimator is very good. So, if you were thinking about theproperties of a statistical estimator, you would say that whatever the estimator isbeen used here, is pretty good. Across the assets, you're not making a lotof error. But the problem with mean-varianceportfolio selection is that after I estimate these parameters, I'm going tooptimize my portfolio using these parameters.So, what happens? I've estimated that the return on asset 1is slightly larger than the return on asset 2.And therefore, I will overweight asset 1 as compared to asset 2.If I'm allowed short positions, then I'm going to short asset 2 and actually startinvesting more, take more leverage on asset 1.But this is precisely the wrong thing to do.If I take the portfolio that I compute which overweights asset 1 and underweightsasset 2 and put it into the market, I would get a return where the overweightedasset is going to perform worse than expected, the realized return is going tobe mu, below mu plus epsilon. And the undeweighted asset, which is asset2, will perform better than expected. So, instead of having a return mu minusepsilon, this asset, asset 2, is going to have a return mu, which is an espilonlarger than the expected return which is mu minus espilon.And this performance, this gap between the estimated performance and the realizedperformance will become worse as more and more shorting is allowed.This is what accounts for the big difference between the estimatedperformance and the realized performance. The main difficulty is, we take theestimated parameters and then optimize. And this optimization procedure inflatesor maximizes the statistical errors in the parameters.There is a quote which sort of sums up the situation.Mean-variance results in error maximizing investment irrelevant portfolios.So, we have to do something in order to make mean-variance portfolio selectionpractical. So, one idea that might come out oflooking at this slide is that the performance becomes worse as we allow moreleverage. So perhaps, the idea would be to limitshort positions, not allow short positions at all.And then, let's see what happens to the performance.In this slide, I'm plotting what happens to the estimated frontier, which is thegreen line, and the realized frontier, which is the red line, when you have ano-short sales constraint. And as you can see, that the realizedfrontier becomes very unstable this has a large part of the curve down here which isactually inefficient. And the reason behind this is because thefeasible region for the portfolios now has a corner.So, if this is x1, that is x2, you want x1, x2 to be grater than equal to 0, soyou end up getting a corner in the feasible region and this corner causesproblems in portfolio selection, it causes instabilities in portfolio selections.As you add more constrains, maybe you have some asset sector constraints, maybe youhave some constraints on how much money a particular sector can have and so on.All of these become linear constraints. All of these induce more corners and moreinstabilities. If you want to get at what the no-shortsales constraints was doing, which is to limit leverage, the better thing to do isdirectly put a constrain on leverage. And if you put a constraint on leverage,you end up getting performance shown up in this curve.Now, the realized performance of the portfolio is pretty close to the expectedperformance. The gap between these two is small.But the gap between what is expected and what is realized, this gap is still verylarge. So, I expect to perform on the green linebased on the data. I get the real, realized performance isgoing to be the red line. Remember, this blue line is actually notknown in practice so even though the true performance and the realized performanceare very close, I have no way of knowing how well I'm performing.So, leverage constraints do work well in practice but still, the estimated frontieris very bad and so there's needs to be some work in trying to bring that down.The state of the art right now is something called robust portfolioselection. In the robust portfolio selection, whatone does is removes the target constraint, which is imposed with respect to theestimated value of the mean and replaces it by a target return constraint which iswith respect to the worst possible mean in the confidence region.So, let Sm denote the confidence region for the mean.A few slides back, I showed you that the confidence region is an ellipse.So, instead of using a target return constraints, which says to take theestimated value of the mu transpose x and in, insist that, that should be greaterthan equal to r, we'll going to replace it by these constraints.And what do these constraints say? It says, you choose your portfolio x, thereturn that you're going to get is going to be the worst possible return in theconfidence region. Any point in the confidence region ispossible and, therefore, this worst return is something that you could possibly seein the market. And now, instead of that constraint on thetarget return, I'm going to put a constraint that this minimum value must begreater or equal to r. I can do portfolio selection with thisconstraint. It's a little bit harder but not muchharder. And now, the picture I end up gettinglooks like the plot here. The estimated frontier starts coming down.Why does this happen? This happens because now, I'm putting theworst case. So, I have estimated value of mu, thiscould be the estimated portfolio performance.But because now I have put the worst case constraint, this gets dragged down.The realized performance also becomes bigger than expected.So, that starts getting pulled up and therefore, the gap between these twostarts to become very small. There are issues with this technology.You can sometimes get portfolios which are not very interpretable and therefore it'shaving a little difficulty getting fraction.But over time technology either directly or some version of this technology islikely to become very practical. All of these methods were focused ontrying to improve the optimization strategy.There is a flip side to this methodology, where one tries to improve the estimationstrategy. So, here's, are some methods that peoplehave used to improve parameter estimate. One of the most popular methods areso-called the shrinkage methods. And what one does in these shrinkagemethods is that one shrinks to some global quantity.These were introduced by Charles Stein in 1961.There's a paper by James and Stein, and more recently, Ledoit and Wolf haveextended this to the case of covariance matrices in other circumstances.So, let's take the case of the mean. Earlier, I would have estimated each ofthe asset means separately. So, mu est i stands for the estimated meanfor asset i. Now, in the shrinkage technology, insteadof just estimating this asset mean, I'm also going to estimate a global mean,global average mean on the assets. And there is a reason why I put thisestimation outside this bracket. And the reason for that is when I estimatethis quantity, I don't simply take the estimate for all of the d assets and addthem up. I assume that all the assets have the sameexpected mean and use the data of all the assets to estimate that mean.As a result, I have more data when I'm estimating the total mean, than when I'mestimating a given assets mean. As a result, I expect that the error inthis global mean is smaller. So, error is smaller.And the error is larger in individual means.Now, this shrunk estimate, what it does is it takes the estimate for a particularasset, estimate for the global one, let's just call it mu bar and it moves on thisline, some element alpha. When alpha is equal to 1, it's up here.When alpha is equal to 0, it's down here. For some intermediate value of alphabetween 0 and 1, it's some point over here.This one has a very small error. That one has a bigger error.And when you shrink, you end up getting that the error at this point would besmaller. The tradeoff is as you, as you decreasealpha and start coming closer to the global mean, you have less informationabout what the asset is going to do, but you have less statistical error.As you increase alpha, you have more information about the asset is going todo, but you have more estimation error. So, somewhere in between is the bestthing. The next expression is a same kind of ideaapplied to the covariance matrix. So here, there shouldn't be estimated, butshrunk. This should be estimated down here.So, we have a shrunk estimate for the covariance.All it does is takes the estimated value for the covariance matrix and shrinks ittowards another covariance matrix where all the assets have the same volatility orthe same variance. Again, the idea is the same but if I wantto compute one variance for all the assets, I have a lot more data, I canestimate it better, and if I shrink the estimated covariance matrix towards thisglobal covariance matrix, I end up getting a better estimate, meaning an estimatewith lower errors. Another way to improve parameter estimatesis to use subjective views and the most popular way of doing that is the so-calledBlack-Litterman method. Recently, people have been starting to usenon-parametric nearest neighbor like methods to estimate performance and thisis because people have started going away from parametric models like mean-varianceand going towards more data driven models. And the idea here is to observe thecurrent return here r, go back into the past and find all those times t where thereturn is close to the current return. So, this is the current return, this isthe return at some point t in the past. You want to make sure that it's prettyclose to the current return. And for all those times t, find out whathappened to time t plus 1 and use that as sample of what is going to happen in thefuture. These non-parametric methods are currentlyat a very theoretical level, but there is a possibility that these methods willprovide a better way of doing portfolio selection in the future.

## 006.Negative Exposures, Leveraged ETFs, and Beyond Variance

### 008. Negative Exposures and Leveraged ETFs

In this module we're going to talk about how to get negative exposures in thecontext of mean variance portfolio selection.And in doing so, we'll introduce the idea of exchange traded funds and leveragedexchange traded funds. Short positions can often result in veryhigh returns. But short positions are very risky.A long position has a limited downside. The lowest price an asset can take is 0and therefore the largest amount of money that one is exposed to lose is the amountinvested. Short positions, on the other side, haveunlimited downsides. Short positions are created by sellingassets borrowed from a broker and these have to be repurchased and returned to thebroker at a later date. Since the price of an asset can becomearbitrarily large, the potential loss from a short position can also be arbitrarilylarge. So we need a product that has negativeexposure, meaning it gives me, it behaves almost as if it was a short position, buthas limited liability, limited downside. One such product is something called anexchange traded fund. Exchange traded funds are products thattrack the returns on stock indices, bond indices, commodities, currencies, etccetera. This table is something that I took frombloomberg.com and which gives you some idea of ETF's that are tracking variousindices in the world. So SPDR S&P 500 tracks the S&P 500 index.Ishares Russell 2000 is another one which tracks the FTSE.The QQQ, Japan, and so on. You can have exchange traded funds on anynumber of different things. Commodities, currencies, and so on.If you go to Bloomberg and look for ETFs, you will see lots of different ETFs.So these ETFs that are shown on this particular slide track the daily return onthe underlying index. So the daily return on the S, spiral, S&P500 would be the tracking the daily return on the SMP500 index.Etfs also allow you to leverage the returns indices.Leveraged ETFs produce daily returns that are multiple of the daily returns on theindex. Bull ETFs will return beta times the dailyreturn on the index and beta could have values 2 and 3 and so on.So po, pro ultra share as in P500 is a bull, ETF on the under, underlying indexwhich is acid P500. Pro SHORT is another ETF which is aleveraged ETF, but it turns a negative number times the daily return.So an inverse EDF returns minus beta times the daily return and beta can then takevalues 1, 2, 3, and so on. An inverse EDF is a product that can anegative exposure to the index ...with a limited liability.And why is the liability limited? It's because you tend, you're only exposedto the amount that you bought. You bought a 100 dollars worth of aninverse ETF, you can only lose a 100 dollars and yet at the same time get anegative exposure. But one has to be very careful when oneuses leveraged ETFs in constructing a portfolio.In the next few slides, I'll go over what kind of risks are associated withleveraged ETF's? Before we get down to explaining, thesource of the trouble with leveraged ETF's lets understand what happens, to thereturns on an ETF. And return on an ETF is the return on theunderlying index compounded daily. So on a long ETF, it's simply a, thereturn, the cumulative return or the gross return on an ETF will be a product of eachof the daily returns, just like a stock. The return on a leveraged ETF will be thedaily return multiplied by beta. So if you have a beta ETF and beta cantake values plus 2 and 3 or minus 1, minus 2, minus 3, The way you compute the grossreturn is you take beta times the daily return on the underlying index, that givesyou the daily return. On the ETF, you multiply it all the waythrough and you end up getting the gross return over TPS.The return itself is actually constructed by investing in the derivatives which areon the index rather than buying the stock s in the index.This daily compounding has consequences that are not immediately obvious.On the next slide, I'm going to work through and explain to you, how, dependingupon whether the ETF is simply a long ETF. Where it a leverage EDF often have anintuition about daily returns can go wrong.So, here's a simple example. Suppose you have an index.The index value today, let's time t is equal to 0 is 100.At time t equal to 1, let's say day 1, t equal to 1.It goes up to 105, and at time t equal to 2 which is day 2, it comes back to 100.So if you look at what happened over this period, nothing changed.You went up or, and then came down. So it really there was no level shift.The only thing that you experienced over this period is volatility.It went up and down. So if you had bought the index you wouldhave bought the index at 100. The value would have gone up to 105 andthen come down. If you had bought a long ETF what wouldhave happened? Suppose the current value of the ETF orthe index or Is 100. Then on day 1, the price of the indexwould have been 100 times 1 plus R 1, which is 105.Perfectly tracking what is going to happen, so it should be 100 here, it wouldhave gone up to 105 and what happens on day 2?The ETF will go down by 105, which is the current price times the return on day 2and you will drop back to 100. So, so far when you're looking at whathappens to just a plain vanilla long EDF and the index they're tracking.Now, let's see what happens to a bull ETF. A bull ETF let's say in this particularcase we take beta to be equal to 2. Twice bull 8 ETF.The current price of the index is 100. Over the 1st day the index returned 5%, sothe bull ETF will go up 10%. So it now, on Day 1 it's value will be110. It would have been increased by 10%instead of 5%. On Day 2, the index went down 4.76%, so R2was minus 4.76% and therefore, the, the amount by which it's going to go down,this should be 110. The price, the ETF will go down by 110times 1 plus 2R2. So this time it's going to drop down andthe net value that you'll end up getting here is 99.52.So we'll, you will not come back 100, you will go below it.So the bull ETF, over the 2 day period, actually lost money.Now, if you look at the mechanics, it's not the case that bull ETF is returningsomething that they did not promise. But if you were to interpret as if a bullETF was holding a twice leveraged position, then if the index went up from100 to 105 and came back to 100, you expect to come back again.And that intuition is wrong, you end up losing money because in every day you'recompounding by twice. So if you make money and next time youlose double, you end up losing much more than what you made over the first.Now let's see what happens to a inverse ETF.So in an inverse ETF, you start form 100. On the first day, you end up making moneyon the index. So the r one was 5%.And therefore, the inverse ETF will lose money, so it'll come down to 95, by thesame percentage but now it's come down. On day 2, the return is minus 4.76 %, andtherefore the inverse ETF is going to make money, it's going to be 95 times 1 minus R2. You'll end up getting to 99.52.Again, you have lost money. You started from 100, you ended up to only99.52. Moreover, the two times ETF and thenegative ETF both ended up at the same position.Intuitively, we would have expected something which is twice the ETF.And something which is negative ETF should not end up at a different position.One of them making money, the other one losing money and so on.But here we end up getting to the same position.The index did not lose money. The long ETF did not lose money.But the leveraged ETF as well as the inverse ETF Ended up losing money.All of this happens because the daily compounding leads to some unintuitiveresults. All the computations that I've shown onthe slide are correct in according to the rules of what the EDF returns are, butthey do not conform to the intuition that we have for these products.In this slide, we are going to work through the mathematical expression forthe return of a leverage ETF. The gross return on the static leverageposition in the underlying index is simply going to be beta times s capital T minusbeta minus 1 as 0 times 1 plus rt, so this entire expression.It's coming because we have to borrow beta minus as zero amount of money and time 0and the funding rate is R so this is the amount of money that I have to return attime capital T. So, that's the amount that I have toremove from what I would gain from selling my positions in the underlying text.Therefore, the return that I end up getting is approximately beta times.St over SC. Now, that should think of almost as asimple interest rate analog. So when I invest in a beta leveraged ETF,I know that the returns that I'm going to get on this ETF is going to be compoundeddaily. So I expect to see some sort of acompounding effect. So it will be S1 over S0.So I should expect a term like S1 over S0 to be the power of beta.S2 over S1 to the power beta and so on. And therefore all of these terms shouldcancel and it will end up getting approximately S capital T over S 0 to thepower beta. This is what I should expect based on thedaily return. Now, what truly happens with EDFs is thatyou get a term which corresponds to this compounding effect, which is S T over S 0to the power of beta. You get a term that corresponds to theexpense ratio which is sort of similar to this term up there.You get another term which is an expense associated with the ETF itself which is FTand then you get a third term which corresponds to, the volatility, of the wa,of the returns over the period 0 to T. Si over Si plus 1 squared, sum it from iequals 0 to n minus 1. And the reason I'm using N here and notcapital T is because N is the number of daily observations between time zero andtime capital T. So this term over here corresponds to thevolatility. And unless the term beta squared minusbeta is equal to 0. This extra term which corresponds to thevolatility drags the return down. So, there's a minus sign in front and thatminus sign drags the return down on the leverage EDF.Effectively, the leverage EDF is short on volatility and so in markets that areassociated with high volatility, we expect that the performance of EDF will be muchworse than the compounding rate that we expect take and therefore we think weshould expect that in markets with high volatility leveraged ETF's are not goingto preform very well. Etf's are generally designed for shortterms plays on an index or a sector and should be used in that way.Over long periods, leveraged ETFs do not work as one may expect, especially involatile markets. In this slide I'm just going to show you asimple example illustrating this point that leveraged ETFs during volatilemarkets do not perform as we expect them to do.In the first half of this slide, I'm showing you the returns on pro ultrashares. Oil and gas which is at twice ETF on theunderlying oil and natural gas index and DUG which is a Pro UltraShort oil and na,natural gas which is minus 2 times leveraged ETF.So if you look at what happened to the daily returns on these 5 days, they areroughly opposite of each other. And there's a little bit of a gap betweenthem because of the expense ratio. Because of the funding rate and so on.But roughly they're going opposite of each other.And so if the intuition over data returns carries over, then we expect that theseETF should give me opposite returns over a large period of time as well.But if you look at what happened to the returns on these or the price of thereturns on these EDFs from September 2008 to February 2009, the blue linecorresponds to DUG which is the same thing up here.The red line, or brown line, corresponds to DIG, which is the same thing up here.Up here, DIG and DUG are running opposite each other.Down here because of the volatility, both dig and dug get dragged down.The price of these, both of these ETFs get dragged down.And this is because ETFs, particularly leveraged ETFs, are short volatility.They do not perform very well when the volatility is large.

### 009. Beyond Variance

In this module, we're going to introduce ideas of value at risk and conditionalvalue at risk that define tail risk and, in doing so, we are going to move beyondvariance as a risk measure. Problems with variance.Variance is a risk measure which is appropriate for normal and otherelliptical distributions. By elliptical distributions, we mean,those distributions whose level sets of probabilities are ellipses.This is certainly true of normal but it's also true of other distribution.It does not, variance does not capture larger deviations from the mean.And in order to do that, we would have to use higher moments, like [unknown] and soon. It's also a symmetric measure, it equallypenalizes deviation above and below the mean.And that's okay for normal and elliptical distributions because their distributionis symmetrical around the mean. But for other kinds of distributions wherethere are, the distributions are not symmetrical, variance will not provide avery good representation of the risk of the portfolio, and we need other measuresthat can capture some of this. Meaning, they can capture largerdeviations form the mean and they can capture asymmetry about the mean.The value at risk is one such risk measure.The value at risk of a random loss L at the confidence level p is defined as thepth quantile of the loss. So, if you refer to this figure down here,I'm, on this axis, I'm plotting the loss, on this axis, I'm plotting the density ofthe loss. So, the magenta line is actually thedensity of the loss. The 95% value at risk for this loss isgoing to be the value here, it's approximately 9.5 and so on, such that theprobability beyond it is at most point, not 0.95 but 0.05.So, the probability on this side is 0.95. The probability beyond it is 0.05.And therefore, this point itself is 0.95 quantile for the value at risk.Value at risk, as you can notice, it only looks at the tail probability, andtherefore, it's a tail risk measure. It's increasing in p, so the value at riskat the 0.99 level is going to be greater than 0.95.So, value at risk at 0.99 will be somewhere down here.This will be the 99% quantile and therefore its an increasing in the p, thevalue of p that you provided. The conditional value at risk of a randomvariable L, is the expected loss beyond the value at risk level.So here, here are all the losses that are beyond the value at risk.When you compute a conditional value at risk, you take this loss, compute theconditional probability of these losses, and take the expectation according to it.So, in an expression, it's the integral from value at rest to infinity x times fxdx. So, this is just a plain expection of thetail and then I divided by the probability that things are going to be in the tail.So, this is approximately that expectation from value at risk to infinity, x fl x dxdivided by 1 minus p. It's also a tail measure.It's very easy to show that, in fact, the conditional value at risk is greater,always greater than or equal to the value at risk as you can see on this slide.The value at risk is the blue dotted line. The conditional value at risk is the reddotted line. And, in fact, this is, it's all you cantheoretically prove that they are going to be larger.Just like the value at risk, the conditional value at risk is alsoincreasing in p. Other names for conditional value at riskis tail conditional expectation in expected shortfall.For a normal distribution, we can easily compute the value at risk and theconditional value at risk. The value at risk is simply the mean valuetimes the volatility and phi inverse p and what is phi here, its the CDF of astandard normal random variable with mean 0, and volatility equal to 1.The conditional value at risk of a normal random variable is also can be written interms of the mean vector and the volatility, it's mu plus sigma times theintegral of the inverse CDF over the tail from, going from p to 1, normalized by 1over 1 minus p. The value at risk and the conditionalvalue at risk of a normal random variable is completely defined in terms of the meanand the volatility. Should this be a surprise?You might want to pause and think for a moment.The value at risk and the conditional value at risk are some properties of theunderlying distribution. For a normal random variable, thedistribution is completely defined if you tell me what the mean lecter is, or meanis, and the volatility. And since mean and volatility completelydefine the distribution, they completely define the value for value at risk andconditional value at risk. One of the reasons value at risk andconditional value at risk have become very popular is because you don't have to makedistributional assumption. As long as you have access to samples ofthe underlying loss distribution, you can compute value at risk and condition valueat risk from these samples. So, here's what you do.You take some capital N samples, IID sample of the loss, put them in anincreasing order. So, L paren 1, L1 is now the smallestvalue that you saw among these N samples. L2 is the next larger value that you sawin the N samples. Ln is the largest value that you saw at Nsamples. So, these are simply samples sorted inincreasing order. Now, find an index Kp, which depends onthe probability and is defined as the ceiling of the probability times thenumber of samples that you took. So, if the probability was 0.95, thenumber of samples N was 1,000, then Kp would have been 0.95 times 1,000, ceiling,which is 950. Ceiling, but since it's an integer, itdoesn't matter. So, the index is 950.So, you take your losses, put them in increasing order, compute this index Kp,then the value at risk is approximately equal to the loss, the Kpth term in thisincreasing sequence, it's the Kpth term in the sort examples.What about the conditional value at risk? You take the sum of all the samplesstarting from Kp all the way through the N, divided by N times 1 minus p, and thatis what is going to give you the answer for the conditional value at risk.So, there's another term N that is going to show up here.So, the sum of the N minus Kp plus 1 samples divided by 1 minus p times N.In the next couple of slides, I'm going to show you what happens as you change theunderlying return distribution. The experimental setup that I'm using isas follows. I computed the sharp optimal portfoliocorresponding to just the risky assets in this spreadsheet.I computed 10,000 samples of the loss or equalently negative of the return forthree different distributions. The first distribution was a normaldistribution with mean mu and covariance V.And mu and V were those that were specified in the spreadsheet.The second distribution that I use was a student's t distribution with mu equal to12 degrees of freedom. I kept the return vector the same as mubut I've rescaled the covariance as mu minus 2 divided by mu.The reason I rescaled the covariance is that after this rescaling, the variance ofthe losses remains the same as V. So, both distribution a and distributionb, both the normal distribution and the multivariate t distribution have the samemean and the same covariance matrix. The difference comes in is that the tdistribution has fatter tails, has higher moments that are not represented in thenormal. Finally, I took a third a distribution wasa mixture, a 75, 25 mixture of two normals.The first normal has a little bit lower variance, and the second normal addsactually one point time, 1.5 times higher volatility.And these numbers, 0.75, 0.25, 0.76 and 1.5 are chosen in such a way that if youlooked at the mean vector in the covariance matrix for this mixture ofnormals, you end up getting exactly mu and V back.So, all three distributions have the same mean and the same co-variance.The only difference is how is the return distributed beyond the first two normals.Students see distribution has fatter tails than normal, particularly when thedecrease of freedom are small so we expect the value at risk and the conditionalvalue at risk to be larger. The normal distribution with a covarianceof 1.5 squared times V has all of the volatilities 50% larger.And we expect that it will have a very large value at risk and conditional valueat risk. This mixture model models a situationwhere there's about a 25% chance of having very high volatility and we want tocapture and see what happens to the return distribution.So, this is the last histogram for the normal distribution.The 95% value at risk is 1.67%, everything is in percent.The 95% value at risk is 3.5, 3.15%. The value at risk is larger than the, theconditional value at risk is larger than the value at risk and the numbers are asthey are shown in the slide. For the t distribution, the 95% CVaR is4.58. If you compare it to 3.15, it's larger.And you can sort of, as I skip between these two slides, you can immediately seethat the data is getting fatter. The 95% VaR also goes up to 226.What happens about the mixture of normals? The conditional value at risk is 5.6.And again, if just flip between these two slides, you will see that the data isbecoming larger. And 95% VaR is at 1.93.So, what's interesting here, that if you compare these three numbers, the value atrisk is 1.67 here. For the t, it's 2.36, larger value.But the VaR actually goes down for the mixture distribution to 1.93.So, if you just focused on VaR, just focus on where the pth quantile is.You would prefer the mixture of normal distribution to the t distribution.If value at risk was the risk measure to use which is a mandated risk measure in alot of regulations, you would prefer to use the mixture of normals as compared tot. But if you look at the distribution of thelosses for the mixture of normal and compare it to the t, you are expect, youare likely to see very high losses in the mixture of normals, which is captured inthe fact that the conditional value of risk of the mixture of normals is a lothigher. And this is the reason why, one of thereasons why we are moving away from value at risk and going to conditional value atrisk. Value at risk is only sensitive to theprobability of losses. Conditional value at risk is sensitive toboth the probability of the losses and the actual location of losses.Where does the loss happen in the tail? As a result, it turns out to be a bettermeasure. It's also a measure which has some verynice properties associated with diversification, and it's a risk measure,which falls into the class of risk measures called coherent risk measures,and these risk measure have some nice properties.In later module on risk management, we are going to focus on the exact properties ofvalue at risk and the conditional value at risk.What are the advantages and disadvantages, and you'll get more into the details ofhow to do portfolio selection with that. I'm just going to leave you with someproperties of VaR and CVaR, proves of this, that this value at risk is that itcaptures the behavior. It can robustly estimated from the date,data, because it's a quantile rather than an expected value, it's not susceptible tooutliers. It's, I've already pointed out that it's,susceptible only to the pth quantile and not the distribution beyond it.And that is one the bad parts of value at risk.And it creates incentive for something called tail stuffing.The value at risk is not sub-additive therefore, diversification can sometimesincrease the value at risk, which is a problem when we're trying to do assetallocation. What about conditional value at risk?It all captures tail behavior, it's sub-additive and therefore,diversification actually reduces conditional value at risk.The mean conditional value at risk portfolio selection can be formulated andsolved very efficiently. And more and more, we are moving in thisdirection as opposed to mean variance. The bad part is that the, the conditionalvalue of risk is defined in terms of an expectation and therefore, it can be verysensitive to outliers. We'll return to this topic again in therisk management module.

## 007.Statistical Biases and Potential Pitfalls

### 010. Statistical Biases in Performance Evaluation

In this module we're going to discuss statistical biases in performanceevaluation. The goal here is not to build realisticmodels but rather stylized models, so simpler models, but models thatnonetheless will help explain to us that biases do arise, and that biases can besignificant. When we are evaluating the performance offund managers. Let's get started.Some fund managers claim to have special skills.What do I mean by special skills? Well for example they might claim to bevery good at picking stocks or they might claim to be very good at timing themarket. And what do I mean by timing the market?I mean the following. Maybe they know a good time to enter intothe market, in other words when to invest in the S&P 500 or the Euro stocks, orwhatever. And also they might claim that they know agood time when to get out of the market, when is a good time to sell.So, that's what timing the market means. This skill is often referred togenerically as alpha. And the term comes from the capital assetpricing model. If you recall the cap end that you'ld seenin the previous module. We know that the expected return on anasset is equal to the risk free rate plus beta times the expected return on themarket minus the risk free rate. I've added in here this additional termhere alpha. So this can be viewed in the context ofthe capital asset pricing model as the excess returner, the skill if you like,that a manager can earn on an investment. I don't want you to think that alpha isnecessarily associated with account fund. It's a generic term used to evaluateskill, whereby a manager can earn excess. Risk adjusted returns.Why is this important? Well, a fund manager who has alpha, or whohas skill, can often charge substantial management fees.And so what we want to know, is whether or not the skill is real.In general, it's very hard to tell, but you can still do some interestinganalysis, and that's what we're going to do in this module.We're actually going to look at this question from three differentperspectives. The first two perspectives, will requirethe binomial distribution, and so we're going to review a little bit about thebinomial distribution now. If you recall, we say that x is a binomialdistribution. Or we write x tilde Bin n p, if theprobability that x equals r equals n choose r, times p to the r, times oneminus p to the n minus r. And so x might represent for example, thenumber of heads in n independent coin tosses, where p is equal to theprobability of a head. The mean and variance of the binomialdistribution are given by these quantities here.The expected value of x is n times p, and the variance of x is n p times 1 minus p.You can also see from one that the probability that x is greater than orequal to r is equal to the sum of the probabilities that x equals r, x equals rplus 1 up to x equals n. And that's given to us by this summationhere on the right hand side. So, to see our first perspective on thisproblem, consider the following situation. Suppose a fund manager has a track recordof ten years and that this fund manager has outperformed the market in nine of theten years. The fund manager claims to have greatskill and that his fees should reflect this.What we want to know is, well how can we assess his claims?Does he really have great skill? So first analysis might assume thefollowing, in a given year he outperforms the probability p and under performs withprobability 1 minus p. And by the way, when I say outperform, Imean outperform relative to the risk the manager is taking on.So I'm talking about risk adjusted returns here.Outperformance or underperformance is assumed to be independent across years.If the manager has skill, then p is greater than a half.Otherwise p is less than or equal to a half, and the manager has no skill.So the first question that now comes to mind is the following.How likely is such a track record if the fund manager had no skill?Well to answer this, let x be the number of outperforming years.If the fund manager has no skill, then x is going to be binomial, with n equals 10,and p equals a half. We said that the fund manager outperformedin 9 of the 10 years. So, a track record as good as this wouldcorresponds to x being equal to 9 or indeed x equals 10.So we want to compute the probability that x is greater than or equal to 9.Assuming the manager had no skill. In other words, assuming p is equal to ahalf. That is given to us by our binomialprobability we saw in the previous slide. We can evaluate this easily in Excel orsome other piece of software, and we find the answer of 0.0107.So therefore, if the fund manager has no skill, then the probability of having atrack record as good as his, or better, is only 0.0107.So at this point, you might think it's fair to conclude, that the fund managerdoes indeed have skill. After all, you could think of this in astatistic setting, for those of you who are familiar with the statistics, you'd beaware of the concept of a p value. And usually a p value that's less than orequal to 0.05 would be assumed to be significant.So we've got a p value here if you like, of 0.0107, this seems significant.It seems unlikely in this case that the fund manager is no skill.Given the track record of 9 successful years out of 10.So that's the first perspective we're going to take.Here is a second perspective, suppose instead that there are M fund managers andthat the manager who claims to have skill has the best track record of thesemanagers. The questions that now arises is, doesthis change anything in our analysis? Should it change something in ouranalysis? To answer this suppose we start with thehypothesis that none of the fund managers have skill and that track records of fundmanagers are independent. There are two possible questions now thatarise. The first question is, how likely is thethird manager to have such a track record if all fund managers have no skill.Well, in this case, if we've identified the third manager in advance, then thefirst perspective gives us the answer. It would actually.Actually be 0.0107, as we calculated beforehand.The second question or possible question to, to ask, is how likely is the bestmanager to have such a track record if all fund managers have no skill?And now, what is the appropriate question here?Which of these two questions is more appropriate?This actually depends on our prior hypothesis.What do I mean by that? Well let's come back to this slide here.We've actually identified this manager here, this is the third manager.And this is the best performing manager of the M managers.And so what I mean by prior hypothesis is the following.Did we identify this third manager in advance?Maybe this third manager was our friend, or a cousin, or somebody else we specifiedin advance before we saw any data. If that is the case, then this question isthe more appropriate question. We've seen the manager in advance, we'reinterested in his performance, not because he was the best performing manager, butbecause he was the third manager or some manager we've seen in advance.However, if we're interested in the third manager because he was the best performingmanager, and that's why his track record has come to our attention, then theappropriate question is actually the second one.How likely is the best manager to have such a record, if all fund managers haveno skill? And this is because the reason we'reinterested in the third manager is not because he was number three in the list.But because he was the best performing out of all m managers.And that's why he came to our attention. So, it really depends on our hypothesis.Why are focusing on this manager? Is it because he was the third manager,we'd pre-selected him in advance? Or is it because he was the best manager,and that's why the manager's track record has come to our attention.Depending on which hypothesis is correct, we get a very different answer.With the first hypothesis, we see it's 0.0107.With the second hypothesis, for our interest in the manager is because he'sthe best performing manager out of M, the second hypothesis is the more appropriate.So let's answer this second question. We're going to assume none of the managershave skill. We're going to let z i be the event thatthe ith manager out-performs in r years or more out of the n years.We're going to let v be the event that the best manager outperforms in r years thatevent, or more. Then what we're interested in is theprobability of v. The probability of v is equal to 1 minusthe probability of zed 1 bar up to zed m bar.Now what is zed i bar? Zed i bar is the complement of zed i.So zed i is the event that the ith manager performs in r years out of n, so zed i baris the event that the ith manager outperforms.In less than r years out of n, so it's the complement of zed i.So therefore just to make sense of this, if the best manager is to outperform in ryears, the event that the best manager doesn't outperform in r years and more.Is equivalent to all managers. All m of them outperforming in less than ryears out of n. And that's this quantity over here.Because we're assumption that these z, zed i's are independent, and IID.I can write this as just the probability of zed 1 bar.Times the probability of zed q bar, up to the probability of zed m bar.Just keeping these separate. And these are all IIDs, so this is,there's m of them. And so I get the probability of zed onebar to the power of m. Now, recall, the probability of zed 1 bar.Zed 1 bar is the event that's the compliment of zed 1.So therefore, the probability of zed 1 bar is equal to 1 minus the probability of zed1. And therefore, I can plug in the numbers.I'm assuming, in this case, I believe, that m is equal to 20.And I know that the probability of zed 1 is 0.0107.Because I actually calculated this. Onto our first perspective.So this is for a fixed single fund manager.The probability of zed 1, we found to be 0.0107.So we need the probability of zed 1 bar, here, which is 1 minus that.Take it to the power of m, we get this number here, 0.1942.And actually you can easily see what happens.As m gets bigger, as we increase m, the number of fund managers in themarketplace. Place then actually probability of v willactually increase to one as m gets very large.What are our conclusions. Well our conclusions are as follows.If there are a lot of fund managers in the market, then the, the fact that oneparticular fund manager has a fantastic record, does not, in and of itselfconstitute evidence that, that fund manager has skill.After all, we have shown here, that with just 20 fund managers we would expect thebest manager to have a record of outperforming in 9 years.Or more out of 10 to recover probability 0.1942.And that's not a very small number. If we take m equal to 30 or 40, thisnumber will get bigger. And so even though we've assumed all thefund managers have no skill here. The fact that we're focusing on the bestmanager's track record. Suggests that the best track record, willbe good. So we haven't established evidence tosuggest that a particular fund manager has skill just because he's got a great trackrecord. It all depends on the hypothesis.How did we identify this manager? I should also point out that while we havefocused on the best manager here, we could also have focused on the second bestmanager or the third best. Manager and so on.If n gets sufficiently large, we're not going to just expect the best manager todo well. The second best manager will also have avery good track record. The third best manager will have a verygood track record. And so on.As long as m gets sufficiently large. And this is true even if all of the fundmanagers have no skill. Here's another perspective.This is our third perspective. Suppose again that all fun, fund managershave no skill. At the end of every year, fund managerswho have out performed the market that year, survive.And fund managers who have under performed in the market that year, get fired.Here's a question. After one year of this experiment, whatwould be the average track record of fund managers in the market?Well. It's got to be perfect.Only the fund managers that have a good year survive, so they will have a perfecttrack record. The fund managers that have an imperfecttrack record, in other words they under performed that first year, well they'vebeen fired, so they're no longer available, they're no longer in themarketplace so we won't see them. And so their performance does not enterinto our calculation of the average track record.And indeed you can look at this after 2 years, or 3 years you'll only see perfectfund managers in the market. So only perfect fund managers survive, andthey appear to have a perfect track record.And yet it's clear that in fact, that these fund managers have no skill.You could also generalize this in fact, as follows: you could imagine that fundmanagers who've outperformed in a given year will stay in the market with someprobability p. And that fund managers who'veunderperformed in the market will be fired with a different probability.And we can assume that fund managers who've under-performed get fired morefrequently than fires, than managers who've over performed.You could do that type of experiment, you could simulate that kind of system andwhat you'll still see is that the average track record of fund managers in themarket would actually be greater than a half.So actually they will appear to be a level of skill in the market, even though thatskill isn't really there. This is an example of what is calledsurvivorship bias. The reason being that some people havesurvived, they're the people who have outperformed in the market, and theyactually make the market look better. They look like the, the collection of fundmanagers look better than they really are. They've just survived because the poor andunlucky fund managers have actually Under performed and lost their, and lost theirjobs. So this is an example called survivor biasor survivorship bias. Its a very common phenomenon in financeand beyond and we're actually going to see some more examples of survivor,survivorship bias very soon. Now some final thoughts here.I've been assuming up until now that the fund manager or the fund managers have noskill. And you might ask the question, well, isthat fair? Is it fair to assume to begin with thatfund managers have no skill? After all, in practice there are somemanagers with skill. And that's absolutely true.There are some managers in practice with skill.I don't there are too many of them and certainly lots of fund managers may thinkthey have the skill but the reality is quite different.Nonetheless it is true that there are some fund managers out there with skill.That having been said, I don't think we're being unfair in assuming to begin withthat fund managers have no skill. And that's because it is theresponsibility of the fund manager to convince us that they have skill.After all, fund managers with skill try to charge fees to manage our money.So it's up to them to convince us that they have skill.It's not up to us to give them the benefit of the doubt and assume they have skill.So it's perfectly reasonable to start off with the assumption that they've no skill,and then to see where that takes us. And if we can find such a manager, is theresulting out-performance sufficient to justify the management fees?That is not clear as well. If the management fees are too large, thenthose fees are going to dominate the out-performance.That the manager provides and so in that situation we wouldn't want to invest withthe manager anyway.

### 011. How Should Average Returns be Computed

In this module we're going to discuss a varied topic of problem.Namely, how should average returns be computed?We'll see why this is an important question and why there can be differentanswers to this question. We'll also see what answer is moreappropriate to investors. Here's an example.Suppose an investment fund delivers the following performance.In year 1, they returned 20%. In year 2, they returned minus 10%.What is the average annual return of the fund?Well, it's going to be 20% minus 10% divided by 2, which is equal to 5%.So we can say the average annual return is 5% here.But suppose I change things just a little bit.Actually, I won't change anything, I'm going to give you a little bit moreinformation. Consider this example.The exact same fund, the exact same performances in years 1 and 2, plus 20%and minus 10%. But now I also tell you what number ofdollars were invested in the fund. In year 1 there was 1 million dollarsinvested in the fund. In year 2, there was 10 million dollarsinvested in the fund. Now I'm going to ask you the samequestion. What is the average annual return of thefund again? Well, it's not clear any longer becausethere's two possibilities. We could say it's 5% as before where wejust take the average of 20 and minus 10. Or we could choose to compute a dollarweighted average return. If you look at this, you can see there's 1million dollars, which received an average return of 20%.And there's another 10 million dollars which received an average return of minus10%. So if I look at the average return to eachdollar, then this is the correct answer. It's 1 million times 20% minus 10 milliontimes 10% divided by total of 11 million and I get minus 7.27%.So in this case the average annual return is actually much smaller.So we can see 5%, or minus 7.27%. And the question is which return is morecompelling if any? Why is this important?Well it is important because investors care about returns to their dollars.And so in fact you could argue that at the aggregate level, investors should becaring much more about a dollar weighted return, in which case this number is moresignificant. And so to emphasize this claim, considerthe following two situations. If you're an aggregate investor, in otherwords if you take all investors together and you asked them which would theyprefer, would they prefer this situation? Let's call this situation 1, or situation2. The difference between situation 1 andsituation 2, is that in situation 1, 1 million dollars was invested in year 1 andthat earned 20%. And $10 million was invested in year 2,and that earned minus 10%. Or the reverse of that is situation 2.10 million dollars in year 1, earning 20%. And one million dollars in year 2, losing10%. While I think investors in aggregate wouldper, far prefer to be investing in this situation here, because this is what willhappen to their dollars. Investors care about dollars invested,what's going to happen to their dollars. They don't necessarily care about averageannual return of 5%. If in years where the returns were veryhigh, they didn't have any dollars invested.And years in which returns were very low they had lots of dollars invested.What they care about is the return on their dollar.Here's another reason why investors should care about the total number of dollarsinvested. In financial markets, expected returnsoften decrease as the dollars invested increase.This is because the liquidity of a market, or the so called capacity of a tradingstrategy is not unbounded. Now this isn't always obvious to the smallinvestor who only invests in liquid markets and therefore does not move themarket. So, what I'm getting at here is a smallinvestor might buy some shares in an S&P 500 ETF.Or maybe they buy some foreign exchange. Those markets are extremely liquid, so asmall investor trading in those markets is not going to move the markets.In other words, the act of their trading is not going to have an impact on themarket price of those securities. This is not true in general for largeinvestors. The larger they are, the more they tend tomove a market. The more liquid the market, the more theymove it. And in this case the cost per securityincreases with the number of securities they buy.And the cost per security decreases with the number of securities they sell.So this implies that returns decrease on average as dollars invested increases.Let me give you an example. A simple example which is, might be agambling example. Suppose we've got 2 teams.We've got team A, and team B. Let's suppose, that the odds of team Abeating team B are 50%, and the odds of team B beating team A are 50%.And let's suppose that the market agrees on these odds, maybe you're going to Vegasand you want to bet on team A versus team B, you see these odds in the casino.You however think that the probability that team A will win is 75% and the team Bwill win is 25%. So in this situation you'd like to bet onteam A. But you won't be able to bet an unlimitedamount. Maybe it's not Vegas, may your friend isgiving you these odds. So your friend is giving you these odds of50% and 50%, but they'll tell you, sure you can bet but I'm not going to accept abet of more than $10. Well in that case the most you can bet is$10. And so in this case it's a very ill liquidmarket. There's not much capacity in the market,the capacity is $10, after which there's no ability to trade anymore.So believe it or not, financial markets behave like that as well.The more you trade in some of these markets, especially for big investors, themore you move the market against you. And so what happens is you tend to seedecreasing returns to dollars invested. Now the question of how to compute averagereturns is important. Depending on how you answer it, certaintypes of investing can seem more or much less attractive.An example of this is the hedge fund industry.On aggregate, they would prefer to report average returns over time.And in fact they do so. Now that's not to say the hedge funds arebeing dishonest, they're certainly not. One can just view it as being goodmarketing. Every industry markets and the hedge fundindustry is no different. So if they wish to report their returns asbeing average returns over time, then that's fair enough.However, we as investors should be aware of this and be aware that from ourperspective we care more about average net returns per dollar invested.So if we measure returns this way we might get a far different average return thanthat reported by say the hedge fund industry.And it's important to be aware of this, because there are very different,different ways of computing returns, and you get very different answers dependingon how you compute them. This has actually caused some controversyand debate. There are some financial blogs out therethat discuss this topic. A nice blog and a nice discussion of thistopic can be found at this URL here. And I'll encourage you to take a look atit and read this discussion. Here's another problem with averages.It's not a financial example but it is a nice example because it demonstrates howpeople can be easily confused by the way a question is worded.Sometimes the confusion becomes very apparent once it's explained, but ineveryday conversation, sometimes this, these issues go by us we don't reallynotice we're calculating the wrong quantity.So here's a question. Suppose I wish to estimate the averagenumber of children per family in the US. And to compute an estimate I do thefollowing. I sample n people randomly, maybe n willbe a very large number. Maybe it's a 1000 or 10,000 or 50,000.And for the i th person I determine x i, which is the number of siblings in his orher family. My estimate, c hat say, is then given bythe following. C hat is going be some of the XI's plus 1.So, this extra 1 is for the person that I sampled.So, the number of children in that family will be the number of siblings plus theperson I sampled. So that's x i plus 1.and then I divide byn. So, that's my estimate of the averagenumber of children per family in the US. Now let's ignore any minor problems thatyou might see with this sket sampling. There's a bigger question here.And the bigger question is does the sampling scheme have a fundamentalproblem? If so, in what way will c hat be biased?And how does this problem compare to the average return problem?So these are some other questions we are interested in as well.To explain to you why there's a problem with c hat, consider the followingsituation. Let's assume there's a universe of 5families. So this is family.We've got family number 1. This is the number of kids, or children,in each family. So family number 1 we'll assume has 4children. Family number 2 we'll assume has 3children. Family number 3 has 2 children, familynumber 4 has 3 children, and family number 5 has 0 children.So this is our universe. The total number of children is 12 and sothe average number of children per family is 12 over 5 which is equal to 2.4.So this is the correct answer. 2.4 is the average number of children perfamily in this universe. But if I use the sampling scheme in theprevious slide, where I sampled by child or by kid, I'm going to get a differentanswer. To see this note the following.There's a total of 12 children. So if I sample by child, then 4 out of 12times, I'm going to sample 1 of these 4 children.Each of these children will say 3 siblings plus themselves will lead to 4.I've got 2 families with 3 kids, so that's a total of 6 kids.So, 6 out of 12 times I'm going to sample a child from here or from here.Each of those children will say they've got 3 fam, 3 kids in their familyincluding themselves. 2 out the 12 times I'm going to sample 1of these 2 children. And each of these 2 children will say theyhave 1 sibling. So, 1 plus themselves will equal to 2 so Iget an answer of 2 here. And then 0 out of 12 times, I'll samplefrom down here and a reported number of siblings will be 0.So, I'll get a total here equal to let's see, it's 16 plus 18, 34.34 plus 4 is 38 over 12. And 38 over 12 is equal to 3 and 1 6th.So in this case, the way I compute the average here, by sampling by child, I'mgoing to get an average of 3 and 1 6th, and this is the wrong number.The average I want is 2.4. So what I've done here is I've actuallycalculated the average incorrectly. I want to know the average number ofchildren per family. So what I should be doing is sampling byfamily. Which is effectively what I'm doing downhere. Instead, the sampling scheme I gave to youon this previous slide, I'm sampling by person, or by child if you like.And by doing that, I'm getting this average over here.And in fact, I'm getting a number that's too large.And in fact, that's how c hat would be biased.I'm more likely to sample children from large families, as we saw here, so thosefamilies will over report themselves. They'll have, we'll see higher averagenumbers as a result. We'll get 3 and 1 6th in this case.And in fact, an easy way to see this is to note the families with 0 children willnever be sampled. So if we're ignoring all families with 0children it should be clear that our bias is upwards.And here's another problem that has been very topical recently.It concerns the controversy surrounding waiting times to get through immigrationat Heathrow Airport In London. This was a big news story last year whenmany people who were entering Heathrow airport, and had to wait a very long timeto get through immigration. So a lot of newspapers were writing inabout, writing about this problem at the time.It was definitely a source of controversy in Britain.And so people were interested in estimating the average waiting time oftravelers at immigration at Heathrow airport.One way in which this est, in which this average waiting time is estimated was asfollows. Sample 1 person every hour, compute thatperson's waiting time and then take the average of all these people.So maybe there is 16 hours in a day. We get x 1 up to x 16.We sample 1 person from each hour, find their waiting time, and take the average.And then report this as the average waiting time to get through immigration.The question here is, is this a good scheme?I'm not going to answer this question, but you can think about it.I will give you a hint, it's a bad scheme. And it has a fundamental problem which issimilar to the problem on the previous slide where we discussed ways to computethe average number of children per family.

### 012. Survivorship Bias and Data Snooping

In this module, we're going to discuss Survivorship Bias and Data Snooping.We've already discussed survivorship bias in an earlier module and we'll talk alittle bit about it again here. Consider the following investment.We're going to purchase an equi-weighted portfolio of the top 20 stocks in the S&P500. Note that the stocks are chosen and fixedtoday. In order to get an idea of how thisportfolio would perform, we decided to back-test it using historical data asfollows. We're going to get the last 20 years ofdata return data for each of the 20 stocks.On the first day, that is the first day 20 years ago, we're going to set up theinitial equi-weighted portfolio. If the stock didn't exist back then, forexample Google, then omit it from the portfolio and just form an equi-weightedportfolio of the stocks that did exist that day.Every month we're going to rebalance the portfolio so that it remains equi-weightedand we're going to take transaction costs into account.What we will then do finally, is that we will plot the annual net returns that isrt against t, where rt is the net reutrn to time t realised over the previous year.So we have the following question. Do you think the plot will berepresentative of the future performance of the investment?Well, we're going to get a plot like the following.So we're going to have time down here. So this is today, this is 20 years ago, sothis point is 20 years ago, this is also the 0% return so we've got r1, standingfor R one year so the one year return over here and, so any point in time are goingto get some sort of plot like this and for example at this point, the value herewhich is some value over here. This corresponds to the realized return aday t over the previous year. So back to t minus 1 year.The question is, do you think that this plot will be representative of the futureperformance of the investment? Well the answer is certainly not.Why not? Well, what we've actually done is we'veintroduced survivorship bias into this problem, and we've introduced an enormousamount of it because what we've done is we've picked our portfolio today here, andwe picked the 20 best stocks in the S&P 500.Now we go back 20 years ago, and what we've done is we're back-testing theperformance of an equi-weighted portfolio of these 20 stocks, but we've actuallychosen those stocks by implicitly looking into the future.We've gone forward 20 years to today, pick the best performing stocks.After all, the top 20 stocks in the S&P 500 have surely performed very well overthe last 20 years. And so we've actually introduced anenormous amount of buys into our back-test.This is equivalent to today to going 20 years into the future, picking the best 20stocks in the S&P 500, 20 years into the future and actually trading those stockstoday, that's an example of survivorship bias.It's an extreme example of survivorship bias, and it should be clear to everybodywhat we have done and why it is wrong. But actually survivorship bias crops up anawful lot in finance and not always as obviously as we've seen in this examplehere. So it needs to be born in mind byinvestors, risk managers and so on. People always need to be on the, on thelookout for it. So here's another example of survivorshipbias in action. It's called the football game scam.Sometimes it's called the horse racing scam, when the context is changed to horseracing. We're going to stick with the footballperson. On each of 10 consecutive Wednesdays youreceive a letter predicting the winner of a big football game the following Sunday.We're going to assume here that a football game is either won or lost, and that thereare no ties in a football game. Each week the prediction was correct.In week 11 however, a letter arrives but this time it seeks payment of $10,000before revealing the prediction for the next game.The question is what should you do? Should you pay the $10,000 or should youignore it? Well this is a, this is an example of ascam the answers you should ignored and the reason is as follows.So what's going on here is the following. The scam artist, the person perpetuatingthe scam has, playing the following game. In week 1, the scam artist had a totalpopulation of 2 to the power of 10 people. To half of this group he sent a lettersaying team A would win, and to the other half he sent a letter saying team B wouldwin. For week 2, let suppose that team A won,this means 2 to the power of 9 people saw a prediction in week 1 that was correct.He now splits this 2 to the power of 9 people again into two groups, half of themget a prediction for week, for team A winning, the other half get a predictionfor team B winning. If you come to week 3, and now you've got2 to the power of 8 people remaining, who actually were correct, or have got thecorrect prediction on week 2. And you keep going on like this until week1, week 1 there's only 2 to the power of 1 people remaining or rather week 10, Ishould have said. So in week 10 there's 2 to the power 1people remaining which is equal to 2, you were one of them.You received a letter saying team A would win, another person received a lettersaying team B would win. Presumably team A won which meant thatafter week 10 you were the only person and there's just one person remaining and thatis you. So you're the ultimate survivor here,you're the one survivor out of 2 to the power of 10 people who see the correctprediction 10 weeks in a row. There is no skill here, no skillwhatsoever. And so this is an example of extremesurvivorship bias, where you see the track record of only one person and that trackrecord is perfect, and it's your track record 10 weeks in a row of perfectpredictions. We're now going to discuss an example ofdata snooping. Data snooping arises in many context notjust in finance but beyond finance and very often the problem with data snoopingare quite subtle and hard to spot. So we're going to see an example here.A bank has 4 years worth of daily historical returns data, on the Dollar.British Pound exchange rate. It employs the following mechanism forgenerating a trading strategy. It first normalizes the entire return dataso that it has mean zero, and variance one.Now just to point out here, normalizing data is a standard and well justifiedstatistical technique in general. We're going to use 75% of the data fortraining, 75% of the data actually corresponds to approximately 750 returns.And that's because there's approximately 250 trading days in the year.So if you take out holidays and weekends. We find that the typical year has about250 trading days. So if you take 75% of 4 years, you'regoing to get approximately 750 trading days, or 750 returns.The remaining 25% of the data set, which corresponds to one year, so approximately250 days, is kept at what's called a hold-out test set.We're going to use this test set to evaluate whatever strategy is yielded bythe training data. The trading strategy appears to be a greatsuccess. On any given day it uses the returns ofthe previous 20 days to forecast the direction of the next day's return.However, the trading strategy performs very poorly in practice.The question is, why? So let's think about this for a moment.What we have done is we've split up our data set into training data and test data,so let the following be our training data, so we have about 750 observations in ourtraining data. So starting from one up to 750.So this is date 1, date 2, date lets say t minus 20.We've 20 days in between up to day t. Now imagine the following, so we said thatthe trading strategy is based on the previous 20 days of returns.So suppose we're here at day t, this is day t plus 1, and we want to know thereturn from t to t plus 1. Let's call this mean return, mu t to tplus 1. We've seen, let's say, mu t minus 20 up tot. So we know at day t, we know this quantityhere. This is known as a day t.,Suppose for example that this is greater than 0, maybe much grater than 0.What does that tell you about mu t to t plus 1.The return you expect between dates t and t plus 1.Well if you think about it you should see that this implies that mu t to t plus 1will be less than 0 on average, why is that?Well the reason is because of this normalization we did.We actually normalized the 1000 data points that have mean zero, so if all 1000data points had mean zero, and I've got 20 data points here which have got a strictlypositive mean, in fact I said here that it's much greater than zero.Then that means the remaining data points must have a mean return that's less thanzero, in particular the return from t to t plus 1, must also be less than zero.And so in fact, this trading strategy we've determined will tell us maybe thatwe should sell on day t, knowing that we expect to make money from t to t plus 1,because the mean between t and t plus 1 will be negative.So, this might seem to be a small bias. But it is a bias, nonetheless, and it canactually mess things up. Now, this is what's happened with thetraining data. Because of our normalization process,we've actually introduced a bias into how we determine this trading strategy.So now, what about the test set? Well, the test set is meant to be anindependent set of data. It has 250 returns, and the idea behindthe test set is, that it should be completely unpolluted, if you like.It should not have been polluted by the act of coming up with a trading strategy.However, it's subtle, but it has been polluted.And the reason is as follows. Suppose I test my trading strategy, whichI've determined up here using the training data.Suppose I test that strategy on the test set.Again let's say I'm at date t, I go back to date t minus 20.My trading strategy says, look at what's happened on the previous 20 days.So I'm just summarizing the previous 20 days by the mean return over those 20days. There's other factors inside these 20 daysas well that could also be part of the strategy.But let's suppose then on, on this particular day t, this mean over theprevious 20 days, let's say it's less than 0.Well, what does that say for days t to t plus 1?Well, it says in this case, that mu t to t plus 1, the return you expect from t to tplus 1 must be greater than 0. Why is that?Well, the reason is because the test set was part of the overall normalizationscheme. We actually included the tests set andtraining set, combined them together and normalized that data, so that the mean ofall the training and test data is zero. That means, that if this mean over these20 days is negative, even though it's only 20 days out of the total of 1,000 days, itdoes mean that the rest of the data must have mean greater than 0.In particular, the return from t to t plus 1, we would expect to be positive, andthat's why we have that. And so the trading strategy will be, ifyou like a mean reverting strategy. If the previous 20 days are negative webuy. If the previous 20 days are positiveresale. And so this test set will actually justifythe use of the trading strategy. We will see that we'll make money on thistest set. And the big problem here is the following.We normalized the entire return data set, and this was a mistake.A test set should have had nothing to do with the trading strategy.It should of been kept entirely separate from the entire process of finding thetrading strategy. Only when we find the trading strategy, dowe bring the test set in and use the test to evaluate the trading strategy.But we didn't do that here. We made the mistake of actually includingthe test set when we normalized the data. It might seem like a very small issue, butit is a real issue and it will introduce a real bias.It will make the strategy look better than what it really is.And the test set will have failed here because it would not have been anindependent test set. It will have been used as part of thelearning process. The learning process being the processused to generate a learned, good trading strategy.What we should have done is just normalize the training set.If we just normalize the training set, then the test that would have beencompletely uncorrupted or unpolluted. And over here, this behavior which areidentified would not have been true. And so presume-, presumably the test thatwould have found out that there was indeed a problem with the trading strategy wouldbe determined on the, on the training set. These examples crop up an awful lot infinance. Many banks and funds over the years havelooked for trading strategies in similar manners and introduced small but stillsignificant biases into their trading strategy's and into their learningstrategies for developing trading strategies in this manner.The conclusion is, one always needs to be aware of introducing these biases, andwhen you're keeping a test set, the test set must be completely independent of theprocess that was used to generate the trading strategy.There are many other examples of statistical biases and difficulties thatarise in finance. Survivorship bias and data snooping areeverywhere and one does need to be aware of this.There are many other examples that we can discus, we don't have a great deal of timeto do so in this course. And let, let me just mention a couple ofother examples where biases arise here or statistical difficulties arise.Here's an interesting question, just how likely is a 25 standard deviation move?Now the reason I bring this question up here is that at the beginning of thefinancial crisis in August 2007. There was a very large move in the market,some funds lost an awful lot of money. And some participants reported that theyactually saw a 25 standard deviation move and they used the size of this move tojustify the size of their losses. Well, in fact it did more than that, infact said they saw 25 standard deviation move, not just once, but several days in arow. So, a quick question, how likely is a 25standard deviation move? Well, let me tell you.You can easily estimate this using Monte Carlo, and using something called, apartial sampling of Monte Carlo. A 25 standard deviation move, assuming anormal distribution. So the probability done a normaldistribution. Let's say it's n zero one, but it could ben mew sigma squared. It doesn't matter that I'm assuming zeroone. Probability that this is greater than orequal to 25. Which is 25 standard deviations, isapproximately equal to 3.05 by 10 to the power of minus 138.So just to emphasize this is equal to .000305 and yes, there are 137 zero's inthis expression. So the probability of a 25 standarddeviation move is absolutely infinitesimal.To give you some sort of comparison, the number of particles in the observableuniverse. Depending on who you ask it's something onthe order of 10 to the power of 78 or maybe 79, or 80.But it's some sort of number like this. So, this is an enormous number.But it is in fact dwarfed by 3.05 by ten to the power of 138.So you can see that this number is extremely small.So if somebody reports a 25 standard deviation move, you have to ask thequestion. Were they just exceedingly unlucky, orperhaps their model was wrong? I think the, I think the answer is selfevident. How likely is a 25 standard deviation moveseveral days in a row? Well making the heroic assumption thatthese moves are independent, you would end up with a number like 3.05 by 10 to theminus 38. And it it's 3 days in a row say, well youhave to cube that, and if you cube it you'll get an answer like 2.7 by 10 to theminus 413. So I thing it is fair to say that inAugust 2007, it was inaccurate to say you saw 25 standard deviation move severaldays in a row. It much more likely that your model iswrong and very wrong at that. Alright, another example versus the[unknown] problems arise is in the are of retailed structured products.I'd like to be able to see more about structured products.Products in the course but we don't have time.So I'll just state the following; retail structured products are if you like exoticsecurities that are sold to retail investors.So these could be investors with just $10,000 or 10,000 Euro to invest.Their bank manager or their financial advisor suggests a structured note.And a, a structured note works like a bond, there's usually a payoff after 3 or5 years where you redeem your principal. Maybe you spend $10,000 on day 1, 5 yearslater you get your $10,000 back and in-between you get a coupon.And this coupon is tied to the performance of another asset, often the equitymarkets. Why do I say there are biases instatistical problems here? Well these structured products are oftendesigned to look better than they are. They tend to inverably back-test verywell. So for example, any structured productthat is long Apple. In other words, maybe what I'm saying hereis that the coupon that you get increases as a function of the returns on Apple.Well, in that case, any structured product that is long Apple will presumably backtest very well from 2000 onwards. Why is this?Well, this is a, a plot of the return on Apple.Actually, from 1985 up till today. But from 2000 onwards, I think, was around$7 at this point. And you see it's gone up to $700, almost$700 at 1 point, now it's below 500. But either way, there's been a massive runup in Apple over the last 10 years. And so, if you hold Apple in yourstructured product. Or rather, your the coupon that youreceived from your structured product depends on the performance of Apple.Well then, it 's going to look very good when you back-test that.There is also hidden risks that investors and structure products they're oftenexposed to often exposed to volatility risk we haven't reset much aboutvolatility yet to the end of the course. Obviously the rose the area of pricingoptions which is on the binomial model but we didn't explicitly talk about volatilityrisk. We'll talk about that later in the course.Investor's structured products were often exposed to credit risk as well.You're relying on the credit of the issuer of the structured note.If you think this is insignificant, then there's two words for you.Those two words are Lehman Brothers. Lehman Brothers also issued structurednotes, and sold them on to retail investors.Well, many people lost money when Lehman Brothers went under.So there is, there can be significant credit risk here as well.Another problem with structured products is that there is no secondary marketavailable to them. So if you purchase a structured product orinvest in a structured product. Then, you better be able to hold onto ituntil maturity. Because if you can't and you need to sellit. Before maturity, there would be nosecondary market. The only person you'd be able to sell itto is the bank that issued it to you in the first place.They'll know you're looking to sell and you will not get a good price.So, there's a lot of problems with structured products maybe they've got 1 or2 positive aspects, but overall they're, they're I think investors should be verycareful about investing in them for all of the reasons I mentioned here.Finally, we're going to end with a, a toy example or a play example.It's called the Monty Hall problem. I don't mention it here.This, it's got nothing to do with finance, however, even just a couple of years agowas discussed quite a lot in the Financial Times.There were some articles and letters written to the Financial Times about thisproblem. It often raises a great deal of confusion.And so we'll discuss it here too, because it provides a great example of how aseemingly simple problem can confuse people.So it should serve to highlight the fact that while statistics and issues withaverages and biases, don't require advanced mathematics, not advancedmathematics at all. It comes to be very confusing, and onedoes need to be aware of these issues in practice.So what is the Monty Hall problem? The Monty Hall problem is as follows.There are three closed doors. A goat lies behind two of the door.And one million dollars lies behind the other door.You don't know which door has the one million dollars and so you have to guessthe door. If you guess correctly, you actually aregoing to get the one million dollars. If you guess incorrectly and you open thedoor with the goat behind it, then you're going to get the goat.Before the door is open, Monty Hall opens a different door.So what happens here is maybe you guess door number 1.At this point, Monty Hall comes along and opens one of the other two doors.And the door he opens will have a goat behind it.And this is always possible, because two of the doors have goats, so even if you'veguessed incorrectly, then one of these two doors will have the goat.And so Monty Hall will open that door. Okay, so Monty Hall opens a differentdoor. The door always has a goat behind it.And now he gives you the option to change your mind and pick another door.The question is, should you change your mind?So, just to be clear here, suppose you start off, you guess door one.Then Monty Hall opens door three and shows you a goat behind it.You now have the option of changing your mind.You can stick with door one or you can change and go with door two.The question is, should you change? Well, I'm not going to give you the answerto that question. I'll let you think about that.There is a definite answer. If you're not sure, let me give you ahint. Consider the situation where there are 100doors. One, two, up to 100 doors, and thatthere's a goat behind 99 of these doors. The game plays, the game is paid asfollows. You pick a door, and then Monty Hall opens98 doors, all of which have goats behind them.Should you change your mind them? The answer to that question is the sameanswer to the question of the three door case.

## 008.Review of the Binomial Model and the Black-Scholes Model

### 013. Review of the Binomial Model for Option Pricing

In the next sequence of modules we're going to discuss equity derivatives inpractice, but before we get on to discussing equity derivatives inpractice, we're going to spend some time in this first module discussing andreviewing the binomial model. So we'll call again our pricing of aEuropean call option in the binomial model We're going to assume anexploration of t equals to 3, a strike of $100 and a gross risk free rate of requals 1.01. So the pay off of the option is given tous by the maximum of 0 and st minus k which is 100.So we see here the pay off of the option. Its 22.5, 7, 0, 0 and recall how wepriced this option. We computed our risk neutralprobabilities, which are given to us down here, q u and q d and then we workbackwards in the binomial ladder. So for example the value 15.48 is thevalue of the core option at this node and is given to us by one over the risk freeinterest rate, 1.01 Times the expected value of the payoff of the option oneperiod ahead. So we can work backwards in the latticeand price the option that way. Note also that when we price using thismechanism here, we're guaranteed to have no arbitrage by construction.And that's as long as D is less than or less than U.Remember that this is our new Arbitras condition in the binomial model.And it ensures that QU and QD are both strictly great in zero as we have downhere. And of course what that means thereforeis that in a price like this It's impossible to have an arbitrage becauseit would be impossible to get a payoff here and here, which is strictlypositive, and have a value that's strictly negative here, for example.And that's because qu and qd are strictly positive.So this is how we price securities or derivative securities in the binomialmodel. We ensure that this condition issatisfied to ensure no arbitrage, and then we work backwards in the lattice asusual. And so we can continue on in thisfashion. Compute the price of the option at everynode, working backwards until we find an initial option price of 6.57 dollars.Now, we can also write the option price, or compute it in one shot.When one calculation, using this expression here.So, this just reflects the fact that the option price is the expected value underQ of the discounted payoff of the option. The discount factors won over are acute.And these are the probabilities, so for example, 3Q squared times 1 minus Q,while this is equal to 3, reduced to. Times Q squared times one minus Q to thepower of three minus one. So this is a binomial probability, itcounts the number of ways in which the stock price can go up into periods andfall in the third period. And in fact, this is equal to three here,and we know that there's three ways to get up to this point, so down one and uptwo, up one, down one, and up one, or up two and down one.So we can also basically combine all the one period probabilities into threeperiod probabilities given to us by here, and compute the value of the option inthis manner. We also discussed, trading strategies inthe binomial model. So let's quickly review again what we didthere. St is going to denote the stock price attime t. Vt denotes the value of the cash accountat time t, without any loss of generality we assume that b0 equals one dollar, sothat bt equals r to the power of t. So now we're explicitly viewing the cashaccount as security. We let xt denote the number of shares.Held between times t minus one and t. We also let yt denote the number of unitsthat the casher account have between times t minus one and t.Then theta t equals x t y t as the portfolio held immediately after tradingat time t minus one and therefore is known at time t minus one.And immediately before trading at time t. So, basically, if this is t minus 1, andthis is time t, then we know theta t at this point, and this represents theportfolio that's held immediately after trading at time t minus 1, until tradingat time t. So theta t is a trading strategy.We also discussed the value process associated with a trading strategy.It is defined to be vt equals xtst plus ytbt for t greater or equal to one.So this, if you like, is the value just before, trading, at time t.And a t equal to zero, well we can't talk about trading just before time t equal tozero, because time t equal to zero is the beginning of our horizon.So this is equal to the value of the portfolio just after trading at timezero. We also have a definition of selffinancing strategy. Self financing trading strategy is atrading strategy where changes in VT, are do entirely to trading games or loses,rather than the addition of withdrawal of cash funds.In particular self-financing trading strategy satisfies this condition here.And of course we know that this, is equal to the value.Of the portfolio, just after, trading at time t.So basically, what we're saying here, is that a portfolio, or a trading strategy,is self-financing. If it's value just before trading isequal to its value just after trading. And what that means is that no funds havebeen deposited or withdrawn at time t. In other words, it is self-financing - itfinances itself. No new cash injections at time t, no cashwithdrawals at time t. We also have the following proposition.We said if a trading strategy theta t is self-financing, so s.f.is self-financing, then the corresponding value process vt satisfies the following.So this is the profit and loss from the trading strategy between times t and tplus one, so if we like, this is our p and l At time t plus 1.It's equal to x t plus 1 times the change in the stock price between t and t plus 1plus y t plus 1 times the change in the cash account between times t and t plus1. So a valid question at this point is whydo we care about self financing trading strategies.Well, we care for multiple reasons. In the multi-period binomial model, wecan actually construct a self-financing trading strategy that replicates thepayoff of the option, or, indeed, any derivative security.This is called dynamic replication. And the initial cost of this replicatingstrategy must equal the value of the options, otherwise there is an arbitrageopportunity. The dynamic replication price is ofcourse equal to the price obtained from using the risk-neutral probabilities andworking backwards in the lattice. Indeed this is exactly how we computedthe risk neutral probabilities in the first place, we initially considered aone period model, and actually with the way we computed QU and QD was byreplicating the payoff of the option at this node, and this node.So if we recall, we solve two linear equations and two unknowns.What we were doing at that point, is replicating the payoff of the security,in this one period model. So the risk neutral probabilities camefrom a replication, in this one period model, and you can actually splice allthe one period models together, to construct a multi-period model.And use the replicating strategies in each single one period model to constructa dynamic replicating strategy for the option.And so over here we find the replicating strategy for a European option.This is the option we began the module with, so for example, we see up here Uphere we see 0.802 times 107. 107 is the value of the stock.0.802 is the number of shares that we hold in the stock immediately aftertrading at this point. So 0.802 times 107 plus minus 74.84 times1.01, which is the value of the cash account at that node.Is equal to 10.23 here, the value of the option at that node.We could also check that in fact this is also equal to 0.598 times 107 plus Minus53.25 times 1.01. Now where does this come from?Well, 0.598 is the number of units of the stock held between times 0 and time 1.So 0.598 is the value here, and the minus 53.25 is the value here.And what we're seeing is that up at this node, the value of the option is 10.23.So this must be equal to the value of the replicating strategy at this node, whichis this value here, but this must also equal the value of 0.598 times 107 minus53.25 times 1.01 And that's because the replicating strategy is self financing.This here is the value of the self financing strategy immediately beforetrading at this node and this value here is the value of the self financingstrategy immediately after trading at this node and those two value must be thesame and they must equal the value of the option which is 10.23.So that's the end of our review of pricing in the binomial model andreplicating strategies in the binomial model.

### 014. The Black-Scholes Model

In this module, we're going to review and discuss and Black -Scholes model ingeometric boundary and motion. Black and Scholes used this model wayback in their paper in the early 70s to derive European coal and productionprices. We're going to review them here.Because we're going to be using the Black-Scholes model in later modules,when we discuss the Greeks. The Greeks are the partial derivatives ofthe option price with respect to the model parameters.Such as the underlying security, time to maturity, the implied volatility, and soon. So, it's very important that we know whatthe Black-Scholes model is and that we know the assumptions behind theBlack-Scholes model as well. Recall that the Black-Scholes modelassumed a continuously compounded interest rate of, or they assumedgeometric Brownian motion for the dynamics of the stock price.So that the stock price at time t, as little t say, is equal to the initialstock price times e to the mu minus sigma squared over 2 times 2, plus sigma wt.Where Wt is a standard Brownian motion. The stock price is assumed to pay adividend yield of c, and it also assumed that continuous trading is possible withno transactions costs. And that short-selling is allowed.So, this is a geometric Brownian motion model.Here are some sample paths of geometric bounding in motion.So, these are simulated paths of the geometric bounding in motion betweentimes t equals 0 and t equals two years. All three paths assume an initial stockprice s is zero of $100. Wanting to keep in mind here is that thepaths of the Brownian motion, while they're very jagged, they never jump.So in other words, you can't have a path with Brownian motion going like this, andthen jumping down to another point here. So, the Brownian motion, and therefore,the geometric Brownian motion moves continuously in time.In comparison, here's an example of a binomial model with n equals 26 periods.And here, I have shown you three simulated paths of the stock price here.So there's a red, a blue, and a green path.Now, it might not look very similar to Brownian motion or geometric Brownianmotion at this point. But imagine that instead of having 26periods, that I have 260 periods. It's, or 2600 periods.Well then, in that case, these simulated paths are going to look much more jagged.And in fact, they will begin to look like these paths of geometric bounding motion.And indeed, that is one of the properties that we mentioned before about thebinomial model. It can be viewed as an approximation togeometric bounding motion. And indeed, if I let the number ofperiods go to infinity, keeping the time horizon, T fixed.Then, the binomial model will converge in an appropriate sense to geometricbounding motion. We know in the binomial model that thethe call option price is given to us by this expression here.It is equal to i equals, the sum from i equals 0 to n, n choose i times qu to thepower of i times qd to the n minus i times the maximum of 0, u to the power ofi and d to the n minus i, S0 minus k. And so, in our binomial model, this isactually the fair value. I'm ignoring the discount factor here,this should be an e to the minus or t in here.But I will omit it because there's not room in the page this, but assuming it'shere. Then, this expression here is equal tothe price of the call option in the binomial model.Now, we also mentioned before that we let the number of periods and we go toinfinity, then we're going to actually get the Black-Scholes formula.In other words, this expression here will converge to the Black-Scholes formulahere. And this Black-Scholes formula isarguably the most famous formula, the most important formula in all ofeconomics and finance. I say arguably becasue I'm sure somepeople might disagree with that statement.But nonetheless, it's certainly a very important formula with widespreadapplications in practice. Now, a couple of things to keep in mind.Note that mu does not appear in the Black-Scholes formula.This is just analogous to the fact p, the true probability of an up move in thebinomial model. Does not appear in the risk-neutralprobabilities we calculated for the binomial model.Now, this is certainly surprising, at least initially.In fact, before we ever studied options pricing, if I was to ask you whatparameters the call option price depends on, well, you might have said thefollowing. You would have probably have said thatthe call price depends on the following. S0 the initial stock price, the strike K,the time to mature, T. Maybe there the risk-free interest ratefor discounting, the volatility sigma, the dividend yield c, and maybe I'mguessing you would of said mu as well. And that's fair enough.The vast majority of us would also agree with you, and I've assumed that the calloption price would also depend on the drift mu of the geometric Brownianmotion. But in fact, it's not true.The call option price in the Black-Scholes model, actually depends is,only on the first six parameters here. So in fact, it depends on S0, K, T orsigma and c. So, mu does not appear in here.That said, imagine for a second that some really positive news came through to themarkets about the stock price. So that mu became very large, maybe mubecame very, very large so that the market was anticipating that the stockprice will increase a lot. Well, what would happen in that situationis that many people would buy the stock immediately in anticipation of this goodnews. And therefore, the stock price wouldincrease. So, the way I like to think about this isthe following. The option price does not depend directlyon mu, but I think it is fair to say that S0, the stock price, now does depend onpeople's views about the prospects of the stock.And so, I like to write this as S0 of mu. So, I do believe that mu does enterimplicitly into the value of the call option.It enters implicitly in the sense that the stock price depends on mu.And so that, for me, is how to resolve this apparent contradiction that mu doesnot enter in the Black-Scholes formula. Black and Scholes obtain their formulausing a similar replicating strategy to the strategy we used in the binomialmodel. However, they did not use the binomialmodel. The binomial model only came about a fewyears after Black and Scholes wrote their original paper.So, Black and Scholes actually did their replicating argument in the context of ageometric Brownian motion model. If you want to prize European put option,then you can simply use put-call parity, put call parity is given to us here.We've seen it a few times now. So, if we know the call price, then wecan just bring this term over the right side to get the put price.As I mentioned on the previous slide, the Black-Scholes formula is arguably themost important and famous formula in all finance and economics.It is used extensively in the financial industry.It has also led to an enormous amount of acadmic work since it's publication.What we're going to do is we're going to see how this is used in practice.But we will emphasize now that the geometric Brownian motion model is not agood approximation of security prices. And indeed, everybody in the marketplaceknows there are many problems with geometric Brownian motion and theBlack-Scholes model. Nonetheless, it is used extensively andit is very important that people understand the limitations ofBlack-Scholes, and how it is used in practice.

## 009.The Greeks

### 015. The Greeks  Delta and Gamma

In this module, we're going to use the Black-Scholes formula to compute thesensitivity of option prices to the underlying parameters.The underlying paramenters include the underlying security price, the underlyingvolatility paramenter sigma, as well as the time to maturity.We're going to focus on to the so-called Greeks in this module.The delta of an option, and the gamma of an option.The delta of an option is the sensitivity of the option price with respect to theprice of the underlying security. The gamma is the sensitivity of the deltawith respect to the price of the underlying security.So we're going to discuss the delta and gamma in this module, and see how theybehave as time to maturity changes and as the underlying security price changes aswell. So recall the Black-Scholes formula forthe price of a European call option with striking and expiration capital T.It is given to us by this quantity here d1 and d2 were given over here.And, capital N refers to, to the cumulative distribution function of astandard normal random variable. R is the risk free interest rate, c isthe dividend yield, and the stock price St, is assumed to satisfy or followgeometric Brownian motion dynamics for Wt as a Brownian motion.The Greeks refer to the partial mathematical derivatives of a financialderivative security price with respect to the modern parameters.So I emphasize here that we've got the word derivative appearing in twodifferent contexts. Sometimes we refer to it as security, aderivative security price, and sometimes it's going to refer to the mathematicalderivative. So the Greeks are very important part ofderivatives they're used an awful lot in industry.They refer as I said here, to the partial mathematical derivatives of the financialderivatives security price with respect to the model parameters.The first Greek we're going to consider is delta.The delta of an option is the partial derivative, again it's the partialmathematical derivative of the option price with respect to the price of theunderlying security. The delta measures the sensitivity of theoption price to the price of the underlying security.And so the delta for European call option price is given to us by this, iIt's deltaC, delta S. Now, given the Black-Scholes formula overhere, we can easily calculate delta C delta S.It comes out to be e to the minus c times capital T, times N of d1.Where if you recall, N is the cumulative distribution function for standard normalrandom variable. Now this follows from 5, but it actuallyrequires a somewhat tedious calculation. If you just look at this expression, thenit does indeed appear to be the case. The delta C, delta S is equal to e to theminus cT, N d1. And indeed that is what we have overhere, but don't be fooled by this, actually there is a little bit more workinvolved, because d1 itself depends on S and therefore, d2 which appears over herealso depends on this. So in order to calculate delta C delta S,we actually have to take derivatives within this N d1 term, and indeed withinthis N d2 term as well. If we do that, using the chain rule andso on, and then simplify everything down, it turns out that indeed we get delta C,delta S is equal to just this expression here.The delta of a European put option is also easily calculated, one way to dothis is to use Put-Call Parity. So, if you recall, Put-Call Parityimplies that P0, the initial price for a put option is equal to C0 plus Ke to theminus rt, minus S0e to the minus cT. And so therefore delta P, delta S isequal delta C, delta S minus e to the minus cT.So once we know the delta of call option, which is given to us here.We can easily calculate the delta for European put option as well, thatâs givento us over here. So here in this figure we have plottedthe delta for a call option and a put option.So we've assumed, although it doesn't state it on the slide here, that thestripe is K equal to 100. The first thing to note is that, the calldelta is always between 0 and 1. And the delta of a put is always betweenminus 1 and 0. Now, if you think about it, this makessense because the payoff for a call option.So for a call, the payoff at time t is equal to the maximum of St minus k and 0.And the payoff for a put option at time T is equal to the maximum of K minus sT and0. So a call price, a call option.The value of a call option clearly increases as S increases and that's whythe delta of a call option is greater than zero.Similarly, the value of a put option will increase as S decreases, and that's whythe delta of a put option is less than zero.Something else to keep in mind here is the following.Note, that as the stock price, the current stock price moves away from thestrike. Then the delta moves towards either 1, or0 in the case of a call option or towards minus 1 or 0 in the case of a put option.Now, what's going on here? Well, the easiest way to see why this ishappening is the following. We know the value of the call option isgiven to us by the Black-Scholes formula. However, it is also true and actually,one can check this mathematically with the Black-Scholes formula.That the following is also true. It is equal to, and this is approximatelyand I'm ignoring interest rates and so on here.So thats why I'm using the approximent sign here, this is approximately equal toS minus K. If S is very large, and by very large Imean it is bigger than K, and much bigger than K.And indeed, it is so much bigger than K, that it becomes very unlikely that youwouldn't exercise the option at maturity. Likewise, it is equal to 0, if S is verysmall. And by very small, I mean S is muchsmaller than K. And in particular, it is small enoughthat the chance is of exercising the option are approximately 0.And then otherwise, where intermediate values of S, well, we can calculate 0 asbeen just a BlackâScholes formula. The important thing to note here is thatdelta C delta S is therefore going to be equal to 1 which is delta S delta S.For S very large, and it's equal to 0 for S very small, and indeed that's what wehave here. It's 0 for S very small and a 10 towards1 for S very large. The exact same argument also holds truefor the put price. We know that the put price, of course, isgiven to us by the Black-Scholes formula of a put options.Well, we can also write this as being approximately, and again, ignoringinterest rate factors and so on. This is approximately equal to K minus S,for S being very small. And that is approximately 0 for S beingvery large, and for intermediate values of S we would actually use theBlack-Scholes formula. So I'll use BS for Black-Scholes formula,and here for intermediate values of S. The important thing to note though is forS very small, then I can use this expression here.And the derivative of this with respect to S is minus 1 and that's why I'mgetting minus 1 down here. Similarly, for very large values of S,the put price is 0, or approximately 0. It's partial derivative with respect to swill be 0, and indeed that's what I have up here.So, we see that for extreme values of S, the delta of a call option is either 0 or1 or approximately 0 over 1. And similarly the delta for a put option,is approximately minus 1or 0. Here, we've plotted the delta for threedifferent European call options. The three options all have the samestrike, k equal to 100. But they have different times tomaturity, T equals 0.05 years, so approximately two and a half weeks.T equals 0.25 years, so approximately three months and T equals 0.5 yearscorresponding to the six month expiration.So we see here the deltas. Notice again, as in the previous slide,for S sufficiently large or small, the delta is going to go to 0 or1.But notice that they go to 0 or 1 faster for smaller time's maturity.So in other words, if we'd look at the case where t equals .05 which correspondsto two and half weeks. We see that S doesn't have to be too faraway from the strike of 100. Before it's delta goes to 1 or 0 andthat's because with only two and a half weeks to maturity.There's not much chance for the strike to either get into the money if its downlow, or to fall out of the money if its up high.And therefore the delta quickly goes to 0 or 1 depending on whether or not thecurrent stock price is below the strike or above the strike.And so that's why we see the red curve corresponding to T equals 0.5 years.Moving to 0 or 1 faster than the options with maturity T equals 0.25 years and Tequals 0.05 years. And the same argument of course alsoimplies that the T equals 0.25 year option.The delta of this also goes to 0 or 1 faster if you like than the option that Tequals 0.5 years. Another way of seeing this is, looking atthe delta, not as a function of the stock price as we did on the previous slide butas a function of time to maturity. So now we have time to maturity downhere. So, 1 corresponds having one year tomaturity, 0.5 corresponds to six months to maturity and 0 corresponds to having 0time maturity. We've got three different options.We have at-the-money option, so at-the-money has K equal to the currentvalue off the stock price, ITM stands for In The Money.So a 10% in the money option, means that S0, is equal to 1.1 times K.So therefore, it is in the money and the 10% out of the money, OTM option standsfor an option with a strike that satisfies S0 equals 0.9 K.And so, what we are seeing in this case makes sense.We see that for the option that is out of the money, it is 10% out of the money, so0.9k, the current stock price is less than K.So if the option were to expire today, you'd get nothing.And therefore, what we see is that the delta decreases, and it decreases toward0 as the time to maturity decreases toward 0.Similarly, the in the money option, where S0 equals 1.1k.So therefore, remember the payoff of the option is equal to the maximum of STminus K and 0. So if S, T, is equal to 1.1 k, well thiswould be equal to 1 K, so it's in the money.And what we see here is, that, as the time to majority goes towards 0, thedelta of this in the money option, goes towards 1.And that be, and that is because as the time to maturity goes towards 0 wouldbecome more and more likely to exercise the option.And so the option behaves more and more like ST minus K, because this maximum isgoing to be equal to ST minus K as the time to maturity goes to 0.And of course, the partial derivative of this expression here is equal to 1 andthat's why the delta goes to 1. On the other hand, down here in the 10%out of the money case well then this is going to behave like 0.If we're out of the money, it's going to behave like 0.As the time to maturity goes to 0 and therefore, the partial derivative of thiswill be equal to 0 and that's what we're seeing here.Perhaps the more interesting case is when the option is at the money and K equalsS0. Well, then in that case, and I'm talkingapproximately here, the chances of exercising approach 50%.So, basically, there's a 50% chance of exercising and 50% chance of notexercising. And it turns out and it can be confirmedby differentiating the Black-Scholes formula, or calculate the expression wesaw on the earlier slide that the delta actually approaches 0.5.The gamma of an option is the partial derivative of the options delta withrespect to the price of the underlying security.So, the gamma measures the sensitivity of the option delta to the price of theunderlying security. The gamma of a call option is thereforegiven to us by delta 2C delta S squared, and again it's somewhat tedious but itcan easily be calculated using basic calculus.We can take the partial derivatives of the BlackâScholes formula to calculatethe gamma. If we do that we will find a sequel tothis expression here. E to the minus C time T, N of d1 dividedsigma S square root T. How about the gamma of the European putoption? Well that's easily calculated fromput-call parity. So put-call parity is given to us here.So therefore, we can actually say that P, is equal to C, plus e to the minus rttimes K, minus e to the minus cT times S. So we can therefore, see the delta 2p,delta s squared is equal to delta 2c delta s squared.Well, plus 0 minus 0 because the second partial derivative of this is equal to 0.And the second partial derivative of this with respect to S is equal to 0.So therefore, we see that, see that the gamma for put option is equal to thegamma for a call option. So, once we know the gamma for Europeancall option we therefore we have the gamma for European put option.And in fact, you can see that this expression is always greater than areequal to 0. So the gamma for European options isalways positive. this is due to what's called optionconvexity. Here is the plot of the gamma forEuropean options is, as time to maturity varies.So, the gamma here is a function of the stock price, and we've got threedifferent times to maturity. 0.05 years, 0.25 years and 0.5 years aswe saw before. Notice that the gamma is steepest for theshortest maturity. So, in this case, for T equals 0.05 yearsi.e approximately two and half weeks to maturity, we see that the gammas are verysteep around the strike of K equals 100. But we also see that it falls away to 0much faster than the option when T equals 0.25 or the option when T equals 0.5years. The reason is as follows, the delta ofthe European option when T equals 0.05 years, well, it's going to be a half, orapproximately a half when the stock prices at the strike K.But as the stock price goes up, the delta's going to move towards 1 and it'sgoing to move towards 1 much faster than the options with the higher time tomaturity. Similarly, as the stock price falls belowthe strike of 100, the delta of the call option is going to move towards 0.And it's going to move towards 0 much faster than the delta of the options withtimes to maturity of 0.25 and 0.5 years. So this actually is, another, this plothere is just another way of looking at this plot.In the option, where T equals two and a half weeks or 0.05 years to maturity.We see that when S eqauls 100 that delta is approximately 0.5.But for small moves of, of S above 100 the delta quickly goes towards 1.And for small moves of S below 100 the delta quickly goes towards 0.And does it does much faster than the options with larger times to maturity.So we're seeing without the option which is two and half weeks to maturity has amuch higher gamma than the option when T equals 0.5 years or T equals 0.25 yearsto maturity. And another way of looking at this is tonow plot the gamma as a function of time's maturity.So one year to maturity, six months to maturity zero time to maturity.We see that for the option that's out of the money, 10% out of the money or 20%out of the money. I mean this would also be true foroptions that are in the money, the gamma of those options actually goes towards 0,it falls towards 0. And that's because as the time tomaturity goes to 0, we know for sure we're not going to be exercising if we'reout of the money. And we know for sure that we are going tobe exercising if we're in the money. In other words, delta will be 1 if we'rein the money, delta will be 0 if we're out of the money, and so gamma will be 0in both cases. On the other hand, if we're dealing withan at the money option, where the current stock price is equal to K.So here is where s is equal to K for this blue curve.Well, then as the time to maturity goes to 0, we're going to find that ourdelta's equal to a half but that the gamma will actually be very, very large,and grow very large. And that's because small moves in s willmove the delta to either 1 if S increases, or 0 if S decreases.And so we get a very large gamma for at-the-money options.I should mention as well by the way, that with all of these plots that we'relooking at of delta and gamma market practitioners understand this behavior.They understand it at an intuitive level. They know how the delta of a colonEuropean put option behaves, they know how the gamma of these options behave.And so, it's very important, that if you're working with options and practice,that you understand these figures and you understand why they behave, and look theway that they do.

### 016. The Greeks  Vega and Theta

In the last module, we saw Delta and Gamma.In this module, we're going to see Vega and Theta.Vega is the sensitivity of the option price with respective changes in theparameter Sigma, the volatility parameter Sigma.Whereas, Theta is the sensitivity of the option price with respective changes inthe time to maturity. So, were going to discuss Vega and Thetain this module. We'll see how they behave as the functionof the underlying security price and indeed as the function of the underlyingtime to maturity. It is very important that we understandhow all of the Greeks work. And the Vega and the Theta are veryimportant Greeks in practice. Again, here we have the Black-Scholesformula. Were going to use the Black-Scholesformula in this module to compute the Vega and Theta of an option.So, just remind yourselves, the Black-Scholes model assumes that thestock price follows a geometric Brownian motion, so that the stock price of timeLT is equal to S0e to the r minus c minus Sigma squared over 2 times T, plus SigmaWt, where Wt is a Brownian motion under the risk neutral probability distributionQ. So, this is the formula here.And you saw in the last module what the delta of an option is.We also saw what the gamma of an option is.And we can calculate the Delta and Gamma by taking the appropriate derivatives ofthis expression here, for a call option. Likewise, we could the same for a putoption or if we liked, we could use put-call parity to compute thoseexpressions for put options. So, first let's deal with the Vega.The Vega of an option is a partial derivative of the option price withrespect to the volatility parameter Sigma.So, the volatility parameter is this parameter over here.Now, if you stop and think about it for a moment, you might think that as Sigmaincreases, the value of the option will increase.And indeed that is true. For example, the payoff of a call option,capital T, CT, is equal to the maximum of 0 and ST minus K.While it makes sense the Sigma gets larger, the value of the security willalso increase. an easy way to see that perhaps isimagine that S0, the initial stock price, is much less than in, than the strike ofK. Well, in that case, if Sigma is very verysmall, the chances of the stock price growing enough, so that the option endsup in the money, will be zero, or approximately zero.On the other hand, as Sigma gets sufficiently large, the probability thatst will be greater than K will actually increase, in which case, the option valuewill be non-zero. And so it makes sense that the callprice, the initial price of the option C zero, should be increasing in Sigma.And we will see that that is indeed the case.The Vega of an option is a partial derivative of the option price withrespect to the volatility parameter Sigma.Vega, therefore, measures the sensitivity of the option price to Sigma.And using the Black-Scholes formula, it can easily be calculated.Vega is equal to Delta C Delta Sigma, which turns out to be e to the minus eT,s square root of time to majority times phi of d1, where phi is the probabilitydensity function of a standard normal random variable.Now, we can also compute the Vega for a European put option by using put-callparity. So, this is put-call parity here.Remember, so it actually implies. So, it implies that the put price isequal to the the call plus e to the minus rt times K minus e to the minus cT timesS. And so, therefore, we can actuallycompute Delta P, Delta Sigma, we see it's equal to, well Delta C, Delta Sigma.That's the first term here. And then these other two terms don'tdepend on Sigma at all. So, it's plus zero minus zero.And so, we see Delta P, Delta Sigma equals Delta c, Delta Sigma.And so, the Vega of a European put option is the same as the Vega of a Europeancall option. Here's a question for us.Is the concept of Vega inconsistent in any way with the Black-Scholes model?And the answer is yes. If you recall, the Black-Scholes mo-,model assumes that St, the stock price of any time t, is equal to S zero e to theMu minus Sigma squared over 2 times t, plus Sigma times Wt, where Wt is astandard Brownian motion. Mu and Sigma are constants in this model.They are not assumed to change. And that indeed was the assumption of theBlack-Scholes model. They assumed continuous trading.They assumed that there were no transactions, costs, and that short saleswere allowed, and that borrowing or lending at the risk free interest rate,or was also possible. Using these assumptions, they constructeda self-financing trading strategy that replicated the payoff of the option, andthat is indeed how they are paying the Black-Scholes formula.Nothing in their model allowed Sigma to change, Sigma was a known constant.And yet when we're talking about Delta C, Delta Sigma, we're implicitly recognizingthe fact that Sigma can change. And indeed, in the marketplace, Sigmadoes change. So, in that sense, the, While,mathematically, one can always define Delta C, Delta Sigma, there's no problemwith that. Within the economics of the Black-Scholesmodel, it isn't consistent to talk about Sigma changing.Because we ob-, we obtained the Black-Scholes option price under theassumption that Sigma could not change. Here are some plots of Vega for options,for European options, as a function of the stock price at time t equal to zero,and as the time to maturity varies. So, we've got three different times tomaturity T equals 0.05 years, T equals 0.25 years, and T equals 0.5 years.There are probably two things to notice first.The first observation is as follows. Note that if I pick any one of theseoptions, the Vega goes to 0 as the stock price moves away from the strike, whichwas $100 here. So, what is going on here.Well, it's very simple. So, again re-, returning to what we didin previous modules, we know the following.Let's take a call option as our example. .We know that the call option price[BLANK_AUDIO] will be approximatelyequal to, and again, ignoring interest rate factors and so on.It would approximately be equal to S0 minus K, for S0 being very large.And by very large, I mean much larger than K.And sufficiently large, that I'm almost certain I'm going to be exercising theoption. It will be equal to zero for S0 beingvery small. And very small here means much smallerthan K. And indeed, small enough that the chancesof exercising the option are approximately zero.Well, we can see here that Delta C, Delta Sigma, therefore, must be equal to 0 inthis situation because the partial derivative of S0 minus K with respect tosigma is 0. And also 0 down in this situation aswell. And therefore, for S0 very large, whichis up here, or S0 very small, which is down here, we see that Delta C, DeltaSigma goes to 0. And indeed, that's what we see for eachof these three options. So, that's the first observation.The second observation, so let's call this observation 1.The second observation here is that the Vega[BLANK_AUDIO] increases in timematurity capital T. So, we see that the option where t equal.05 years, the blue curve here, is larger than the Vega for the option where tequals 0.25 years and so on. And in fact, this is not surprisingbecause if we go back to the Black-Scholes formula.Over here, we can see that every place where Sigma appears, we find it togetherwith a square root of T. Or if you like, when Sigma squaredappears in the Black-Scholes formula, I see a T appearing.So, I've got Sigma square root T or sigma square root T appearing here.So, basically, every time I see a sigma, I'm multiplying it by the square root ofT. And, therefore, the impact of a change inSigma, i.e. the Vega, it would be amplified by thesquare root of T. And it is, therefore, the case.And, by the way, maybe I should have mentioned or was assumed to be equal toc, was assumed to be equal to zero in these plots here.We can see that the blue curve has, is a factor of square root of 2, which isapproximately equal to 1. 4, times higher than the green curve.And the green curve is a factor of the square root of 5, which is approximatelyequal to 2.2 something, greater than the red curve.And that's no surprise because 0.5 years divided by 0.25 years is equal to 2.So, the square root of 2 is approximately 1.4.And, indeed, we see the green curve reaches a peak of 20 here.1.4 times 20 is 28. And that's roughly the peak of the bluecurve. Likewise, down here, we have the redcurve reaching maybe a peak of approximately 8 and a half or 9, 8 and ahalf or 9 multiplied by 2.2 brings us up towards approximately 20.So in fact, this behavior is entirely predictable.The, the change, the, the Vega for the option is magnified by the square root ofthe time to maturity. Another way of saying that is, anotherway of seeing this is by looking at this figure here, where we have plotted theVegas for three options. And not the money option.A 10% out of the money option and a 20% out of the money option.And in all three cases, we see that the Vega converges to zero as the time otmaturity goes to zero. And the, this would also be true if ishowed a 10% in the money option or 20% in the money option.The next Greek I want to talk about is the Theta of an option.The Theta of an option is the negative of the partial derivative of the optionprice with respect with time to maturity. So, therefore, mathematically speaking,Theta equals minus Delta c, Delta t. And that's for a call option.We can also compute it for a put option, if we actually go ahead and do themathematics, compute the derivatives of the Black-Scholes formula.We will find that theta's equal to this long expression here, where, phi is thestandard normal PDF. So, if you recall, N is the standardnormal CDF and phi is the standard normal PDF.Why do we take the negative? Well, we take the negative because inpractice, time goes forward. So, in practice the time to maturity ofan option decreases. Suppose I have an option right now whichis 200 days to maturity. Well, then tomorrow, it would have 199days to maturity. So, therefore, the time to maturity isalways decreasing in practice. And so, it's conventional to take Thetato be the negative of the partial derivative of the option price withrespect to time to maturity. Here are some figures.Again, we see Theta for European call option as a function of the stock price.K was equal to 100 in these examples. We assumed r, the interest rate, andindeed c, the dividend yield, was equal to 0%.We plot the Theta here for 0.05 years, 0.25 years and 0.5 years.Notice, number one, that the Theta is negative in all cases.Now, in general, Theta will be negative for European call and put options.It's, it's not always the case that it's negative.There are certain situations where theta could be positive.But in general, most of the time, theta is negative.In other words, when you hold a European call or put option, you lose a littlepiece of money every day if the underlying stock price does not change.That's what Theta means. Remember Theta is equal to minus thepartial derivative of the call option price with respect to time to maturity.So, as the time to maturity decreases, I lose a little piece of the value of theoption, the Delta c decreases. Again, another observation, is that asthe stock price moves away from the current strike of K equals 100.We see that the Theta goes toward zero. And again, we can use our earlierexamples to see why this is the case. We know, and this time we'll say in thecase of we have a call option here, so we'll stick with the call option, in thecase of a call option, we know that c0 will be approximately equal to, as zerominus K, if S zero is much bigger than K or very large, and it's approximatelyequal, if S zero is much smaller than K. In both cases, the partial derivative ofthis term, with respect to capital T, the time to maturity is zero.Likewise, the partial derivative of this term, zero, with respect to time tomaturity capital T, is also zero. And so, that's why we see, for largevalues of S and for very small values of S, we see that the partial derivativewith respect to time to maturity is zero. And that's why all of these curvesapproach zero as S moves away from the strike, K.Why is the theta most negative around the strike for short times to maturity?That is, for time to maturity of two and a half weeks of 0.05 years.Well, one way to see that is the following.Suppose I've just got one day to maturity.So, I've got one day. So, T is equal to one day to maturity.Well, then, and suppose the stock price is equal to K.So, I'm at the money. This means I've got one day to maturity.If the stock price increases, I'm going to exercise the option and make somemoney. if the stock price decreases over thenext day, I'm not going to exercise the money.So, the option value will be none-zero at this point because over the next day,there is a chance that the stock price will increase and I'll be exercising andmake me some money. However, imagine rolling time forward oneday without changing the stock price. Well, in that case, this is going to goto zero days to maturity. That's zero is still equal to K.And now the option expires worthless. So, when there's just one day tomaturity, the Theta is larger, larger and more negative, because I have more tolose over the next day than I would if there was one year to maturity.If there was one year to maturity, I would have 365 days left.Moving time forward, one day isn't really going to impact the value of the optionvery much at all. However, when I've just one day left tomaturity, that one day encapsulates all of the value of the option when I'm atthe money. And if I roll time forward one daywithout changing the stock price, I'm going to expire worthless and, therefore,receive nothing. So, the Theta becomes more negative andpeaked around the strike as the time to maturity decreases towards 0.And on this plot, we see the Theta for European put options as a function of thetime to maturity. We've plotted here three different optioncurves. One for not the money option, the bluecurve, and the green and red curves for 10% out of the money and 20% out of themoney options, respectively. So, in fact, just so we're clear, a 10%out of the money option, in this case, it's a European put option.So, 10% out of the money option will have K being equal to 0.9 times S zero.So, the strike is below the current stock price.And, so, currently it is out of the money.For the 20% case, we will have K equal to 0.8 times S0.So, in these cases, we see this out of the money options that they're Theta isdecreasing. Let's take this green curve here.We see Theta is decreasing for a while, that's negative and decreasing.But beyond the certain point, it becomes, it, it turns around and moves towardzero. And that's because it's becomingincreasingly unlikely that the option will be exercised.It's value is moving towards 0, and so its Theta will be 0.The partial derivative of 0 with respect to t is equal to 0.So, at this point, the value is moving towards 0 because it's becoming less andless likely to be exercised. The red curve, corresponding to a 20% outof the money option, has actually be turned earlier than the green curvebecause its 20% out of the money is further away.And so, it's becoming less and less likely to be exercised at an earlierpoint than this green curve here. And, in case you're wondering, we caneasily create these plots, just by using this expression here.This is an expression, so for those of you who are comfortable with Code in R orMatlab or Python. Or indeed in Excel, you could create atable of values for t. Create the, Thetas for these different Tvalues and create a plot. You can easily create these kinds ofcurves that I'm showing you.

## 010.Risk Management of Derivatives Portfolios and Delta-Hedging

### 017. Risk-Management of Derivatives Portfolios

In this module, we're going to spend a little bit of time discussing how torisk-manage option portfolios. We're going to briefly discuss twomethods. First method is based on the Greeks.We're going to use a Delta-Gamma-Vega approximation to hedge against relativelysmall changes in the underlying security price and the volatility parametersignal. However that method will not work wellwhen these changes in the underlying security price and the volatilityparameter are substantial. In that situation, we would use scenarioanalysis instead and we, we will spend a little bit of time discussing scenarioanalysis as well. Once again we have here the Black-Scholesformula. I just want to emphasize that theBlack-Scholes formula gives us a closed form or analytic expression.For the price of European call and put options in the Black-Scholes framework.That is where it is assumed the stock price follows a geometric Brownian motionwith these dynamics where we can trade continuously in time with no transactionscosts, and where short selling of the stock is allowed.So Black-Scholes using a replicating argument that we also used in the case ofthe binomial model showed how to compute the prices of call input options in thisframework. And indeed they came up with this, theBlack-Scholes formula. In early modules, we saw how we cancompute the delta. We know that delta is equal to delta c,delta s. We also saw how to compute gamma.Which is equal to delta 2c, delta s squared.We also saw how to compute vega. So vega was equal to delta c, deltasigma. So these are just partial derivatives ofthe option price, with respect to the parameters s, and sigma.We also saw indeed how to compute theta which is equal to the negative of thepartial derivative of the option price with respect to time to maturity.So it's very straightforward to compute these quantities just by takingderivatives appropriately inside here. And indeed, in the case of a put option,we can also compute these expressions very easily sometimes simply using putcall parity. In fact, by put call parity, it is easyto see that the gamma and vega of call and put options are identical.So at this point, we have the Black-Scholes formula and I'm going toassume that we know how to calculate these quantities as well.These are easy to calculate programatically one can do them in Excel,or indeed in Or, Python in any programming language that you like.Let's consider some approximations. We're going to view the option price as afunction of s and sigma only. Then the simple application of Taylor'sTheorem. Now Taylor's Theorem is a theorem I hopeyou saw in your undergraduate mathematics class.If you haven't don't worry about it. What it does is the following.It enables us to see what happens to the call auction price.For small changes in s and small changes in Sigma.In particular, suppose we let s go to s plus Delta s, so Delta s represents thechange in the underlying stock price. And sigma goes to sigma plus delta sigma.So delta sigma represents the change In sigma, the volatility parameter.Well then Taylor's Theorem allows us to say that this option price at the newparameters, s plus delta s and sigma plus delta sigma is approximately equal to theoption price at the original parameters s and sigma plus delta s times delta cdelta s. Plus a half delta s squared plus delta 2cdelta s squared plus delta sigma times delta c delta sigma.So we recognize that delta c delta s is equal delta.Delta 2c delta s squared is equal to our gamma term and delta c delta sigma isequal to our vega term. So we therefore get that the P&L,remember the P&L would therefore be this term minus c, s sigma so I will bringthis over to this side and I get the P&L on the left hand side, P&L standing forProfit and Loss. So P&L would be with the delta times thechange in the stock price, plus gamma over 2 times the change in the stockprice squared plus vega times delta sigma.And so what we have here, is that the profit and loss on the option price whenthe stock changes by an amount of delta s and the volatility changes by an amountdelta sigma. When that profit and loss is equal tothe, a delta component, which is this, a gamma component, which is this, and avega component which is this. Now I should mention as well, if I wantedto I could also include time to maturities, another parameter.So I could have t and t plus delta t in here.And then I would also have a theta component, so that's perfectly fine aswell, and indeed people do this. But to keep things simple, I just want tostick with delta, gamma and vega here. And if fact sometimes people just workwith delta and gamma. So if I assume delta sigma equals 0, Iwill obtain a delta-gamma approximation. So, the p now, in this case, will just bedue to delta and gamma. And, this is often used, for example, inhistorical Value-at-Risk calculations. Now, we go, won't go, anymore, into, intoValue-at-Risk, for options portfolios here, but I know you've seenValue-at-Risk elsewhere in the course. Now something else I can do is I canactually go back to this expression here. And just do some simple algebraicmanipulations to get the following. I can also say that the P&L is equal todelta s times delta s over s plus gamma s squared over 2 times delta s over s allto be squared, plus vega times delta sigma.Now I can write this. So this is my return, delta s over s, isthe return on the stock price. I'm going to call delta, this is, thisdelta here is delta c delta s. So, delta times s, is often called theesp, standing for equivalent stock position or the dollar delta.Delta s over s all to be squared well this is my return squared and so thisquantity here gamma s squared over 2 is sometimes called dollar gamma.So dollar gamma is this expression here. and what I should emphasize, is that inpractice, market participants, option traders, or just investors who happen toinvest in options, as well as underlying securities, stocks, and futures and soon. What they will do is they will often knowwhat the ESP is of their option. So they will often know, so they willtypically know the ESP , the equivalent stock position, they will know theirdollar gamma and they will know their vega.And knowing these quantities will help them understand how their portfoliobehaves as the underlying stock moves and as the volatility parameter's sigmachanges. So, for example, let's consider thefollowing situation. Suppose the ESP, the equivalent stockposition is equal to 1 million dollars, now this might come about because maybe Sis $100, delta's a half so a half times 100 is 50.But maybe I've got thousands of these options, and altogether they combine togive you the ESP of $1,000,000. Maybe my dollar gamma is equal to let'ssay 500k, $500,000. And supposed my vega is equal to $100,000for 1% change in sigma. Now suppose delta s over s is equal to10%. So, suppose the underlying stock hasincreased by 10%, may be this is over the next day and suppose sigma goes towhatever the previous value was plus 2 percentage points.Well, then I can use this expression and these quantities here to approximate myP&L. So, in this case, my P&L, my Profit andLoss on my option position will be approximately equal to my ESP which is 1million dollars times 10%. So it's going to be 1 million times 10%.Plus, my dollar gamma, which is 500k times the return squared.My return is 10%, so 10% squared is 1%, plus my vega which is 100k, per 1%.So it's plus 100k and volatility might doubt, the sigma has changed by 2% sothat's times 0.02 and this is equal to the, let's see, it's a 100k plus 5k plus2k. So that's equal to 107k.And, of course, I should mention that one can get very different options, so onecan get options with very different ESP's gamma's, and vega's.What also interesting is that people have used this not just for a single option,but for an entire portfolio of options. What can have an entire portfolio, it cancompute the ESP for the entire portfolio, and the dollar gamma for the entireportfolio and indeed the vega for the entire portfolio.And so one will then understand there maybe represent the exposure of theportfolio in terms of the ESP, the dollar gamma and the vega.Typically of course they will also know the data for the portfolio and maybe someof the other Greeks as well, that we have the time to go into.So, the Greeks are very important. People understand their sensitivities,their risk-sensitivities, in terms of these Greeks.Now, as I've shown you here, understanding your Greeks and typicallywriting them in terms of quantities like ESP Equivalent Stock Position or dollargamma and so on. Here's a very good idea and marketparticipants do use these approximations all the time, but it is also worthpointing out that for very large moves in s or sigma can, can break down, it willno longer work. And the reason that it will no longerwork It's because Taylor's Theorem isn't valid for very large moves in s or sigma.Now I won't go into any further details on this but you have to understand thatTaylor's Theorem it gives you a good approximation for relatively smallchanges in s and relatively small changes in sigma.If you get very large moves or extreme moves, then these approximations breakdown, and they aren't very accurate. In that case, what people often use isscenario analysis. So, here's one slide giving you an idealof what is going on with scenario analysis.So what I've shown here, is the following, it's an example of a pivottable, that I've constructed in Excel. If you don't know what a Pivot table iswhen then you can use the help facilities in Excel to figure out what they are andhow to use them, they can be very useful in manage situations.we're not going to say anything more about them here.what we've assumed here is that we've got an options portfolio, the optionsportfolio is written on the s and p 500s, we've got lots of options and maybe we'vealso got futures in our portfolio. And what we done is we've considered twostresses. We've stressed the underlying securityprice. In this case, the underlying securityprice, as I said, is the s and p 500. And down on this axis we're consideringstresses where the s and p 500 falls by 1% or it falls by 2% or 5% up as much as20%. We're also considering situations wherethe s and p 500 increase by 1%, 2%, 5%, 10%, and 20%.Across the x axis up here, we're considering stresses and volatility.So this vol here refers to the sigma parameter we've been discussing.So this is the sigma that enters into the black shoals formula.What we're doing is we're considering sigma going to sigma plus 1 percentagepoint, sigma plus 2 percentage points, up to sigma plus 10 percentage points.And down to minus 10 percentage points as well and then in anyone one cell we cansee what the profit or loss is on the portfolio at that particular scenario.So for example down here, this corresponds to the s and p increasing 5%,and implied volatility's increasing 5 percentage points.Well in that case I'm going to see a loss of 4, 3, 2, 2.Now, if this is in units of dollars, then it represents $4,322.But maybe it's in units of 1 thousand, in which case it represents a loss of 4.3million dollars. So, this is an example of a scenarioanalysis. People do this all the time in financewith derivatives portfolios. To stress their risk factors, in thiscase the risk factors are the prices of the underlying security and thevolatility of the options. And then they reevaluate their portfoliosin these new scenarios and compute the profit or loss in these scenarios.So this is an alternative approach to risk management.It gives you a more global approach than the approach given to us by the Greeksthat we saw in the previous slide Where we just use delta, vega, and gamma, andtheta and so on, to analyze the risk of small changes in the underlyingparameters. Here we're looking at much larger changesin the underlying parameters, either the volatility, or the underlying security.And then we figure out what the P&L is in these scenarios.It is important to choose the risk factors and stress levels carefully.It's pretty straightforward to do this with a vanilla options portfolio.By vanilla I mean where the options are pretty standard or straightforward likeEuropean call options. But if you're trying to do scenarioanalysis with very complex portfolios, portfolios containing complex derivativesecurities, understanding what these risk factors are can be a challenge in and ofitself. Moreover, figuring out what theappropriate stress levels are, and by stress level, I mean a 2% or 10% or 5volatility points, they're examples of stress levels.So, with very complex derivatives portfolios, figuring out what appropriatestress levels are can also be very challenging.And if you don't believe me, you can just think of what went down during thefinancial crisis when people were working with CDOs and Asset Backed Securities andABS-CDOs and so on. In these situations the portfolios werevery complex. With many many risk factors andunderstanding how to do scenario analysis with these portfolios was more or lessimpressive. And this is one of the many reasons thatexplain what went wrong during the financial crisis and the difficultieswith these exotic structure products during the financial crisis.

### 018. Delta-Hedging

In this module, we're going to discuss Delta-Hedging within the Black-Scholesmodel. Delta-Hedging allows to exactly replicatethe payoff of an option. When we Delta-Hedge, we're following aself-financing trading strategy whose value at maturity is exactly equal to thevalue of the derivative that we're trying to replicate.So Delta-Hedging is possible, we're going to see how it works within the context ofthe Black-Scholes model. However, in practice, we cannotDelta-Hedge exactly datas because we cannot trade at every instance in time.And, because we actually don't know the true model and the true perimeters of themodel that generate the security prices. So in practice, Delta-Hedging can only bedone approximately. We're going to discuss Delta-Hedging inthis model. Recall that the delta of a European calland put option, respectively, are given by the following terms here.So, Call-Delta is e to the minus cT N d1, and then using Put-Call Parity, we caneasily see that the Put-Delta is given to us by the Call-Delta minus e to the minusc times T. Where T is the maturity of the option andk is the strike of the option. c is the dividend yield, r is the riskfree interest rate, and S0 is the initial stock price.In the Black-Scholes model, an option can be replicated exactly by following aself-financing trading strategy. Now, just remind ourselves, first of all,what is the Black-Scholes model? Well, remember in the Black-Scholes modelwe've seen that the stock price follows the geometric Brownian motion.So, that means that St is equal to S0e to the mu minus sigma squared over 2 times tplus sigma times a Brownian motion Wt. So, this the geometric Brownian motionprocess that the security price follows. We also assume there's a risk freeinterest rate r, a dividend dlc. We assume that continuous trading isallowed. So, cts stands for continuous trading.And that short sales are also allowed. And of course, we also assume that we canborrow or lend at the risk-free rate of r.So this is the Black-Scholes model, here, also I should have mentioned, if it'simplicit assumptions continues trading that there are no transactions costs.Another is we can trade continuously without having to pay a charge or fee fortrading. So, no transactions costs.Alright. So, in the Black-Scholes model, an optioncan be replicated exactly by following a self-financing trading strategy.Now, we did this in the binomial model. So, if you follow the argument in thebinomial model, you'll realize that we can replicate any security in thebinomial model. Now, if you also recall, we mentionedthat the binomial model can be viewed as an approximation to geometric Brownianmotion. And indeed, as the number of periods ngoes to infinity. We argued, or at least, we said that thebinomial model converges in an appropriate sense to geometric Brownianmotion. And therefore, it should not besurprising that it is also the case in the Black-Scholes model that everysecurity can be replicated exactly by following a self-financing tradingstrategy. When we execute this self-financingtrading strategy in practice, we often say that we are delta-hedging the option.And I will explain where this terminology delta-hedging comes from in a moment.But of course, and as I just said in the previous slide, the Black-Scholes modelassumes we can trade continuously. However, this is not feasible inpractice. In practice, you cannot tradecontinuously. And indeed, you have to pay transactionscost when you do trade. So what people do instead is they tradeperiodically, and in particular they hedge periodically.It also means we can no longer exactly replicate the option payoff.In fact, the best that we can do is hope to approximately replicate the optionpayoff. Anyway, let T be the option inexploration, so if you want to understand delta-hedging a margin that we are tryingto replicate pay off of a call option. So remember, the pay off of the calloption C capital 'T' is equal to the maximum of 0 and ST minus k.' And ofcourse, we can price this at any time little t via the Black-Scholes formula.So, what we're going to do is, we're actually going to set a fixed number oftimes. T0 up to t little n.T0 is time 0. T little n is time capital T.We'll assume that Delta t is the length of any of these intervals, so Delta tequals ti plus 1 minus ti for all i. And what we're going to do is we're goingto say V0 of S0 Sigma0 is the initial value of the option, so you can think ofV0 of S0 Sigma0 as being the Black-Scholes price of the option.So we often write it as S0 or Ck sigma, and we call it sigma 0 now and t.So V0 of S0 sigma 0 is the Black Scholes price of the call option at time 0.And we're emphasizing here that it's going to depend on S0 and sigma 0.The other parameters over here we'll keep implicate, but we wont mention themexplicitly. So what were going to do is, were goingto define the following trading strategy. Where Vi plus 1 is going to be the valueof the trading strategy at time I plus one.So we're going to see Vi plus 1 equals Vi plus delta i.So in the case of our call option, delta i is equal to at the minus c times Tminus Ti times nd1. So, it's delta i times Si plus 1 plus Sicdelta t minus Sic, plus another term over here.So what are we doing here? Just looking at equation one here, it'snot really clear what's going on. So let's try and do this.So, at time Ti, we have, at time Ti, we have Vi dollars.So this is the value of the trading strategy at time i.So what we're going to do is we are going to hold delta i units of the stock atthat time. And we are going to put the remainder ofour portfolio value, which will be Vi minus delta i times Si into the cashaccount. So if we do that, then at time Ti plus 1.What will we have? Well, we can see we are going to have Vi.So Vi is what we have at the previous period at time Ti.And remember, we hold delta i units of the stock at time Ti, and we're going tohold them until trading at time Ti plus 1.And therefore, we're going to make or lose delta i times the value of thesecurity at time i plus 1 minus the initial value of the security, which willbe Si. So, the value of the security of time Iplus 1 will be Si plus 1 Plus any dividends we get.So what we're doing is here is we're assuming that we're going to get adividend yield of c, so over the period delta t, we're going to get a dividendyield of c delta t times Si. So this represents the dividend paymentin the period ti to ti plus 1. So , the total value of the, of theposition at time i plus 1, or ti plus 1. Will be si plus 1 plus the dividend thatwe obtain. Therefore, the gain on the stock positionwill be this quantity here minus si. Likewise, we would have invested thisquantity into the cash account at time i or time ti.And therefore, we will earn interest at the risk free rate between time ti and tplus 1 according to the rate of or. And so, we would obtain all of thisquantity from our position in the cash account, time ti plus 1.Therefore, the value of the strategy times i plus 1 will be vi or initialvalue. Plus the gain or loss from holding deltai into the security, plus our position in the cash account.So if delta iSi is less then vi, we will be investing money in the cash accountand earning some interest. If delta iSi is greater than vi, youwould actually be borrowing from the cash account.This term would be negative, reflecting the fact that we owe interest to the cashaccount or to the bank that lent us the money.Now I mentioned here that this is a self-financing trading strategy and it'salmost implicit that it is self-financing.And that is because we're seeing that the value of the portfolio time i plus 1 isequal to the value in the previous period, vi plus the gains or losses fromtrading. These are the gains or losses.This is the gain or loss from the stop position.This is the gain or loss from the cash account.Clearly, if you look at this, we're not injecting any new money into the strategyat time i plus 1, nor are we taking any money out.So in fact, the way we have defined this, value process for the trading strategy,it is actually a self financing trading strategy.So at time, t plus 1, Vi plus 1 equals Vi plus gains or losses from trading.And these gains or losses are given to us in x equation 1 here.So this is a self-financing trading strategy.Now, it is a particular type of soft announcing trading strategy.Because the number of units of the stalk, we hold the time I, is equal to the deltaof the option. Remember delta I is short on for thedelta we saw on the previous slide so it's this for a call option.It would be this for a put option. So we're going to hold that many units ofthe underlying security, at time i. So when we adapt this strategy, thisself-financing trading strategy, we are delta-hedging the options.And if we let delta t go to 0. Remember, what we have is, we've got atime horizon, a capital T. Maybe capital T is 1 year, or 6 months,or 3 months. And we're breaking this down into anumber of subperiods, t1, t2, t3 and so on up to tn minus 1.And the length of each interval here is delta t.So what were saying is, if we let delta t go to 0, in other words, if we let n goto infinity then this self-financing trading strategy will actually replicatethe option payoff at time capital T. This is in fact what Black and Scholesshowed in there original paper. Otherwise, if we don't let delta t go to0, but we have to keep it fixed maybe delta t is equal to one day or one week.Then in that case we're only going to replicate the payoff of the optionapproximately. So Vn is equal to the option payoff atthe time t approximately. This by the way assumes that the stigmaperimeter that we use to price the option is.Correct. And this is why, returning to theprevious slide, I emphasize the dependence of the option price on sigma0. The value of sigma that we're usingwithin the Black-Scholes formula over here.In practice, we can't expect to know sigma 0.We can only guess what the true volatility is, what the true volatilityparameter is. So in fact, we can only expect toreplicate the strategy exactly if we know the true sigma 0 and we let delta t goto, to 0. If we assume the wrong sigma 0, then V0and all the delta i's will be wrong. Remember, V0's the initial value of theoption, the call option in this example that's given to us by the Black-Scholesformula. But if we use the wrong sigma 0 insidehere, we're going to get the wrong price. Not only will we get the wrong price, butall of these delta i's will also depend on sigma 0.If you look to the previous slide, you'll see that, in the case of a call option ordelta i is equal to this expression here. And d1, as we see here, is a function ofthe sigma parameter. So if we get the wrong sigma, we're goingto get the wrong d1. And we're going to get the wrong delta aswell. And so, therefore, if we get the wrongsigma 0, we're going to have the wrong value v0, and we'd have the wrong deltaI's. And so, we will not be able to replicatethe option exactly even if delta t went to 0.In practice, as I said, we can't let delta t go to 0, that's because we don'ttrade continuously in practice. So delta t would be fine, maybe one dayor half a day or one week and we can only hope to guess the right value of sigma.So what that means in total is that, we can't exactly replicate an option.We can't hope to replicate an option in practice, because we don't know sigma.And in fact, the true dynamics of the security prices don't follow geometricBrownian Motions or they are not geometric Brownian motions.So the concept of dynamic replication is really only a theoretical concept.That said, it is useful in practice, because we can hope to use these ideas toreplicate option prices approximately, and replicate other, derivative payoffsapproximately. Remember, this strategy here isself-financing. So we can actually always follow thisstrategy, we just have to guess what the correct sigma is to use inside N of d1 toget the correct delta. And we also hope that the initial valueprice was calculated correctly, i.e., that we used the right sigma 0.If we do that, we can hope to replicate the option approximately and sufficientlyaccurately for risk management purposes.

## 011.The Volatility Surface

### 019. The Volatility Surface

We're now going to discuss the volatility surface.If the Black-Scholes model was correct, the volatility surface would be flat.In practice, it is anything but flat. And we're going to see, in this module,what the volatility surface is, how it is constructed.And we're also going to see some of the arbitrage constraints that restrict thevolatility surface on the shapes it can take on in practice.The Black-Scholes model is a very elegant model.But for several reasons, it does not perform very well in practice.The first reason is that security prices often jump.However, this is not possible with geometric grounding motion.A second reason is that security price returns tend to have fatter tails thanthose implied by the log-normal distribution.By fatter tails, I mean the fact that extreme returns are more likely inpractice than you would expect if the security prices actually had loggednormal distributions as implied by geometric Brownian motion.Returns also are clearly not IID in practice.So, if I'm to break any time period, if I was to break any time period up intofinite intervals of time, then if the security price follows a geometricBrownian motion, then log returns would be IID.And this is clearly not the case in practice.By the way, if you want to learn more about geometric Brownian motion, there isa module that we have recorded on geometric Brownian motion that can befound on the course platform. Anyway, for all of these reasons, we knowthat security prices in practice do not follow geometric Brownian motion.And market participants are well aware of the fact that the Black-Scholes model isa very poor approximation to reality. They've certainly known this since theWall Street crash of 1987. I will return to discussing the crash of87 in a, in a, in a while. But it was, maybe, after this crash thatfor many people it became clear that the assumptions of geometric barrier motiondid not hold and that, in practice, people would have to adjust theBlack-Scholes model in an appropriate way in order to trade options.All of that, having been said, we have to point out that the Black-Scholes modeland the language of Black-Scholes is still pervasive in finance.Most derivatives markets use aspects of Black-Scholes to both quote option pricesas well as to perform risk management. So, even though the Black-Scholes modelis clearly not a good approximation to market dynamics, it is still verynecessary to understand the Black-Scholes model if you want to understandderivatives pricing and how derivatives are used in practice.The incorrectness of Black-Scholes is most obviously manifested through thevolatility surface. This is a concept that is found alsothroughout derivatives markets. The volatility surface is constructedusing market prices of European call and put options.Now they can also be constructed using American option prices, but it's a littletrickier. So, we're going to stick with the case ofEuropean call and put option prices. So, these include, for example, optionson foreign exchange and options on the most commonly traded market indices, suchas, the S&P 500, the Eurostoxx, the Dax , the Nikkei, and so on.So, all of these indices have options traded on them that are European options,and so everything we say here will apply to these indices and, indeed, foreignexchange options as well. The volatility surface, sigma K, T, is afunction of the strike K and the expiration, T.It is defined implicitly through this equation here.Where c subscript mkt stands for the market price of the call option.And c subscript bs stands for the Black-Scholes price of a call option.Now, in this definition we're going to use call options but I can tell you thatin the case of European options we could just as easily use put options, we'regoing to get the exact same volatility surface.So we will stick with call options here but again we could just as easily use putoptions as well. So what have we got here?On the left hand side we have the market price of a call option when the currentstock price is s, the strike is k, and the time to maturity is capital T.We can see this in the marketplace. We can go into the marketplace and seehow much this call option is worth. That is the left hand side, over here.On the right hand side, we want to use the Black-Scholes formula for the priceof a call option. Now, we're going to know that all ofthese parameters s, we see that's it's the current stock price timed maturitiesknown, risk free interest rate is known. The dividend, dividend yield can beestimated. The strike is known.And all we're left with, is the implied volatility, sigma K, T, or simply Sigma,as we've been calling it, up until now. So, what we do, is as follows, we equatethe market price of the option with the Black-Schole's price of the option.And we solve for the one unknown parameter sigma.So, when we solve this equation for sigma, we are getting what is called theimplied volatility for the option. Note also that this implied volatilitywould generally depend on K and T. And that is why we've written it as sigmaof K and T. Here's an example of the impliedvolatility surface, as of the 20th of November, 2007, for the Euro Stocks 50index. This, is an index of stocks traded in theEuro zone. It is, there are 50 securities in theindex. And it is, the analog, if you like, ofthe S&P 500 in the US. So, there are several points to, to keepin mind. First of all, we don't see this surfacein practice. What we actually see, is the following.We see a finite number of options in the market place, which strikes andmaturities K1, T1, up as far as, let's say Kn, Tn.So these are the strike maturity pairs for which options are traded in themarketplace. Maybe these values here represent thesevalues of K and T. So, I might see a finite number of strikematurity pairs and I'm plotting them here in the figure.Now, what is done at this point is for each option price, I actually determined,the implied volatility. [SOUND].And I do that by working with this equation here.I have my Black-Scholes formula coded up. I can have it coded up in any language Ilike, in Ora, Python, or Excel. And I see the market price as well.And what I do is, I run a simple calibration or root finding algorithm todetermine what value of sigma will make this equation correct.And that's how I calculate these values here.So, I can get all of these values here and then I can plot these points here asI have shown. At that point, I now have a finite numberof, of these points. What I do is I fit a surface to thispoint. And that gives me my implied volatilitysurface. I need to fit my surface carefully, I'lluse some sort of regression or interpolation, extrapolation procedure tocomplete the surface. And that gives me the implied volatilitysurface. Now, in practice, to get a surface likethis, I would also need to have additional points, as well.And, I might make some assumptions, in order to extrapolate out to the extremeedges, edges both in strike, in the strike dimension and in the time to thematurity dimension. So, that is how I construct my impliedvolatility surface. And as I mentioned in the previous slide,for European options, it doesn't matter whether I use call or put options, I'mgoing to get the same surface. Now, here's a question.Why will there always be a unique solution, sigma K, T to this equationhere? This is equation 2.How do I know that I will always find a unique solution to this equation here?Well, here's why. The first thing to remember is vega, ifyou recall vega. Vega of a call option was equal to Deltac, Delta sigma. And we mentioned that this is alwaysstrictly positive. So, now you can imagine drawing thefollowing graph. On the x-axis we will plot sigma.And on the y-axis, we will plot the option price C of sigma.Now, if this is the zero value then maybe the option starts off here or it startsoff with zero. If it's out of the money but it willstart off, let's say, at this point here, as a function of sigma.And then it's going to grow someway like this.Okay? How do I know it's going to increase?Well, I know it's going to increase because vega equals delta c, delta sigma,strictly positive. So, c is an increasing function of sigma.Now, if I go into the marketplace, I will see the option price in the market.And maybe this will be the option price in the marketplace.So, therefore, all I need to do to find my unique value of sigma is to comeacross here, find out what this value is. And this my sigma K, T.And that is how I know there will be a unique solution to that equation too.I am assuming, of course, that there is no arbitrage with the market price of theoption. Now, if the Black Scholes model werecorrect, then we should have a flat volatility surface with sigma K, T equalssigma for all K, T. After all, remember, the Black-Scholesformula is, is based on the Black-Scholes model.And the Black-Scholes model assumes that the stock price follows a geometricBrownian motion, so that the price at time T in the stock is given to us bythis quantity that I'm writing here, where wT is a Brownian motion.And here, it is assumed that sigma is a constant.So, if the Black-Scholes model is correct, and indeed the price dynamics ofthe underlying security follow geometric Brownian motion, then sigma would be aconstant. And I would get sigma K, T equals sigmafor all K and T. And indeed, it would be constant throughtime. As I compute the vol surface, thevolatility surface on day one, if look at it on the next day, I should still seethe same constant sigma. So, that's what I mean when I sayconstant through time. In practice, however, volatility surfacesare not flat. And they move about randomly.Indeed, options with lower strikes tend to have higher implied volatilities.And we can see this here. Note that the lower strikes are down inthis direction. So, we see the lower strikes tend to havehigher implied volatilities than higher strikes.For a given maturity T, this feature is typically referred to as the volatilityskew or the smile. Notice for any fixed timed maturity T,suppose I take T equals two years, and I look at the slice corresponding to Tequals two years, I'll still see this behavior, where the implied volatilitiesrise as the strike decreases. So, the fact that the volatility surfaceis not constant is another way to recognize the fact that the Black-Scholesmodel is incorrect. It is not close to being right.And the market knows it is not correct. For a given strike K, the impliedvolatility can be either increasing or decreasing with time to maturity.In general, for a fixed K, sigma K, T converges to a constant as T goes toinfinity. Of course, I should mention, in practicewe will only see options with maturities after 2 or 3 years.So, in general, you actually don't observe sigma K, T for T being verylarge. It is also worth mentioning that when Tis small, you often observe an inverted volatility surface, with short termoptions having much higher volatilities than longer term options.And indeed, we see that here to some extent as well.We see that for very small times maturity and for strikes that are fairly low orleast moderate to low, we see the implied volatilities are higher than for longertimes maturity. This actually is often true in times ofmarket stress. In times of market stress there's a lotof worry and concern in the market. People are risk averse.There's a lot of volatility. And, as we know, option prices increasewith volatility. And so when there is market stress, wecan't see short term options having higher volatility than longer maturityoptions. Single stock options are generallyAmerican. And in this case, call or put optionstypically give rise to different surfaces.But I mentioned a moment ago, we're not really go into this.The general ideas behind the volatility surface can be found by just discussingthe case of European options. And indeed that is what we will stick to.Now, the fact of the volatility surface is not constant, emphasizes just howwrong Black-Scholes is. And in particular, how wrong thegeometric Brownian motion model, for security dynamics is.That said, pretty much every equity and foreign exchange derivatives trading deskcomputes the Black-Scholes implied volatility surface for all of the marketsthey're trading in. So, these could be foreign exchangerates, like dollar versus euro or dollar v.yen or euro v. pound and so on.And also, for all the main equity in the states, like the S&P 500, the Eurostoxx,the Nikkei, the Dow Jones, the FTSE, and so on.Not only are the volatility surfaces calculated for all, in all of thesemarkets, they also calculate the Greeks. So, remember, the Greeks are thesensitivities of the option prices with respect to parameters.So we have the delta, the gamma, the vega, the theta, and so on.We can still calculate all those Greeks using the Black-Scholes formula.But we just have to make sure now that when we use Black-Scholes formula, we'reusing the correct volatility, which is a function of the strike and time tomaturity. So, it is, it is, it is interesting tonote how the Black-Scholes formula is wrong, the Black-Scholes model is wrong.Everybody knows it's wrong. It is wrong for a number of reasons.That said, the Black-Scholes model is still used everywhere.And indeed, use of the Black-Scholes formula is often likened to using thewrong number in the wrong formula to obtain the right price.Where does that come from? Well, if we go back to equation 2, thisis what I'm getting at. So, the wrong number is this, sigma K, T.After all, the Black-Scholes model would assume sigma is a constant.So, the wrong number is going into the wrong formula.The wrong formula is the Black-Scholes option price.And it's the wrong formula because, you know, the Black-Scholes model doesn'thold. So, the wrong number goes into the wrongformula to give the right price. The right price is the market price.And of course that is the right price because that's the price of the option inthe marketplace. The shape of the implied volatilitysurface is constrained by the absence of arbitrage.And it is worth making this point here. For example, we know that impliedvolatilities must be greater than or equal to zero for all strikes K andexpirations T. So, therefore, we must have thiscondition here. It is also true that at any givenmaturity the skew can not be too steep. Otherwise, arbitrage opportunities, suchas a put spread arbitrage, would exist. Now, what do I mean by put spreadarbitrage? Well, I'll answer that here.So, lets fix T and lets look at a slice on the volatility surface.So, here I'm going to show you a slice. So, T is fixed.Here is K, the strike. And up here, I therefore have sigma K.I'm going to exclude T from the argument of sigma because we have it fixed in thispicture here. Now, I said that the skew can not be toosteep. Well, what would be too steep?Well, maybe this would be too steep. Why can we not get a skew that is toosteep? Well, the reason is as follows.Imagine we've got two strikes. So, these two strikes, we'll call them K1and K2. Now, imagine we buy a put.Maybe I'll write it over here. Imagine, we buy a put with strike K2 andwe sell a put with strike K1. Well, such a strategy is actually knownas a put spread. So, if I buy a put with strike K2 andsell a put with strike K1, then this is going to have a positive cost.The value of this will be greater than or equal to zero, and that's because K2 isgreater than K1. And so the payoff of the put strike K2will always be greater than or equal to the payoff of the put with strike K1.So, it's value today must be greater than or equal to zero as well.So, therefore, my put spread must have a positive price in the marketplace, ifthere's no arbitrage. However, in my Black-Scholes volatilityworld, if I have a volatility surface like this, then this is going to be sigmaK2 and this will be sigma K1. So, clearly sigma K1 is greater thansigma K2. Remember however, the price of a putoption, so the Black-Scholes price of a put option would be increasing in sigma.And if this skew is to steep, then sigma K1 will be much larger than sigma K2.And the put option with strike K1 will be more expensive than the put option withstrike K2. And that would introduce an arbitragebecause as I said, in the marketplace, the put with strike K2 must be morevaluable than the strike with K1. But if this gets too steep, then in fact,that would be violated and there would be an arbitrage in the volatility surface.So, that's what I mean by put-spread arbitrage.Likewise, the term structure of implied volatility cannot be too inverted.What do I mean by that? Well, again, we can draw another picture,but this time we will keep K fixed. So, T is actually our variable on thex-axis here. This is sigma of T and I'm keeping Kfixed here. Well, this would be an inverted, whatwould be called an inverted term structure of implied volatilities.This is just a slice of volatility surface I showed you a while ago.So, for example, if I come back for a picture, I would fix K.So, maybe I would fix K at 4000. And then I would get this slice here.And this would be the term structure of implied volatilities when K equals 4000so it would be this guy here. If I'm looking at K equals 3800, say,here, I get this kind of term structure implied volatilities and we see that theyhave, it, at and we see that it is inverted at K equals 3800.So, returning to this here, the best way to explain what I mean by call spreadarbitrager is just to make the following point.Suppose [SOUND] r equals c, the dividend yield equals zero.Well, then, in that case, it can be shown mathematically.If there's no arbitrage, then, an option price, let's say, a call option pricewould strike c2 must be greater than the value of a call option price, sorry, acall option price with expiration T2 must be greater than a call option price withexpiration T1, where T2 is greater than T1.So, maybe this point here is T1 and this point here is T2.But if it gets too inverted, the implied volatility for T1 is here.It is sigma T1, and for T2, it is here. And it's the same sort of argument as weused up here for the put spread. If it gets too inverted, then sigma T1 istoo large, relative to sigma T1, relative to sigma T2.And the call option price with maturity T1 would be greater than the call optionprice with maturity T2. And that would be an arbitrage.That only holds mathematically when r equals c equals zero, but the sameintuition holds more generally. you might want to think, by the way, ifyou're interested, why in this situation this must hold.Maybe we'll address that in the forums. So, to summarize, in practice, theimplied volatility surface will not violate any of these restrictions.One, two, and three. Otherwise, there would be an arbitrage inthe market. These restrictions can be difficult toenforce, however, when we are stressing the volatility surface.What we mean by stressing the volatility surface?Well, stressing a volatility surface is something that is often performed in riskmanagement applications. What we do is we have a portfolio ofderivatives, maybe a portfolio of options.We know the current value. And we want to see what will be the newvalue of this portfolio if the volatility surface changes.So, what we might do is shift the volatility surface from its currentsurface to a new surface. That will give us a new value of theportfolio, from which we can calculate the profit and loss.So, this is something people often do in practice.So, it's also an example of a scenario analysis which we saw in an earliermodule, where we shift the underlying security by various percentages.We also shift the implied volatilites by various percentages and recalculate thevalue of our portfolio in these scenarios.And then, compute the profit and loss in these scenarios.So, as I said, this is a very important task for risk management.In derivatives portfolios, we need to be able to stress volatilities.We want to be able to stress volatilities in a manner that is consistent with noarbitrage. And so, when we are moving an entiresurface, we need to do so in such a way that it doesn't violate these noarbitrage conditions.

## 012.The Volatility Surface in Action and Skew

### 020. The Volatility Surface in Action

In this brief module, we're going to show you some videos of how the volatilitysurface moves. We will look at examples during thefinancial crisis and we will see how the volatility surface spiked up during thatperiod. We will also see that the volatilitysurface is not flat. It has a certain shape, i.e.the skew is very noticeable. We will also see the inverted termstructure of the volatility surface. Particularly during times of marketstress and market panic, for example, during the financial crisis.So hopefully this will emphasize to you the importance of the volatility surfaceand how stochastic it is, how far it is from being constant and in particular howthat means the Black Scholes model is far from being a good approximation.What we have here is a three dimensional figure.It is a plot of the implied volatility surface of the S&P 500 on August 1st,2007. Now what we're going to do is actuallyplay a video showing how this implied volatility surface varies through time,right up until January 2009. So before we play let's just make a fewobservations first of all. Along this axis here we have what iscalled the moneyness. Now the moneyness is nothing more thanthe strike divided by the current security price.In this case, the security is the S&P 500 Index.Over on this axis, we have time to maturity measured in days, so in factyou've got times to maturity ranging from just a few days depending on the nextoption maturity at a given time out until 800 days.Now, on the z axis, the vertical axis here, we are plotting the impliedvolatility, so we've plotted it from 10% up as far as 70%.Now, one thing to keep in mind is that on this scale, from 10% to 70%, the impliedvolatility surface on August 1, 2007, looks very flat.It looks like that there's no implied volatility skew here.Well that is not true. That only appears to be the case becausewe are plotting it against a wide range, 0.1 up to 0.7.If we were to plot this surface in the range 0.1 to 0.3, we actually would seethe implied skew. We would see implied volatilitiescorresponding to these strikes here, 1.1, 1.15, and so on.Being maybe 4 or 5 volatility points below, the implied volatilities forstrikes corresponding to .85, and .9 and so on.So you can take my word for it, that there is a skew here, it's just hard tosee because we're plotting it against a range of 0.1 up to 0.7.Another thing to keep in mind here is that we have the date up here.We have August 1, 2007. So this is the start date for the video.We're going to run this up until January 2009.Now the volatility data we're using is coming from the option metrics appliedvolatility database. This database has all the impliedvolatilities on US options, index options, ETFs, and so on.It gives you the implied volatilities at the close of the day, and so that'sanother important point. This video is just showing the impliedvolatility surface at the close of each day.Within each day the implied volatility surface will also be moving around, butwe don't have that data. So we just going to plot the close of dayimplied volatility surface. So the first thing we'll do is we'll justplay the video from the start to the end and then we'll go back and look at a fewperiods in time. So here's the video, you can see itmoving, you can see sometimes the implied volatility surface becomes inverted,sometimes it's not inverted. OK, so you saw during the middle therethat the implied volatility surface got very, very high indeed.In fact it actually rose well above 0.7 or 70%.let's go back a few moments, and see what was going on here.So one moment to look at is back around March, 2008.so if we, we can play it one day at a time here.So you can see that the volatility surface is around, hanging around 20%.Obviously, as I said, there is a skew there, so it's not flat.But, it's around 20% at this point, at this point in time.If we move on we see it starting to rise some more, now if we go on to March 13th,March 14th we see a big jump up. Actually what happened there was thatBear Sterns stock started to plummet. there were worries that it wasn't viable,that it was going to go bankrupt. Then in fact that's what was going onaround here. round this time as well is acquired for$2 a share by J P Morgan. and then the volatility surface came backdown. So now let's roll it forward untilSeptember 2008 which is where the financial crisis really took off.Lehman Brothers went bankrupt, Merrill Lynch was bought by Bank of America andin response to all of this the United States Congress attempted to pass someemergency legislation to effectively bail out the financial system.This was rejected initially by Congress. Let's see what happened that day, let'splay. OK, so now we are into September 8th.Again the volatility surface isn't too high.It's around 20% ish, it looks at that level maybe a little bit higher.It's hard to see the exact levels in this three-dimensional surface.so let's see what happens. September 15th was the date when Lehmanfiled for bankruptcy. So, this is the 11th, so this is the12th, and I think this was a Friday. So, the next date we're going to see isSeptember 15th, which was a Monday. That was the day that Lehman Brothersfiled for bankruptcy, and we see that the volatility surface moves up entirely.But also we see the short term vols really spike up.So, these are climbing up to levels maybe around 40 or 40% plus, again it's hard tosee exactly what levels these are on this surface, but we can certainly see what ishappening. let's keep going on.So, it calms down a little bit, it's climbing, so this is sort of, gettinginto the middle of the financial crisis. 25th, 26th, 29th, so what happened herewas that the Emergency Economic Stabilization Act was defeated in theUnited States House of Representatives, so this was the day when Congressdefeated a bill that was proposed. The idea was that this bill would helpbail out the financial system. Congress defeated it, and so initiallythere was a huge panic in the market on this date.The following date we see it falls back down again.Note, however, that these are still pretty high levels of volatility, up to40% and, and beyond. On some of the days, we are seeing thehighest volatility levels that had ever been seen.So now, we're in October 14th, October 15th, October 16th, and so on.It's worth mentioning that on October 6th to the 10th, that was the worst week forthe stock market in 75 years. The Dow Jones lost 22.1%.the S&P 500 lost 18.2% that week. So in fact we can go back and take a lookat that week. So it started on the 6th.So this was the implied volatility surface on the 6th of October.This was the week, as I said, where the stock market had its worst returns inover 75 years. So all in all a pretty, intense, periodof time in the financial markets. letting the video run we see thingscalming down somewhat, by the end of January 2009, but still these volatilitylevels are much higher then they were before the financial crisis took hold.it's worth also mentioning the Vix index, the Vix index is sometimes called theFear index. It's a widely used market indicatorthat's constructed actually using the options for the S&P 500.So the Vix index is actually constructed using very near terms option.So typically one month after two months. It's also worth pointing out that these,this is what happened to the implied volatility surface of the S&P 500, thisis the most important equity index in the world.If we were to plot the implied volatility surface for individual stocks, individualbanking or financial stocks, or even industry indices, we would see far moreextreme moves in the implied volatility surface.Anyway, so this is just a video showing you what happened to the volatilitysurface, the implied volatility surface of the S&P 500 during the financialcrisis. One of the points to take home is that itis not a constant, as it would be implied by geometric Brownian motion model ofBlack and Scholes. Moreover, it is very stochastic, it movesabout an awful lot. In periods of high market stress,obviously it increases. With the short end or, if you like, theshort time to maturity, implied volatility is rising, much more than theimplied volatilities of longer time to maturity options.

### 021. Why is There a Skew

In the last module we introduced the concept of the volatility surface.And we saw that volatility surfaces in practice tend to have specific shapes.In particular if you fix a timed maturity and you look at the slice of thevolatility surface. Then you will typically see that impliedvolatilities increase as the strike decreases.This is known as the volatility skew or the smile.In this module we're going to discuss some reasons why we see a skew or smilein practice. So recall, this is our example of animplied volatility surface. This is just the volatility surface for aparticular moment in time for a particular underlying security, in thiscase is the Euro stocks index in November, 2007.Martin mentioned before that the way this volatility surface is constructed is wehave a set of options with strikes, and maturities K1, T1, up to say, KN, TN.And what we do is, we figure out the implied volatility.For each of these strike maturity pairs. And we do that, as we said, by equatingthe market price for the option, CMKT. So the market price of the option.KITI, with the Black-Scholes price of the option.So at the current price srckiti and we get sigma.K I T I. And what we do is, we see this in themarketplace, we know all of these parimeters, S R C, can be estimated, K Iand T I. And so we know the Black-Scholes forumla,so the only thing we need to calculate is this.And we explained why we can get a unique solution to this when there's noarbitross. So what we do is we get the impliedvolatility at all of these strike maturity pairs that are traded in themarketplace. Maybe they are these quantities here thatI am plotting. And then I actually fit a surface to allof these points. So that's how I get my implied volatilitysurface. We mentioned, as well, that one strikingfeature of implied volatility surfaces, in general, is the so called skew.That is, if I fix a particular time to maturity.Maybe 2.5. I will see, that, the impliedvolatilities tend to increase. That's it here.They tend to increase as the strike decreases.So this is my slice of the volatilities surface of T equals 2.5.And I can see that these volatilities are increasing, as the strike decreases.So that's called a skew or smile. And after the, the Wall Street crash of1987, this skew or smile behavior started to appear in the marketplaces for variousderivatives markets. And people started wanting to understandwhy these skews were there. And they also wanted to able to buildmodels that produced these skews. So the skew or smile that you see inoptions markets is a very important feature of those markets.So we're going to discuss a couple of reasons for why a skew actually exists inpractice. there are at least two principal excusesfor the skew. First explanation is risk aversion.And this explanation can appear in many guises.For example, security prices often jump, jumps from a downside tend to be largerand more frequent than jumps from the upside.Another guise is that as markets go down fear or panic sets in and volatility goesup. A third reason is simply supply anddemand. Investors like to protect their portfolioby purchasing out-of-the-money put options, and so there is more demand foroptions with lower strikes. So if there's more demand for optionswith lower strikes, then the prices of these options with lower strikes willactually increase. And therefore they will have higherimplied volatilities. Note that in making this argument I amusing the fact that our European option price increases as the sigma parameterincreases. So, all of these three comments here orthree points here reflect risk aversion in some sense.The fact that when markets go down, people get more worried, markets becomemore volatile, therefore options become more expensive.Supply and demand. People want to protect their portfoliosagainst the downside or against negative returns in the marketplace.One way to protect your portfolio, in that situation is to buy out-of-the-moneyputs. And so there's a natural demand for outof the money puts in the market base. Again, that pushes those option pricesup, which is reflected in higher volatilities for these out of the moneyoptions. So these points all reflect risk aversionin some form or another. A second explanation is the so-calledleverage effect. The leverage effect is based on the factthat the total value of the company assets, i.e debt plus equity, is a morenatural candidate. Is a more natural candidate to followgeometric grounding motion, or at least to have IID returns.So let's spend a little bit of time talking about the leverage effect.Let V, E and D Denote the total value of a company, the companies equity and thecompanies staff, respectively. Then, the so called fundamentalaccounting equation states that V is equal to D plus E.So on the left hand side we have V, the value of the firm.This is the value of all of the assets that accompany a firm house.Well, if you think about it for a moment you will see that all of those assets,all the cash flows produced by those assets.Must go to the debt-holders and the equity holders.So therefore, we get V equals D plus E. One way to see this visually as well isto break up the total value of the firm into an equity piece, which we will havedown here. And up here we've got a debt piece.So this is the total value of the company.We've got it split up into equity and debt.And indeed, equation three is the basis for many classical structural models.So we won't be discussing structural models in this course, but I can tell youthat these models are sometimes used to price risky.Or default able debt, and indeed credit default swaps as well.Merton in the 70s was the first to recognize that equity could be viewed asa call option on V withs trike equal to D.And this is valid because debt holders get paid before equity holders.So what Merton was saying is that we can view equity, the equity piece of a firm,or certainly at maturity if you like, imagine that there's some maturity here.Then the equity value at maturity is equal to the maximum of 0 and V minus D.And so what this is doing is a, it's reflecting the fact that the debt-holdersget paid off first. So equity's always the riskiest part ofthe capital structure of a company. So equity holders actually incur lossesbefore debt-holders. So, if a company is being liquidated attime capital 'T' say, then the debt holders must get their money first.And only after debt holders get their money do the equity holders get paid.What they get paid then is the residual, they get V minus D.They only get that if D is less than V. Otherwise the limited liability of sharesAnd equity holders means that they would get zero.So Martin was the first to actually make this point, he then actually was abel tosay, we'll lets maybe model the dynamics of V.Instead of saying let E, the equity piece or the stock price follow a geometricgrounding motion. Maybe we could let V follow a geometricgrounding motion. And then use risk-neutral pricing toactually get the value of the equity. And in turn, use that to get the value ofthe debt as well. So this gave rise to what I calledstructural models for pricing the components of the capital structure in acompany. The capital structure being the equity,the debt, and so on. And by the way, this way of looking atthings is very important. It's playing out right now in the globalfianncial crisis as people are talking about banks failing.And whether equity holders or deposit holders incur the losses.So all of these ideas we're talking about here are actually very relevant to what'sgoing on in the world right now. To see how the leverage effect canactually give rise to the skew, let's do the following.Let delta v, delta e, and delta d be the change in values in v, e, and drespectively. So this might be over some time horizon.T to T plus delta T then the fundamental accounting equation again state that thiscondition. This equation must be satisfied and we'llassume that delta t is fairly small, relatively small so that delta V is alsorelatively small. So now if we divide across this equationby V we get the following here. And then all we're doing is rearrangingthem. We're going to take an E outrside andbring it down here. And take a D outside this term and divideby D over here. So equation four is a way of writing thereturn on the value of the company. So this here is the return on the valueof the company. So if I say, or V for the return in V, soor v, this is return on the equity piece and this is the return on the debt piece.So we see that rv is equal to E over V times rE plus D over V times rD.So, in other words we can actually say that the return on the company.The return on the assets of the company 'rv' Is a weighted combination of thereturn on the equity part of the company and the return on the debt part of thecompany. Now by the way just as an aside for thoseof you that might have studied corporate finance before and capital structurebefore. We're not going to go into taxes andbenefits from taxes on debt and so on. That's another matter entirely.What we're doing here is just trying to understand how the leverage effect cangive rise to the skew that we see in implied volatility surfaces in practice.Alright, so let's, let's come back to, to this.So, what we will do is we'll assume the following.Suppose that the equity piece is substantial, so that it absorbs almostall the losses. So remember, this is how we're thinkingof, of, of our capital structure. We've got our equity piece down here.We've got our debt piece down here. V is equal to D plus E.Now, if E is substantial enough, so that any of these changes in v losses or gainscan be absorbed by e, then that means that delta d will be very small.If delta D is very small then we can do the following.Let's take variances across equation 4. If we do that we'll get the following.We'll get sigma squared v. So this is the variance of the return onthe value of the firm. Is equal to E over V to 2b squared timessigma squared E. This is the variance of rE.Plus d over v 2b squared. Times sigma squared D.Your sigma squared d is the variance of r d plus twice e over v times d over v, thecovariance of rE and rD. However, if the equity component is verysubstantial, so that it absorbs almost all of the loses, and so the debt is notvery risky, then delta D will be very small.And in particular, sigma square D on the covariants of rE with rD will be verysmall in comparison with sigma square E. So in particular, in this situation, thiswill be approximately equal to 0. And so therefore I can get sigma V asapproximate equal to E over V times sigma E.I can rearrange to get sigma E equal V over E times sigma V, remember V equals Eplus D. So if I substitute E plus d in for V.I will get sigma e equals 1 plus D over E times sigma V.And so if sigma V, is a constant. Imagine the value of the assets of reformfollowing geometric value in motion. So, in that case Sigma V is a constant,we'll see that naturally Sigma E will actually increase as V decreases.In other words, even as Sigma V is a geometric grounding motion, then as Vgoes up or goes down, Sigma E will actually change.So, sigma V can be constant, but sigma E will therefore be stochastic, and we willsee that sigma E will increase as the equity piece decreases.And, so, this also explains why you would see a skew in the marketplace.Why you would see volatilities, implied volatilities, being higher for lowerstrikes than for higher strikes. This is called the leverage effect.

## 013.The Volatility Surface and Pricing Derivatives

### 022. What the Volatility Surface Tells Us

In the last couple of modules we introduced the volatility surface.We saw how to construct the volatility surface, and we also discussed the skewand why we might see a skew in practice. In this module we're going to discusswhat the volatility surface tells us. We will see that the volatitlity surfacegives us the marginal risk neutral distributions of the stock price.It does not tell us anything about the joint risk neutral distributions of thestock price at various times. So that is the key part of the volatilitysurface. It is very important to appreciate it.It only tells us the marginal risk neutral distributions of the stock priceat a given fixed time. It tells us nothing about the joint riskmutual distributions. And we will emphasize that in this moduleand indeed in later modules. So recall again this is an example ofimplied volatility surface and just remind yourselves again to make sure wedon't forget. It is constructed as follows, we see aset of strike expiration pairs in the market place.So we have k1 t1 up to k n t n. We see the option prices in themarketplace for all of these. So, we actually see the caller put price,let's say call price c subscript mkt for market of kiti, and that's true for iequals 1 to n. So, we see these prices in themarketplace, and what we do is, we set these prices equal to the Black-Scholesprice with S, r, K, T, C, and sigma of kt.So we set this market price equal to the Black Shoal's price.We know the left hand inside, we know the Black Shoal's formula, we know s r kt.We can estimate C, and so there's just one unknown in this equation, and we canactually back out of this unknown for sigma k i t i.And that will give us the implied volatility at the strike k i andexpiration t i. So that will give us a number of pointson our surface here. And then we fill in the rest of thesurface using some sort of interpolation or extrapolation procedure.I didn't really discuss how we would do this interpretation or extrapolation, butone has to be careful when doing it. So we're going to continue to assume thatthe volatility surface has been constructed from European option prices.We're going to discuss now what the volatility surface tells us and what wecan use it for. Certainly we can use it for riskmanagement purposes. I've mentioned that already.We can do scenario analysis. We can actually stress the volatilitysurface by moving it up or down, or moving parts of the volatility surface upor down. Recomputing the value of a portfolio,computing the pnl, and so on. So, the volatility surface is certainlyused for risk management purposes. What we're going to discuss in the nextcouple of slides, is what can it tell us in terms of being able to pricederivative securities beyond call and put options.So, to answer this question, let's first of all consider, a butterfly strategy.Now a butterfly strategy centered at k, does the following.It buys a call option with strike k minus Delta K.It buys a call option with strike k plus Delta K.And then it sells two call options with strike k.The value of the butterfly, B0, we'll say, at time t equals 0, is thereforegiven to us by this expression here. Where C is the call option price at thestrike K minus Delta K, and maturity T, and so on.And in fact, in practice what we'll be doing is, doing this, using the marketprices, so if you like you can assume that these are market prices.MKT, being shorthand for market. let's also see what the payoff of thisbutterfly strategy is at maturity. So maturity is capital T.Let's get an idea of what this looks like at maturity.So, let's draw a plot. So we will call this the payoff, and wewill call it B capital T, for the payoff of the butterfly strategy at maturity.And along the x axis we will have the underlying security price, which is st,at maturity capital T. And, let's, mark off k.k minus Delta K. And k, plus Delta K.Well, it's pretty straight forward, to see, that this strategy earns nothing, ifthe stock price at time capital T is less than k minus Delta K.It also earns nothing if the stock price at time capital t is greater than k plusk Delta K. Moreover, is easy to see that the maximumpayoff of this strategy is equal to k and it occurs if the stock price itself atmaturity is equal to k. And it grows linearly for values of stplow k and then it decreases down to zero, at k plus Delta K.So, in fact this is the payoff of the butterfly strategy at maturity as afunction of st. Now, a couple of things to keep in mind,the maximum payoff is k. And, if you like, if you're inside thisinterval where you do get a payoff at time capital t, the average payoff willbe k over 2. So the average payoff, if you're paidoff, will be k over 2. Alright another thing to keep in mind, weknow from risk mutual pricing that the fair value of this payoff.This is a payoff at maturity. So the fair value of this payoff atmaturity is the current value of the butterfly today which is B0.We know B0 is equal to the right inside of 6.But from risk mutual pricing this is also equal to the expected value of time 0.Using risk mutual probabilities e to the minus r times t times the payoff.And the payoff we will call B capital T. Now I know I've used b in the past torefer to the cash account. Here it's referring to the butterflypayoff here, and this is our butterfly payoff.So keeping this in mind we're going to get an alternative expression for b0.We have one expression for B0 here in equation 6.On the next line we're going to get an alternative expression for B0 using thisrepresentation here. So what we can say is that B0 is equal toe to minus rt or rather is. It is approximately equal to e to theminus rt. Times the risk neutral probability of stbeing between k minus Delta K, and k plus Delta K times Delta K over 2.Now, where does that came from? Well, if you think about it, it comesfrom this idea here. So the payoff occurs if st is in k minusDelta K. Up to k plus Delta K.So the risk neutral probability of that is q of k minus Delta K being less thanor equal to st, being less than or equal k plus Delta K.So, that's the probability that s t is inside this interval here.Now, were imagining Delta K being small, by the way.In fact, soon we're going to let Delta K go to zero.So we can imagine Delta K is very small. So, this is the probability, the riskneutral probability that st is inside this interval here.We already explained that if s t is in this interval then the pay off you expectto get is k over 2. And indeed that is why we multiply by thek over 2 here. So we have our e to minus r t term, theprobability that st is inside this interval, times the average payoff inthis interval. And so that's how we get this first linehere. It's an approximation, but it is a verygood approximation for small Delta K. Now, if you recall something aboutdensity functions, then you will understand why we're letting q.The risk neutral probability that st is in this interval is equal to the riskneutral density times the width of the interval.So we're saying the risk neutral probability that st is between k minusDelta K and k plus Delta k. That is approximately equal to thedensity, risk neutral density evaluated at k times the width of the interval toDelta K. And that just follows from a property ofPDFs. We actually explain this in one of theadditional modules on, on probability that we also recorded, they're alsoavailable on the, on the plat, course platform.So, remember, if you've got a PDF, in general.So if this is our PDF, f of x. And suppose we want to compute theinterval that the random variable x is inside x0 to x 0 plus Delta X.Well, the density satisfies that the probability, that the random variable xis in, x0 plus Delta x where Delta x small.That's approximately equal to f of x 0 times the width of the interval which isDelta X. This is a standard property ofprobability density function and that's all we're using here.So we're saying the portability that st is inside this interval here is equal tothe density which is ft, times the width of the interval which is 2 Delta K.So therefore we're going to get B0 is approximately equal e to the minus rt.Times ft of k, times Delta K squared. We have a two here, but that counts aswith a two there, and we get a Delta K times Delta K, which is delta k squared.So what we've done now is we've come up with 2 expressions for the value of thebutterfly strategy. We have this expression here in equation6 which is exact. I'm here with this expression here whichis an approximation. But as Delta K goes to zero, thisapproximation also becomes exact. So, what we're going to do is, we'regoing to equate equation 7 with equation 6 and then solve for ft of k.Or in other words, bring ft of k over to the left hand side.So we will see ft of k, is approximately equal to e to the rt, times thisexpression on the right hand side of 6 here, divided by Delta K squared.If we now let Delta K go to 0 in 8. Well, if you recall your, your calculus,you'll see that all you're doing when you do this is actually computing the secondpartial derivative of the call option price with respect to the strike.And so what we're seeing is that by constructing a butterfly strategy whereDelta K goes to 0. We're actually able to come up with arisk neutral probability density function for st, f t is equal to e to the r t,Delta 2 c, Delta k squared. And so.The volatility surface gives us the marginal risk-neutral distribution of thestock price, st, for any fixed time, t. So this is a really interestingobservation. We see option prices for finite number ofstrikes and maturities. We compute those implied volatilities.We then actually fit the volatility surface to those finite number of points.I mentioned earlier that we need to fit the volatility surface very carefully.And the reason is if we want to be able to compute something like f t of k, thenwe're computing partial derivatives and second partial derivatives.So we need to make sure we do things, we fit things very smoothly.This means that, given the implied volatility surface, sigma kt.We can compute the price p0 of any derivative security whose payoff f onlydepends on the underlying stock price of the single and fixed time capital T.Now, maybe I've chosen f. Unfortunately here because I used fsubscript t. F subscript t to denote the risk neutralPDF of st. Here, f, this f here has got nothing todo with this. This is the risk neutral PDF of st.F, here, is just some arbitrary function representing the payoff of somederivative security. So just to be clear, the f that I'm usinghere has nothing to do with the f subscript t on the previous slide.Which was the risk neutral probability density function of st.Why is it we can compute this quantity here?Well, if I know the risk neutral density of st, I can just perform and integrationagainst that risk neutral density to compute this quantity here.So therefore I can compute the price of any derivative security if the payoff ofthat derivative security only depends on the stock price at a single and fixedtime t. And that's because I will know fsubscript t, the risk neutral density for that stock price.And therefore, I can evaluate this expectation on the right hand side.However, knowing the volatility surface tells us nothing about the jointdistribution of the stock price at multiple times t1 up to tn.And this is not surprising since the volatility surface is constructed fromEuropean option prices. And European option prices only depend onthe marginal distributions of st. Just to be clear, the joint distributionof the stock price at multiple times t1, tn, what I'm referring to there is thefollowing. It would be this distribution, t1, up totn, of s, t1, up to stn. So this is the risk neutral jointdistribution of the stock price at times t1 up to tn.And what we're saying here is that we don't know anything about this jointdistribution. The only thing that we can learn from thevolatility surface is the marginal distribution for each individual time t1up to tn. Here's an example.Suppose we wish to compute the price of a knockout put option with time t payoffgiven to us here. So, it's this piece here is like aregular put option. So this is a like a regular European putoption, the maximum of k minus s, t, and 0.However we only get that payoff if the minimum stock price over the interval of0 to capital T is greater than or equal to B.So B here represents a barrier. If the stock price ever falls below B,then this indicator function here becomes 0, and so we get nothing.Remember the indicator function, this indicator function, can take on twopossible values. It takes on the value 1, or 0.It takes on the value 1, if the minimum of st is greater than or equal to B.And that's the minimum over 0 less than or equal to little t, less than or equalto capital T and it takes on the value 0 otherwise.So this is an example of a knockout put option.And the point I'm trying to make here is that, we cannot compute the process ofthis option just using the implied volatility surface.The implied volatility surface will only give us the marginal distribution,marginal risk neutral distribution of the stock price.It doesn't give us the joint distribution.And in order to evaluate this, I would need to compute the following.So if the value of the security is p0. It will be equal to the expected valueusing risk-neutral probabilities e to the minus or t times the maximum of k minusst and 0 times the indicator function of st being greater than or equal to B.And the point I'm trying to make is, in order to compute this expectation.I would need to know the joint risk neutral distribution for the stock priceat all times between 0 and capital T. But I don't know that.I can not compute that risk neutral distribution from the, from the impliedvolatility surface. And so in practice and we'll come back tothis soon. We would need to use some sort of model,some arbitrage free model to estimate the price of this quantity.

### 023. Pricing Derivatives Using the Volatility Surface

We're now going to see how we can use the volatility surface to see how we canprice different types of derivative securities.Obviously, we can use the volatility surface to price European call and putoptions. After all, we actually constructed thevolatility surface using European call and put option prices.But we will see that there are other derivative securities that can also bepriced. These are derivative securities whosevalue only depends On the marginal risk-neutral distributions of the stockprice. So, we're going to see some examples.In particular we will see how to price a digital option.And we will also see how to price a so-called range accrual using theinformation in the implied volatility surface.Suppose we wish to price a digital option, which pays $1 if the time t stockprice, ST, is greater than K, and 0 otherwise.[INAUDIBLE] . We actually know that we can price thesecurity given the implied volatility surface.Now why is that? Well, the reason for that, as we saw inone of the more recent modules, that if you know the implied volatility surface,then you know the marginal risk-neutral distribution of The security processor ona fixed time 'T', so the pay off of this option is going to be equal to themaximum of '0' and the indicative function '1' which pays off '1' is 'ST'is greater than 'K'. So this is the pay off of the digitaloption. So the risk neutral distribution of thisoption only depends on the marginal risk neutral distribution of st.And so we know from the volatility surface that we can calculate thismarginal risk neutral distribution. And therefore, we can evaluate.This quantity here. Which is the initial value of thisdigital option. So lets see how we can actually go aheadand price this. It is easy to see.That the digital price. Were going to call it dkt.K is the strike. T is the maturity.Is given by the following. So dkt is equal to, well we have thislimit as delta k goes to 0, of the s, the market price of a call option with strikek maturity t, minus the market price for a call option with strike k plus delta kand maturity t, all divided by delta k. Now why is that?Well, it's easy to see this if we draw a picture and that's what we'll do.So we will draw a picture. This is going to be our payoff of thisstrategy, so buying 1 over delta K times and option of strike K maturity T andselling 1 over delta K times the call option strike K times delat K andmaturity T T. So this is represents S T, the stockprice at maturity. We have this value here, whchi is K.And we have the value here K plus delta K.Now it is easy to check. That this option, this strategy here, ofgoing long option and shortest option gives a payoff of 0 up as far as K, andthen it grows linearly up to a value of 1.At k plus delta k. And thereafter, gives a constant valueone. And you can see this easily.So you see that if the terminal stock price is greater than k plus delta k.Then you're going to make a profit of delta k from these two positions.Divide that by the delta k here, and you get a profit of 1.So, this is the payoff. And so it should be clear that, as we letdelta k go to zero. Then this line here is becoming more andmore vertical. And we're getting closer and closer tothe payoff of a digital option which pays 1 dollar, only if st is greater than k.And so that's why we get this limiting argument here.So dkt is equal to the limit as delta k goes to 0 with this.We're just going to multiply through by minus 1, take the minus outside here andwe get it's the limit is delta k goes to 0 of this quantity here.And we just recognize this as being the partial derivative of the market price ofa call option with strike k maturity t with respect to the strike k.So it's very straightforward to see that the price of the digital option is givento us by this. Now recall how we defined the impliedvolatility of an option. What we did is, we equate the marketprice of the option with the Black Scholes price.And we figure out what is the implied volatility parameter, sigma of k and t.Which makes the Black-Scholes price match the market price.Just to simplify notation, I haven't bothered to include the other parametersthat I often include here, R C and S 0. So we know that sigma K, T is thevolatility parameter that must go into the Black-Scholes formula so that we geta price on the right-hand side that is equal to the market price of the option.As I said before, sometimes this is likened to Plugging the wrong number intothe wrong formula to get the right price. So now, if you recall from the previousslide. What we need to do is, we need to computethis partial derivative here with respect to k.Well, we know that the partial derivative of this with respect to k is the partialderivative of the right hand side with respect to k.And there are actually two terms that come into this.We see, the first argument. K appears here.But also in the sigma argument. K also appears in there.So were actually going to have two terms corresponding to, to, to k here.So were going to get that the partial derivative, with respect of k.Is equal to the partial derivative of the Black Scholes formula with respect to thestrike. Plus the Black-Scholes formula withrespect to Sigma. Well, that's our vega times delta sigma,delta K. And that's actually what we will call theskew. Of course, we have a minus, because wehave in both terms. Because we had a minus outside here aswell. So, we're going to get D cave T is equalto minus delta CBS, delta K, minus the vega.Times the skew. And so the skew we're just going to referto this as being delta sigma delta k. And remember that for a fixed timematurity. Maturity in the Acuity market we'll see askew like this. So this will be s t or if you like k.Either one. And this is sigma kt.So, we can actually calculate delta cbs, delta k, and the vega from the BlackScholes formula. These are straightforward to compute,because we know the Black Scholes formula.And there, we can compute these derivatives.The skew can be estimated from the implied volatility surface.So we will have calculated our, our volatility surface, and we'll be able toestimate the sku. In other words, we'll be able to computewhat delta sigma, delta k is. For example, suppose this is the strikehere. Well, this, therefore, has.A value of, let's call it Sigma K. Maybe you go up to K plus Delta K.This has a value, Sigma K plus Delta K, and so we can estimate the partialderivative, the skew, or Delta Sigma Delta K...As being approximately equal to sigma of k plus delta k minus sigma k divided by kplus delta k minus k, which is delta k. And of course as I let delta k go tozero, this approximation becomes better and better.So we can approximate. Delta sigma delta k, or if you like theskew we're calling it, from the implied volatility surface that we will haveavailable to us. So this is an example of how theBlack-Scholes terminology, or technology, is used in practice.Even though the Black Scholes model is known to be wrong.We can still compute option prices with, with the, with the Black Scholesterminology. In this case, we're u-, computing optionprices from the implied volatility surface.The implied volatility surface, if you recall, has been set up, so that, byconstruction. Call and put options will match theprices of call and put options in the marketplace.And we're going to be able to use this volatility surface to compute other typesof options as well. And in this case, we're going to computethe price of a digital option. As I also mentioned before, we can usethe volatility surface to price any security Who's payoff only depends on thestock price at a given fix time tee. That is because we know the marginalretribution distribution once we know[UNKNOWN] and we know the marginalretribution then we can compute the derivative who's payoff only depends onthe stock price and a fix time T So here's an example.This example is taken from the book, the Volatility Surface, by Jim Gatheral.It's an advanced text. So I wouldn't necessarily advise anyoneto go out and look at it. It's more of a doctoral text on financialmathematics and financial engineering. But there's a nice example in that textthat we'll go through here. So what we're going to do, is, we'regoing to, we're going to be pricing a digital option.The digital option is, has a strike of k equals 100.The current stock price is 100. So the digital is at the money.Remember, just to be clear, the payoff of this digital time t is equal to.The maximum of zero. And the indicator function of st beinggreater than or equal to k. And the fact if you stop for a second,you can see you don't really need the maximum here because this is simply theindicator function of st being greater than or equal to k.So, if you recall the vega from the Black-Scholes formula, well it is asfollows. We know that vega, I'll write it here.We know that vega is equal to e. To the minus c T times S square rootcapital T times five of D one. Where D one was equal to the, the log ofS zero divided by K. Plus R minus C plus sigma squared overtwo times T divide, all divided by sigma square root T.Now, in this situation, in this example, we're going to assume r equals c equalszero. T equals 1 year.And s zero equals k. So in that case, d is equal to, it turnsout to be simply sigma over 2. And it also implies that the vega, inthis case. Is equal to.While c is zero. S is 100.T is one. So it's five of sigma over two.So what were actually going to do. Is were going to get this as equal to.S0 times 5 of sigma over 2. So now we can go to the To the task athand, which is to compute the price of this digital option.We know this price is given to us by this quantity here.So we can actually calculate delta cbs, delta k from the Black Scholes formula.You can check. But it actually turns out to be thisquantity here. The vega is given to us by s 0 phi ofsigma atm over 2. Sigma atm is the octamum impliedvolatility. And we're told it's 25 percent.Finally, how about the skew? Well, we are told that the skew is 2.5percent per 10 percent change in strike. So a 10 percent change in strike is equalto 10 percent of s zero. Because the strike is equal to s zero.And it's 2.5% per 10% change. So it's going to be 0.025 divided by .1s0. This is the skew.However, we also have a minus sign here. Now the minus sign is, we're notexplicitly told there's a minus sign here.But we know that there must be, because we know the equity markets we see askewlike this. So clearly as, so this is K.Clearly as K increases, the implied volatility falls.So this number here, which if you recall, is delta sigma delta K, that's going tobe negative. And so I implicitly understand that theskew here presents the negative 2.5% per 10% change in strike, and so that's how Iget this quantity here. The S zero accounts with the S zero her.I can evaluate this quantity using, I can do it simply in Excel, and I get adigital price of 0.55... What's interesting is if we ignored theskew component. In other words, if I just took the marketprice, see market price of the call option.To be equal to just the black[UNKNOWN] price, as a function of KT and sigma atthe money. And ignore the fact that sigma is also afuncion of K as we see in this skew here. If I ignore that, then I would only get adelta cbs delta k term appearing. Remember when we take partial derivativeshere with respect to k, we get a term from the k argument.But we also get a term from the implied volatility argument.Because the implied volatility's a function of k.And that's why I get this second term here.But if I ignored the second term, pretend that signal was a constant, that would bethe case of the Black-Scholes model held, then I would only get the 0.45 valuehere. And, so in fact, by taking the skew intoaccount correctly, I see the price of the digital option as 0.55 and not 0.45, andactually this is significant. This represents ten cents extra.On .54 dollars. So consider now a 3 month range accrualon the S & P 500 index with range of 1,500 to 1,550.After 3 months the product pays X% of notional where x equals the percentage ofdays over the 3 months that the index is inside the range.So, for example, the notional is $10M and the index is inside the range 70% of thetime; then the payoff will be $7M. The question is, is it possible tocalculate the price of this range accrual using the volatility surface?The answer is, yes. Consider a portfolio consisting of a pairof digital's For each date between now and the expiration.So, actually lets expand on this answer and see how indeed we can use thevolatility surface to price this range accrual.So lets assume that there are N Trading days in the three month period inquestion. Then the payoff at time t Let's write ithere. The payoff at time T, that's called a Psubscript T, will be equal to 10,000,000 times the summation from I equals 1 to Nof the indicator function. That the underlying security price, we'llcall it si, is inside the range in question and this range is 1,500 lessthan or equal to si, less than or equal to 1,550.We have to divide by n because its the percentage of days that were inside therange. And so we must divide.So this summation is the total number of days that were inside the range that thesecurity price, the underlined security price, in this case the S&P 500, isinside the range. So the percentage of days that wereinside the range is the summation divided by M.So this is the payoff at time, capital T. So how might we price this security?Well, we know, let's write it here. From Risk-neutral pricing that theinitial value of the security is equal to the expected value under the Risk-neutral probability distribution of E to the minus R capital T.Capital T is assumed to be the maturities of To three months.Of times pt. So let's expand on that.This is equal to 10 divided by n. So I'm going to omit the m, formillionths. So now my units are in millionths.So it's 10 over n. Times the summation from i equals 1 to nof e to the minus r times t minus ti. Times the expected value of e to theminus, or ti, times this quantity here. Now, what can we do with this.We'll notice by the way, that I have a minus minus TI which is a plus TI andthat counts as with a minus TI inside here.So let's look at this expression here. So we have the expected value of e to theminus rti, times the indicator function. That 1,500 is less than or equal to si.Is less than or equal to 1,550. Where S I is the underlining securityprice on day I. Well I can write this as the following,this is equal to, E to the minus R T I TImes the indicator function of si beinggreater than or equal to 1,500 minus the indicator function of si being greaterthan or equal to 1,550. So it's quite straightforward to see thatthis indicator function here. One on the event s size between 1,500 and1,550 is equal to the difference of these 2 indicator functions here.And if you think about it, what you will see is that this is equal to.Well, using our earlier notation for the price of the digital option.This is equal to D 1500 on Date TI minus D 1550 on Date TI.And so actually what we've managed to do is we've managed to break down the rangeaccrual into a strip of digital pairs... A different pair for each[UNKNOWN] TI,and so therefore the price of the rang accrual is equal to 10 million dollarsdivided by N, the number of days, times the summation...From i equals 1 to n of e to the minus r times capital T maturity minus t littlei. Times the digital option.Would strike 1500 maturity ti minus the digital option would strike 1550 inmaturity ti. And indeed, we can compute these digitaloption prices from the implied volatility surface as we saw a short while ago.

### 024. Beyond the Volatility Surface and Black-Scholes

In the last few modules we introduced the volatility surface, and we saw how toprice certain types of derivative securities using the volatility surface.However there are many derivative securities that cannot be priced usingthe volatility surface. And that is because the prices of thesederivative securities depend on the joint risk-neutral distribution of the stockprice at multiple times. An example of that is a barrier option.And we're going to see in this module and example of where a barrier option cannotbe priced using the volatility surface. So, we will discuss the limitations ofthe volatility surface, how it can only be used to price certain types ofderivative securities. And how we will need to use models toprice other types of derivative securities.And so in practice, when we need to price more exotic securities, we need to resortto using models. We cannot use the volatility surface thatwe see in the marketplace. Suppose there are two time periods, T1and T2 of interest and then a non-dividend paying security A.Has risk-neutral distributions given by the following expressions here, where inparticular Z1A and Z2A are independent N 0,1 random variables.So, you can see here, that this is the stock price at time T1, this is the stockprice at time T2. So, you've got some horizon here, today'sdate 0. We've got T1 and we've got T2.And we see that the stock price at times T1 and T2 are log normally distributed,and that's because Z1A is a normal random variable.And, the sum of two independent, normal random variables, is also normal.So, we see that the stock price, at each time T1 and T2 is log normallydistributed. Note, that the value of rho A greaterthan 0, can capture a momentum effect, and a value of row A less than 0 cancapture a mean reversion effect. Well, what do I mean by that?I mean the following. So notice the following.Suppose the stock price at time T1 is known to you, and maybe it's a highervalue than you'd previously expected. So, in other words, suppose Z1A isgreater than 0. Maybe much greater than 0.Well, in that case, if rho A is positive, then row A times Z1A will also bepositive. And so on average, this random variablehere will also be positive, in other words the stock price at time T2 willalso be larger than you will have previously expected.So thatâs what I mean by the momentum effect.On the other hand if rho A is negative, then this term here will be negative.And so, you will get a mean-reversion type effect.In other words, if the stock price of time T1 tends to be large, then the stockprice at time T2 will tend to be small and vise versa.So, that would be a mean-reversion effect.So, you can capture a momentum effect, if rho A is greater than 0.And a mean-reversion effect if rho A is less than 0.Suppose now that there is another non-dividend paying security B, withrisk-neutral distributions given by these quantities again, and again we've got Z1Band Z2B being independent N 0,1 random variables.So notice we're implicitly assuming here, that the initial stock price of stock Ais equal to the initial stock price of stock B is equal to 1.We're also assuming that they've got the same volatility parameter.So sigma A equals sigma B equals sigma and so I see sigma appearing here.And it's the same sigma up here. Now here is an observation, if Z1 and Z2are independent N 0,1 random variables, then, then for any rho in minus, in therange minus 1 to 1. Rho times Z1 plus the square root of 1minus rho squared Z2 is also a standard normal random variable.So this is the standard result. It's certainly easy to see that theexpected value of this random variable is 0, and the variance of it is indeed 1.So given this, we can go back to the previous slide and notice the following.We can see that this is N 0,1 and this term here is also N 0,1 and so it isclear that the stock price at time T1 for the two securities A and B have identicalrisk-neutral distributions. And likewise the stock prices at T2 haveidentical risk mutual distributions. And that's the point we're making here.Therefore, it follows that European options on A and B, with the same strikeand maturity, must have the same price. After all, they've got the same marginalrisk neutral distributions, and it is these marginal risk neutral distributionsthat we would use to compute these European option prices.So therefore A and B would have identical volatility surfaces.We've only got two maturities here, but we could price options with manydifferent strikes and so we can say they've got identical volatilitysurfaces. But now consider a knock in put optionwith strike 1. And expiration T2.In order to knock in, the stock price at time T1 must exceed the barrier price of1.2. So therefore, the payoff function isgiven to us by the maximum of 1 minus ST2 and 0, which is the payoff of a regularput option, times the indicator function. Which is 1, if the stock price at time T1is greater than or equal to 1.2, and 0, otherwise.So, you can think of this payoff as follows, or of the security as follows.So, this is time T here, this is the stock price at time T.You can image the stock price starting off at a value of 1.Maybe this is 1.2. This might be time T1, this might be timeT2. And, you can see that in order to get apayoff, what must happen is that the stock price must, some way or another,get above 1.2 at time T1. And then, at time T2, it must be below 1in order to be in the money. So, it can still move about, but its gotto come down, and be below, the strike level of 1.So, this is the strike level, this is our K.And, 1.2 is our barrier level. And the stock price must be above this attime T1, and it must be below 1 at time T2, in order to get a payoff.So now the question we can ask is as follows.Would the knock-in put option on A have the same price as the knock-in put optionon B? In other words, does the value of thesecurity depend on whether the underlying security is stock A or stock B?And also how does your answer depend on rho A and rho B.Well to answer the first question, we know that they've got the same marginalrisk neutral distributions. So, we made this point on the previousslide and we see it again here. So the stock prices at each time T1 or T2have the same marginal risk neutral probabilities.But what about the joint risk neutral distribution?In other words, what is the risk neutral distribution, let's call it fa for stockA of ST1a and ST2b, so this is the joint risk neutral distribution for security aat times T1 and T2. And similarly we've got the risk neutraldistribution, the joint risk neutral distribution for stock b at times T1 andT2. We know these, they have the samemarginal risk neutral distributions. That was the point of the previous slide.But what about the joint distributions? Remember, if we evaluate this option orcompute the price of this option It's going to depend on fa in the case ofsecurity a or fb in the case of security b.So, how does our answer depend on rho A and rho B.Well if you look at this plot here, what you can see is the stock price needs togo up, and then it needs to fall. So, in fact a small value of rho willactually help you achieve that. In particular, you would like your rhoparameter to be as small as possible, because if rho A for example, suppose rhoA, is very small, less than 0, close to minus 1.Well, if z, if the stock price of time T1 is above the barrier 1.2, that means Z1Awould have to have been large. But if Z1A is large then rho a times Z1Awill be negative because rho A is now much smaller than 0.So in that case, this will be negative and therefore you have a much betterchange of this entire quantity being negative.And the stock price of time T2 being below the strike of 1.So in fact a negative value of rho A and the more negative, the closer to minus 1the better, will help the option xbar with a positive payoff.So in fact, the answer to the question is that if rho A is less than rho B, thenthe price, let's call it, let's call it P0a will be more expensive than the priceof the knock-in on B. Similarly, if rho B is less than rho A,then the price of the knock-in on B will be more expensive than the price of theknock-in on A. So, it certainly does depend on rho A andrho B, and what this tells us is that the volatility surface alone, cannot give usenough information to price these options.After all, these two securities, A and B, will have identical volatility surfacesbecause they have the same risk neutral distributions, same marginal risk neutraldistributions. But they have a very different joint riskneutral distribution and that joint risk neutral distribution will actuallydetermine the value of this not input option.And depending on the value of that rho parameter, we're going to get differentprices. So, this is really just another way ofsaying what we said in the previous module, that we can use volatilitysurfaces to price derivative securities that only depends on the marginal riskneutral distribution of the stock price at a fixed time T.But any security who's value depends on the joint risk neutral distributioncannot be priced just using the information in the implied volatilitysurface. Moving on, lets talk about derivativespricing in practice and in general. So we've seen the dynamic replicationtheory of Black, Scholes, and indeed Merton.Its' very elegant, we saw it as well in the binomial model.But it is not possible to dynamically replicate and, therefore, pricederivative securities in practice. And this is for multiple reasons.First of all security prices don't follow geometric bounding motions.We don't know the particular processes that they do follow, nor do we know theexact parameters that govern those processes.It is also true, that you can not trade at every point in time, continuoustrading is not possible in practice, transactions cost would render itimpossible and so on. So, dynamic replication really is onlysomething we can hope to do approximately.Instead actually supply and demand is what sets derivative security prices.This is particularly the case with the most liquid securities like European andAmerican options in the fixed income markets.This is also true of caps and floors, swaptions and so on.We have also seen these securities earlier in the course.And indeed volatility is itself an asset class.Well, what do I mean by that? Well, I mean the following, sometimespeople want to trade volatility. They have a view that volatility willincrease or maybe they have a view that volatility will decrease.In that case they want to buy volatility or they want to sell volatility.And people treat volatility as an asset class.And indeed it is possible to buy volatility by buying a European calloption for example or buying a European put option.We know the value of the European call option or put option will increase, asvolatility increases. Remember the vega, which is equal todelta c delta sigma is positive, so we know that European call and put pricesincrease as volatility increases. So by buying a European call put option,your actually buying volatility. And so volatility is viewed as, as anasset class, you can actually buy volatility.It's also true, by the way, of other concepts, like correlation.Correlation can also be viewed as an asset class, and indeed there aremechanisms in securities out there, that will enable you to actually buycorrelation or indeed sell correlation. So returning to this point, supply anddemand sets the rate of derivative prices in general.And this is true of derivative securities in other markets.Fixed income derivatives, FX derivatives, credit derivatives, commodity derivativesand so on. Most derivative prices in these marketsare determined by supply and demand. That having been said, derivativespricing models are still needed. You need it for two principal reasons.Number one, to price exotic and other less liquid derivative securities.Remember if you have, for example, European call and put option prices, yesyou can use that to construct an implied volatility surface.And you can use your implied volatility surface to price some types ofderivatives securities. In particularly those securities whosepay off only depends on the underlying stock price at a fixed point in time.But there are other more exotic derivative securities like barrieroptions for example, who's value depends on the joint risk neutral distribution.You can not see this in the marketplace. You can not determine it from thevolatility surface. And so you need models, arbitrage freemodels to price these more exotic and less liquid derivative securities.We also need derivatives pricing models to risk manage portfolios of derivatives.So, we can do this via the Greeks or via scenario analysis that we saw earlier.So, when I say via the Greeks, I mean the following.I could have a derivatives portfolio and compute the overall delta, delta P, deltaS. So, P is the value of my derivativesportfolio. S is the underlying security.I can compute delta P, delta S, and this is the delta from my portfolio.And I can actually hedge this exposure to the underlying security by buying somestock. So, for example, suppose this is equal to$10 million. Well, if I then go out into themarketplace and short $10 million of the underlying security, then my portfoliowill have a net delta of 0 and I am delta hedged.You can do similar sorts of hedging with vega risks.Maybe my delta P delta sigma is equal to some quantity.Maybe it's $100,000 say. Well, what I can then do, is, if I wantto, I can go out into the marketplace, and buy or sell a security which has avega of minus $100,000. By adding that to my portfolio, the newnet vega in my portfolio would be zero. And so, in fact, that's how people willoften use the Greeks in practice. They will use it to hedge away risks thatthey don't want. So, that's what I mean when I say, weneed derivatives models to risk manage portfolios via the Greeks.Because we could, we can compute the Greeks from models, like theBlack-Scholes model, for example. We can also risk manage portfolios usingscenario analysis. And we saw an example of this in anearlier module. Where if you recall, we had a portfolioof options on the SMP 500 and we considered various scenarios across thetop. We were stressing volatility, so we werestressing sigma and down here on the, on this axis we were stressing theunderlying security. So, we were able to look at the P and Lin the portfolio as the implied volatility or the implied volatilesurface is moved to different values. Likewise, as the underlying security isstressed or changed to different values. So, in each of these scenarios here, Ineed to be able to recompute the value of my portfolio.And that means actually having a model to recompute the prices of the securities inmy portfolio and calculating the PNL from this scenario.So, certainly derivatives models are needing in practice to price exotic andother less liquid securities, but also to aid in the risk management process.These models are arbitrage by construction and they are calibrated toliquid security prices. We saw an example of calibration when wewere calibrating the Black Derman Toy model to the term structured interestrates. Note however that these models are onlyan approximation to reality. And generally they are not a greatapproximation. For example, witness how often they needto be re-calibrated. I mentioned in the past that when you'rere calibrating these models, often you have to do so several times a day.Of course, if a model was the correct model you'd only need, you would onlyneed to calibrate it once and you would be done with it.No more calibrations would be required In practice people are always having tore-calibrate their models. And that's just another indicator of howthese models are at best only an approximation to the real world.These models also generally completely ignore the endogeneity of markets.What do I mean by the endogeneity of markets?I mean the following, most of these models do not account for the fact thatthe actual trading of these securities can move the prices of these securities.And if too many people enter into a market and all buy the same security,well, that's going to change the price dynamics of that security.In particular, if a market panic occurs, if people become suddenly very concernedabout that security, everybody will try to sell at the same time.And security price will collapse. So, that's what I mean by endogeneity,what the market is actually doing. The trading of that security is going tochange the price dynamics of that security, and this can be an extremelyimportant characteristic of the financial markets.Certainly have played a role in the financial crisis of 2008 and beyond, whenmany people were holding the same types of securities.Many people ran for the exits at the same time, and so the endogeneity of themarkets was actually missed by many participants.All of that having been said, the ideas of dynamic replication have not beenabandoned and they're still useful. These ideas are still used to partiallyhedge derivatives portfolios in the same manner as I explained up here.So, just to summarize, the concept of exact dynamic replication is only atheoretical construct. You cannot exactly replicate a securityin practice. But the ideas of dynamic replication areindeed still useful and they are still used by participants to perform riskmanagement and so on.

## 014.CDOs and the Gaussian Copula Model

### 025. Structured Credit  CDOs and Beyond

In this first module we're going to briefly review securitization.And we will also discuss how CDOs or collateralized debt obligations areconstructed from an underlying pool of bonds.We will of course go into CDOs in much greater detail in later modules we'll seehow to price them and we will also discuss the infamous Gaussian CopulaModel. Recall the securitization is the namegiven to the process of constructing new securities from the cash-flows, generatedby a pool of underlying securities. An we've already seen examples ofsecuritization in the mortgage market. The economic rationale behindsecuritization is that it enables the construction of new securities, with abroad range of risk profiles. The broad range of investors maytherefore be interested in these new securities, even if they have no interestin the underlying securities. And so this results in an increasedamount for the underlying cash flows. This in turn insures that thecost-of-capital is reduced for the issuers of the underlying securities.So for example, in the case of mortgage backed securities by introducing themarket for mortgage-backed securities. We increase the demand for cash flowsthat arise from mortgages, so that we can reduce the mortgage rates for homeowners.Credit default obligations are securities that are constructed from an underlyingpool of fixed-income securities. They were first issued by banks in themid 1990s and their issuance was originally motivated by regulatoryarbitrage considerations. And that is why they were supplied to themarketplace in the first place, back, as I said, in the mid 1990s.This slide displays a schematic describing the construction of a CDO.We have an underlying pool of bonds, we see them here, we've got 125 bonds.And they form the collateral for the CDO. The CDO is then divided into tranchesdefined by their attachment points. So their attachment points are thesenumbers here. 0% to 3%, 3% to 7%.All the way up to say 40% to 100%. So these numbers on the left, 0, 3 up to40, they're called the lower attachment points.The numbers on the right, 3, 7, 100 are called the the upper attachment points.These are tranches, so we have the equity tranche, we have the mezzanine tranche.We get maybe other tranches and we have a senior sometimes called a super seniortranche up here. So these are tranches which investors canbuy, so for example an investor may buy the equity tranche.Let's say he buys the equity tranche for $50, and what will happen is that theinvestor will ultimately receive $100. Say over the lifetime of the CDO, if noneof the bonds in the underlying pool of assets defaults.But if some bonds default, then the equity tranche would have to incur thelosses. And that means that the investor in theequity tranche will no longer receive that $100 I mentioned, but maybe they'llonly receive $75. Or maybe $50.In fact, the number they receive, will depend on the number of losses in theunderlying pool of bonds. In particular, if the losses in theunderlying pool of bonds exceeds 3% of the notional, then maybe they'll getnothing. Right because 3% will exceed this 3%upper attachment point here and so the equity tranche will be wiped out.That doesn't mean that the investor in the equity tranche will receive nothing.Because depending on how the deal is structured, they might receive somepayments before the losses in the underlying pool of bonds occurs.But basically, the big picture here is that an investor can buy these individualtranches. They'll pay a certain amount of money forit. and then they receive some cash flowsassociated with these tranches over the lifetime of the CDO.If any losses arise that impacts these tranches, then they will have to pay somesort of payment because of those losses. We'll get into all of these details inlater modules. In fact, just as an aside, later we willconsider what's called a synthetic CDO. And in that case, you don't buy a tranchefor $50, in fact the payments of a synthetic CDO are structured to work likea swap. So that no cash flows take place at thebeginning of the trade. The important takeaway for now, is thatif you buy the equity tranche, then you are the hook for the first 3% of lossesin the underlying bond pool. If you buy the mezzanine tranche then youare on the hook for losses between 3% and 7% of the notional principal of these 125bonds. So, maybe each of these bonds has anotional of $1. So, then the total notional principal inthe underlying pool is $125. Well, you as an investor in the mezzaninechance will be on the hook for 3% to 7% of 125.So any losses beyod 3% will start impacting the maezzanine chance and anyloses above 7% wil start impacting the chance above the mezzanine chance.It should be clear then that the equity chance is the riskiest tranche of theCDO. And that's because the equity tranche ison the hook for the first losses that occur in the underlying good bonds.Likewise the senior tranche, sometimes called the super senior tranche as Imentioned earlier, is the least risky tranche in the CDO.Because this tranche only incurs losses after all of the other tranches below ithave been effectively wiped out. In other words, the losses have exceededall of the attachment points, upper attachment points.3%, 7%, and so on, and have now entered into the senior tranche.Finally, just one comment here. In practice in order to construct theCDO, the banks that might only underline pool of bonds will often construct what'scalled an SPV. Which stands for special purpose vehicle.This is a legal entity which is bankruptcy remote from the bank thatoriginally holds these bonds. The bonds, the 125 bonds are placed intothis special purpose vehicle... And the special purpose vehicle issuesthe CDO, and the CDO tranches. But we're not going to get into that.This is part of the legal structuring of these, of these CDOs.So this, by the way, is an example, another example, of an asset backedsecurity. You've seen this already in the mortgagebacked security market. This is an asset backed security wherethe assets, the CDOs, are backed by the underlying pool of bonds.If these bonds were instead placed with loans, we would get what's called acollateralized loan obligation. And in fact, this shouldn't be credit, itshould be a collateralized loan obligation.So these are securities that are constructed from the underlying pool ofloans. The structured credit market was at theheart of the financial crisis. We saw terms like ABS, MBS, CDO andABS-CDO's, all these terms became standard in the financial.And indeed the mainstream media during the height of the financial crisis.Our introduction to structured credit and CDO's will do several things.Number one it will provide further examples of the securitization process.Number two, it will allow us to introduce the infamous Gaussian Copula Model.Which came in for an awful lot of criticism in the mainstream media as wellas the financial media during the financial crisis.We will discuss the difficulties in risk managing structured credit portfolios.We will also emphasize just how crazy some parts of the financial market havebecome in the lead-up to the financial crisis.Now it's also worth pointing out that the mechanics of how CEOs work have much incommon with the mechanics of how a default swaps.And you already have seen credit default swaps.So it's probably worthwhile reviewing and making sure you understand credit defaultswaps and their mechanics. Before, continuing on with these moduleson structured credit and CDO's. One final point I'll mention, is that ifwe're ever going to control the excesses in the financial system.Then I think we're going to need a much better understanding of finance outsidethe finance industry, and certainly the whole, the whole area of structuredproducts. Securitization and so on is consideredsomewhat mysterious to some people who are not in the financial industry.So I think even understanding the mechanics of securitization, the risks ofthese new securities is important for people who don't work in finance.But for politicians, journalists, lawyers and so on.So, I think that's another benefit of studying securitization, and studyingCDO's as we're going to do in the next several modules.

### 026. The Gaussian Copula Model

In this module we're going to discuss and introduce the Gaussian Copula model.This model came under a lot of criticism during the financial crisis.So it's very much worthwhile introducing it here, and seeing how the GaussianCopula model actually works. We're going to use it to construct theprobability distribution of the number of losses in a reference portfolio of bonds.This reference portfolio will be the portfolio underlying CDOs and CDO chancesthat we will discuss in later modules. We assume there are N bonds, or credits,in the reference portfolio. Now, I use the word, credit, here becausesometimes that is how the underlying bonds in the pool are referred to.So a credit can refer to a bond or it can refer to a company like General Motors,or Ford, or so on. So I'm going to use bonds and creditsinterchangeably here. Each credit has a notional of Ai.This is in dollars. However, sometimes it can be expressed asa percentage of the overall portfolio notional.If the ith credit defaults, then the portfolio incurs a loss of Ai times 1minus Ri. Where Ri is the recovery rate that is thepercentage of the notional amount that is recovered upon default.Now, we've seen this already in the context of credit-default-swaps.From a modeling perspective Ri is often assumed to be fixed and known.In practice however, it is random and not known until after a default event hastaken place. We're also going to assume that therisk-neutral distribution of the default time of the ith credit is known.And in fact this can be estimated from either credit-default-swap spreads or theprices of corporate bonds. Therefore we can compute qi(t), therisk-neutral probability that the ith credit defaults before time t for any t.So we're going to assume that we know these probabilities for all of the names,all of the bonds in the portfolio, and for any time t.Remember, for credit default swap, you can actually compute the term structureof spreads or premier, so this is t. This is the fair spread in thecredit-default-swap, and you might see some function like this for differentmaturities. And so, you can back off from this whatthese qi of t's are. So, we're going to assume that these qiof t's are known to us. So now, let's discuss the the GaussianCopula model. We're going to let Xi denote thenormalized asset value of the ith credit. So, Xi you can think of if you like asreferring to Di plus Ei. So, this the debt plus equity of the ithcompany. As I've said, the company could be Ford,or General Motors, or Volkswagen, or any company you like.We're going to assume that Xi is equal to ai times M plus the square root of 1minus ai squared times Zi, where M and the Zi's are standard ith ID normalrandom variables. Note, note also that each Xi is also astandard normal random variable. Each of the factor loadings, ai, isassumed to lie in the interval 0, 1. It should also be clear that thecorrelation of Xi, Xj is equal to ai times aj.And this follows because the correlation of Xi with Xj is in this case, equal tojust the expect value of Xi times Xj. And that is true because the Xi's arestandard normal random variables, which means the have mean 0 and variance 1.So normally I compute the correlation as being the covariance divided by thesquare root of the product of the variances.Well the variances, in this case, are 1. So now I don't have to divide byanything. The, the covariance is the expected valueof Xi Xj minus the expected value of Xi times the expected value of Xj.But the expected value of Xi and Xj is 0. So therefore the correlation is justequal to this term here, and clearly then this is equal to ai, aj, times theexpected value M squared. And M is a standard normal randomvariable, so the expected value of M squared is equal to 1.And so that's how I get this expression here.It should also be clear that the Xi's, our multivariate normally distributed, anwe'll use that as well, in a moment. We're going to assume that the ith credithas defaulted by time ti, if Xi falls below some threshold value xi bar.An that's a function of ti, but generally will just refer to xi bar.By our earlier assumption, it must therefore be the case, that Xi bar equalsphi inverse of qi of ti, where phi is the standard normal cdf.Why is this? Well if you recall, we said that qi, wesaid qi of t is the risk-neutral probability of default by time t.We also said that the ith credit defaults by time ti if Xi is less than or equal toxi bar of ti. What the probability of this occurring,we know is equal to phi of xi bar of ti. Because the Xi's have a standard normaldistribution. So this is equal to phi of xi bar of ti,but we also know it's equal to qi of ti. And so therefore we see that xi bar justapply phi inverse to both sides of this equation, we see that xi bar of ti isequal to phi inverse of qi of ti. We're going to let capital F of t1 up tot capital N denote the joint distribution of the default times of the n credits inthe portfolio. Then we know that F of t1 up to tn mustbe equal to the following. It's equal to the probability that X1 isless than or equal to x1 bar of t1, all the way up to Xn being less than or equalto xn bar of tn. Because this is the event that X1 up toXn defaults before times t1 up to tn, respectively.However, X1 up to Xn is a multivariant normal distribution.So this is equal to phi P, the phi is in bold so that represents a multivariatenormal distribution. P refers to the covariance or in thiscase the correlation matrix. And it's got a mean 0 as well, and it'sevaluated, the arguments of this multivariate normal CDF are x1 bar of t1up to xn bar of tn. So that gives us this line.And now we just substitute n for these x1 bars using this expression here, andthat's how we get this equation down here.So, believe it or not, even though this is very simple, there's lots ofnotations, so on, but it's actually very simple to, to derive this expression,given our assumptions. What we have is the infamous one factorGaussian Copula model. So this here give us the one factoraspect Gaussian Copula model. It's one factor because we just have onerandom variable m driving the dependent between the Xi's.If we go back to the previous slide, we'll see m appearing here.M is a random variable that is uncommon to all of the XI's.So all of the correlation between the XI's comes from this random variable M.If we introduced a second random variable, say n that was also common toall of the XI's then we would end up with a two factor Gaussian Copula Model.The next task is to actually compute the so-called portfolio loss distribution.In order to price credit derivatives and CDOs in particular, we need to be able tocompute this portfolio loss distribution. So that's our first goal here.The first thing we'll do is we'll note the following.That if we condition on the random variable M, then the n default events areindependent. And in particular the defaultprobabilities conditional on the random variable M are given to us by theseexpressions here. Now where does this come from?Well, this comes from the following, we know that qi t of M or t given M is equalto the probability that Xi is less than or equal to xi bar of t given M.Well, we know what Xi is equal to. So we can substitute n for Xi.This is equal to the probability Xi is equal to ai times M, plus the square rootof 1 minus ai squared times Zi, is less than or equal to xi bar of t, given n.So this is then equal to the probability that Zi is less than or equal to xi bar,t minus ai, times M divided by the square root of 1 minus ai squared.And that's all conditional on M. Now if you think about it for a secondconditional on M, if we condition on M as we have here then everything on the righthand side here is a constant. Zi is a standard normal running variable.So this just becomes the probability that a standard normal running variable isless than or equal to. This expression here, and so that's equalto phi of what we have inside here, so that's what the conditional risk neutraldefault probabilities are. There are qi of t given n's.Now let P superscript n, l of t denote the risk neuter probability that thereare a total of l portfolio or defaults before time t.We may then write pl of t as being the integral for minus infinity to infinityof p superscript n l of t given M times phi of MdM where phi is the standardnormal PDF. Now if you're wondering where thisexpression comes from, well, this is just a standard basic undergraduate expressionfor probability. In discrete form, you can imagine thefollowing. Suppose we want to compute theprobability that X is equal to little x. Well, a standard way of doing this is toconsider another random variable y, and to sum over all possible values of y.So it's equal to the probability of X equals little x, and Y equals little y.And this is also equal to the sum over little Y of the probability that X equalslittle X. Given Y equals little Y by theprobability that Y equals little Y. So this is a standard expression youprobably all seen before in your undergraduate probability class.We're just using this here and. In density form rather than discreteprobability mass function form. So M here takes the place of y.So we have our m here, taking the place of y over here, and so instead of asummation, we have an integral. And we're integrating with respect to minstead of summing over the y values here.So this is standard, so we can now write the probability of l default, and just tobe consistent, I should have put a superscript n there.So the probability of l default out of the n names by time t, is given to us bythis integral here. So the next task is going to be how do wecompute this quantity? We know phi of M, it's just the standardnormal density. So, we need to compute this quantityhere. We can compute this quantity, then we canevaluate this integral numerically, and therefore compute this risk-neutralprobability function here. So let's focus on how to compute thisexpression here. So, in fact, we can easily do it using aniterative procedure, and the iterative procedure will work as follows.So the first thing we're going to do let's initialize.We're going to have to run a couple of for loops here.So let's initialize our quantities first of all, we're going to set p 0.Given M to be equal to 1 minus q1 of M. We're going to set p1, given M to beequal to q1 of M. And we're going to set p2 given M to beequal to P3 given M all the way up to Pn given M.We're going to set all of that equal to 0.Now, what I'm doing here is, I'm dropping the dependence on n and t here.So, I don't want the slide to get too cluttered.If I did I'd have an n in all of these values here.And I'd have a t in here, and so on. But that's just going to get reallycluttered. So, I won't do that.So, I'm dropping the dependence of these quantities on n, and t.So, now we're going to do the following. We're going to run the following forloop, we're going to say. For i equals 2 up as far as n.And, for j equals 1 to i. I am going to update these quantitieshere that i have already initialized. In particular I am going to say.P, j given M so this is the probability of j defaults, conditional on M.So this is going to represent the probably of j defaults in the first inames. So there, there are two ways we can get jdefaults in the first i names. We could have j minus 1 defaults in thosefirst i names, and having the ith name defaulting.Which is represented here or we could have had j defaults in those first inames. And then having the ith name notdefaulting. So that's the end of this for loop.We must also handle the, the case of 0 defaults.So we must also update that. We get the probability of 0.Given M is equal to whatever the previous value was or the value in the previousiteration. Times 1 minus qi of M.In other words, what I'm really doing here.So this is the end of the, of the algorithm.What I'm really doing here is I'm lining up the names.I'm ordering them from say, 1 all the way up to to nth names.I know the risk neutral probability given n for all names.And I'm going through these names these credits in order starting with 1, all theway up to value capital N. I'm doing that via these two for loopshere, and I'm updating the probabilities at each step.So, as I said here, so if I'm at this point, for some value of i and some valueof j, what I'm doing is the following. I'm now going to update the probabillityof the j defaults. In the portfolio based on the first inames. So, the way j defaults can occur amongthe first i names is that j minus 1 defaults occur in the first i minus 1names. Remember this value here is the valueleft over from the previous iteration. Which considers the names from 1 up to iminus 1, so I get this equals the probability of j minus 1 defaults in thefirst i minus 1 names. Times the probability that the ith namedefaults, plus the probability of j defaults in the first i minus 1 names, bythe probability that the ith name does not default.And so I can just run through these two four loops to compute pN l of t, given M.So in other words, at the very end once I get up to , N, i equals capital N and jequals i at the end of this procedure I have the probabilities that I want.And now at this point, we can perform a numerical integration on the right handside of 2 to compute Pl of t. So this is Pl of t here.I now have computed all of this using that iterative procedure, and I can donumeric integration to calculate this quantity here.And there should be a super script in there as well.If we assume that the notional ai. And the recovery rate ri are constantacross all credits, then the loss on any given credit will be either 0 or a times1 minus r. Therefore knowing the distribution of thenumber of defaults is equivalent to knowing the distribution of the totalloss and the reference portfolio. And that's because l losses on that caseis equivalent to a loss of l times a 1 minus r and the portfolio of bonds and soknowing one implies the other. So this, the assumption of constat Ai'sand Ri's actually simplifies the calculations, and we're going to beassuming that through out here. But I will mention that this assumptionis easily relaxed. We could actually get by without it.

## 015.A Simple Example

### 027. A Simple Example  Part I

In this module, we're going to look at a simple CDO example, where there's justone period in the model. We're going to assume that all the bondsin the reference portfolio have the same risk neutral probability of default.We'll also assume that all the pair-wise default events have the same correlationparameter rho. So these simplifying assumptions willenable us to easily calculate the loss distribution in the bond portfolio, andwe will use it to compute the expected tranche loss in some tranches of a CDU.So in this simple example we're going to consider it is going to be a one periodCDO. CDOs in practice are over multipleperiods, but here we're just going to consider a one period CDO.The maturity is one year, or if you'd like one period.We'll assume that we've got 125 bonds in the reference portfolio.in case you're wondering why are choosing a number like 125, and not a, a, a st,more standard number like 100. Well, that's maybe a legacy of what goeson in the synthetic CDO market which we will discuss later.In those portfolios you often get 125 bonds in the so called referenceportfolio, and that's why we're using 125 here.We're going to assume each bond pays a coupon of one unit.After one year, and that is if it has not defaulted.The recovery rate on each bond is 0, so in fact, if a bond defaults at any timeover the next year, then the bond will pay 0.If it doesn't default then the bond will pay one unit.In one year's time, at the end of the CDO.We will assume that there are three tranches of interest.The equity, mezzanine and senior tranches.So the equity tranche is always the tranche which has a lower attachmentpoint of zero. The senior tranche often has an upperattachment point of 100. But here we're actually going to assumethat the senior tranche is exposed to default numbers seven up as far as nine.In fact, maybe a super senior tranche would be represented by these dots here,which would contain the defaults, or be exposed to the defaults.Num-, from numbers 10 up to 125. I will mention at this point, that thisexample we're considering is taken from this paper, the Devil is in Tails,Actuarial Mathematics and the Subprime Mortgage Crisis, by Donnelly andEmbrechts. This is a very nice paper.It discusses CDOs, subprime CDOs, the crisis.It's a little bit technical in part, but much of it is readable for anundergraduate audience, and I'd certainly recommend those of you who are interestedin learning more to go ahead and take a look at this paper.It can be easily found online. We're going to make the simple assumptionthat the probability q of defaulting within one year is identical across allbonds. We're also going to assume that thecorrelation between each pair of default events is identical.So these assumptions plus the fact that the maturity is one year and that this isjust a one-period CDO is what makes this example particularly easy to analyze.As before, we assume X i is the normalized asset value of the ith credit.Or the ith bond, and now we're going to write that X i is equal to the squareroot of rho times M plus the square root of 1 minus rho times Z i.Where M, Z 1 up to Z n, are IID normal random variables.And recall that this assumption also implies that X i is also standard normalmean zero variance one. Recall that the ith credit defaults if Xi is less than or equal to little x i bar.Therefore, the probability that the ith main defaults, is equal to theprobability, we write it up here that X i is less than or equal to little x i bar.This must be equal to phi of little x i bar, because x i is the standard normalrandom variable, and phi's the standard normal CDF, so this is true.But we're all assuming that this is also equal to q.This is the probability of defaulting within one year, so this is equal to q,and from that, we see that if I take phi inverse across both sides of thisexpression here, I see x i bar equals phi inverse q.And that's what we down here. So the probability that x i defaultsconditional on M is going to equal to the probability that X i is less than orequal to little x i bar. I can substitute equation three in downhere. Replace x i bar with phi inverse q.Take the M term over to the right hand side, divided by the square root of 1minus rho, and I get this expression here.This is what we're going to call q subscript M, this is going to be the riskneutral probability that X i defaults, conditional on knowing the value of therandom variable M. What is also clear, is that this is equalto the standard normal CDF evaluated at this value here.Because Z i is a standard normal random variable.Therefore, conditional on knowing the value M, the total number of defaults isactually binomially distributed with parameters n, the number of names in theportfolio, the number of credits, the number of bonds and probability q M.Why is that? Well if you think about it, conditionalon knowing M, we've already seen what's the probability of default is, it's q M.But also conditional on knowing M, all of these default events become independent.Because X i depends on M and Z i, and Z i, the Z i's are IID normal randomvariables. So, if I condition on the value of M,then the X i's become independent, which in particular means that the defaultevents of all of the names in the portfolio are also independent.The probability of default conditional on M is q M.So therefore, the total number of defaults in the portfolio condition on Mhas a binomial distribution with parameters of M and q M.So therefore the probability of l defaults, and note I've dropped thedependence on t here which is fine. Because we're just considering one periodwith t equals one year. So therefore the probability of ldefaults, out of the n names in the portfolio.Or n credits in the portfolio, conditional on the value of M isbinomially distributed. And this is equal to N choose l times q Mto the power of l, times 1 minus q M to the power of N minus l.Where phi we said in the previous slide is the standard normal CDF, and we knowthis expression for q M as well. Recall the q the risk neutral probabilityof a single name default within one year. So just be clear.You shouldn't get confused between q and q M.Q is the risk-neutral probability of a single name defaulting within one year.And qM is the same probability that is the risk neutral probability of a singlename defaulting within one year, conditional on the value of M.So here are two questions. The first question is the following, whencorrelations on default probabilities are not identical, why is four no longervalid? Well, that's because, if the correlationsan default probabilities are not identical, then these qM's are not thesame for all of the names in the portfolio.You end up having a different qM, for each of the N names.So this quantity here is no longer a binomial.Random variable or a binomial probability.Next question, how do we calculate P superscript N l M in that case.Well, we'll just do it as we did in the last module, we saw that we had aniterative algorithm, remember we had the two nested for loops.That was the way, how we calculate P N of l in general.In this example, we don't need to run through those two for loops, because herewe can just use the fact that the qMs are identical for all names I equals 1 tocapital N. And therefore this is a binomialprobability and we know this expression. [SOUND] So at this point, in thisexample, we actually know this quantity here.This quantity is a binomial probability. Assuming we can calculate q M, and we canbecause q M can be calculated as this expression here.We know these binomial probabilities, and so in particular we know the risk neutralprobability of l defaults occurring conditional on the random variable M.How can we use this knowledge? Well, we can use it to compute theexpected tranche losses. And that's what we're going to do in thisslide. First of all, maybe I should go down toequation five first. So remember, what we're going to say isthe following. The probability of l losses.Is equal to the probability of l losses given M times phi M and integrate thatwith respect to M. That's just using this trick we mentionedbefore from our undergraduate probability course.If I want to know the probability that X is equal to little x, well I can do thatby summing over y the probability that X equals little x, Y equals little y.Which in turn is equal to the sum over little y of the probability that X equalslittle x given Y equals little y, by the probability that Y equals little y.So here we're identifying M with the random variable Y, and instead of asummation, we have an integral. But that's all we're doing here.So we know how to compute these quantities, we saw that on the previousslide, that these are binomial probabilities.So these are binomial probabilities and therefore we can do a numericalintegration to calculate p of l. For any value of l equals 0 up to capitalN. So we know that p of l's, we can do itvery easily by integrating this expression numerically.So now let's turn to the issue of computing the expected tranche losses.In the equity tranche, we can actually lose either zero, one, two, or three.So the expecwe, expected equity tranche loss will be, k equals 1 times theprobability of one default by year end. Plus k equals 2 by the probability of twodefaults by year end. Plus k equals 3 by the probability ofthree or more defaults by year end. Remember the equity tranche is on thehook, if you like, for the first three losses in the portfolio.So, the most that the equity tranche can lose is actually three.But it will lose three if we have three or more defaults by year end.And so that's how we get the expected equity tranche loss.Let's turn, for example, to the expected senior tranche loss.Well, the senior tranche can only lose one, two, or three.You see back here that the senior tranche is on the hook for defaults seven tonine, so the most it can lose is nine minus, actually six, which is seven minusone, is three. So it's on the hook for these threedefaults, seven, eight, and nine. So some that hope for three units, themost it can lose is three units. It will lose nothing if there are lessthan or equal to six losses in the portfolio.It will lose one, if there are exactly seven losses in the portfolio.It will lose two if there are exactly eight losses in the portfolio, and itwill lose three. If there are nine or more losses in theportfolio. And that's represented over here in thisexpression for the expected senior tranche loss.So you should make sure that you're very comfortable and understand where theseexpressions come from. The equity, the equity tranche is on thehook for the first three losses. The Mezzanine tranche is on the hook forthe next three losses. So, those losses will be lost as four,five and six. The Senior tranche is then on the hookfor the next three losses, which would be losses seven, eight, and nine.And so these are the expected tranche losses for each of those three tranches.

### 028. A Simple Example  Part II

In this module,we're going to continue on with the example we introduced in the last example.That was the simple model, it was a one period model with identical risk mutualdefault probabilities for each bond in the reference portfolio, and so on.So what we're going to do here is we're going to look at some of the tranchelosses or the expected tranche losses.And we're going to look at the characteristics of these expected tranchelosses as a function of the correlation parameter rho and so on.We're also going to see how the total expected losses in a portfoliodoes not depend on the correlation parameter rho.So recall the details for our simple example.We want to find the expected losses in a CDO, or in CDO tranches,with the following characteristics.The maturity is 1 year, andit's just a 1-Period CDO, there are 125 bonds in the reference portfolio.Each bond pays a coupon of one unit after one year, if it has not defaulted.And the recovery rate on each bond is zero.So in particular, if a bond has defaulted before the one year is up,then that bond will pay a coupon of zero.There are three tranches of interest, the equity, mezzanine, and senior tranches.The equity tranche is exposed to defaults 0 to 3,the mezzanine tranche is exposed to defaults 4 to 6, andthe senior tranche is exposed to defaults 7 to 9.We saw in the last module that we couldactually compute the expected tranche losses.We saw our expressions for the expected loss in the equity tranche, the expectedloss in the mezzanine tranche, and the expected loss in the senior tranche.So, on this slide, we're actually going to see what these expected losses are asa function of rho, which is the common pairwise correlation between the variousname in the portfolio, and the individual risk mutual default probability.So this is the q = 1%.So this corresponds to the case where the probability of each individualname defaulting is 1%.So there's 125 bonds in the portfolio,we assume each of them defaults would probability equal to 1% here.Over here, each of them default to probability q=2%,down here, 4%, and over here, 3%.And on the y-axis we have the expected losses.Note, we have 125 names in the portfolio.Each name will pay one unit, if it hasn't defaulted after one year.So therefore, the total portfolio notional is 125.The equity tranche is on the hook for the first three losses, sothe equity tranche can lose a maximum of three.The mezzanine tranche is on the hook for losses 4, 5, and 6.So the maximum the mezzanine tranche can lose is also three.Likewise, the maximum the senior tranche can lose is also a three.It's on the hook for losses 7, 8, and 9.So the maximum loss in any of these tranches is three, and that's why youdon't see in any of these cases anything greater than three on the y axis.Across the x -xis, we're actually plottingthese expected losses as a function of the correlation parameter rho.So this is that value rho we saw in the last module,which defines the normalized asset value, xi.So there are some important observations we should make here.The first observation is the following.Regardless of the individual default probability, q, and correlation parameter,rho, we see that the expected equity tranche loss is greater than orequal to the expected mezzanine tranche loss, is greater than orequal to the expected senior tranche loss.Now this only holds when each tranche has the same notion exposure,in this case three units.So we see it here.We see the blue line,which is the expected tranche losses in the equity tranche, is always greater orequal to the red line, which corresponds to the mezzanine tranche,which in turn is always greater or equal to the senior tranche, expected losses.And that makes sense.After all, we can see that the equity tranche is the riskiest.You can only lose, the mezzanine tranche can only lose,if the equity tranche has already lost everything.In other words, if you have four defaults, the mezzanine tranche loses one unit,then that means we've had more than three losses, andthe equity tranche has lost everything.Similarly, if the senior tranche is to lose anything, than that can only bethe case if we have seven or more losses, which means the equity andmezzanine tranche have already lost everything as well.And so we should be absolutely certain andunderstand why the expected losses in the equity tranche must be greater than orequal to the expected losses in the mezzanine tranche, must be greater than orequal to the expected losses in the senior tranche.Another important observation is that the expected losses in the equitytranche are always decreasing in this correlation parameter, rho.So we see it here.So let's pick q=2% for example.If we look a q=2%,we can see that the equity tranche losses is a decreasing function of rho.And in fact it's true in all four graphs, it's always a decreasing function of rho.Why might this be the case?Well, one easy way to see this, perhaps, is the following.Imagine two possibly different values of rhos,so imagine rho being equal to 0, or rho being equal to 1.Well, if rho is equal to 1, well, then what happens, either all of the names,all of the credits default together, or none of them default together.So in that case, the equity tranche will actually be as risky as the seniortranche, because either all of the names default or none of them default.The probability of all of them defaulting will therefore just beq = 1% in the 1% case, or 2 in the 2% case, and so on.So in other words, let's considered this example here.So the q=1% case, for numerical reasons we didn't take the value of rho all the wayequal to 1, but we can look at the value rho = 0.99 to see what's going on.In these case, either all the names default together or none of them default.In that case, the three tranches are all equally risky, andso the probability of any one defaulting is 1%.So the expected losses in the tranche is going to be 1% times 3, which is 0.03.So this value here is roughly 0.03.On the other hand, if rho equals zero, well because there's no correlationamong default events, we'll always expect there to be maybe just one default orone or two defaults or zero defaults.But what it means is that most of the time we're actually going to see a default,maybe one, maybe zero, but sometimes two or three.And so with such a low correlation,we'll always expect to see some credit event happening.And because it's the equity tranche that is on the hook for that first creditevent, we expect the equity tranche to incur losses most of the time.And that's why we see this number being much higher for a low value of rho.And in fact we'll see this behavior for all values of q.Down here for example, we see q = 4%.And we see the expected tranche loss is now almost 3,and that's because we expect with q = 4%,we expect there to be 4% of 125, which is 5.So we expect to see on average five losses in the portfolio.Because correlation is very low down here,we're always going to expect to see almost five losses in the portfolio,which means that most of the time the equity tranche will be wiped out.We're going to see more than three losses.Most of them we're going to see four or five losses maybe.So, that's why it will be wiped out.Down here, for example, when rho equals 0.99,sure, we do on average expect to see 4% losses,which corresponds to 5 port-names defaulting.But they're all going to default together or not at all.Which means 96% of the time, in fact, the equity tranche won't be hit at all,and only 4% of the time will it see a loss of 3.4% of 3 is 0.12, so this number here is roughly at the 0.12 level.So that's the first two observations.Another observation to note is the following,mezzanine tranches are often relatively insensitive to rho.We can see that, for example, perhaps most easily in this plot, when q = 1%.Which in many cases in practice might be the most relevant example,because in practice, depending of course on the nature of the names inthe portfolio, you will often see a q of approximately 1%.So you see here that actually certainly maybe in this rangehere that I am circling,You see that the expected tranche losses don't very much with rho at all.And actually this is a commonly observed phenomenon.Also, it actually has implications when it comes to model calibration.Now we're not going to get into model calibration forthis Gaussian Copula model, I might say a few words about it in a later module,but generally we won't have time to go into it in any detail.So that's the third observation here.So I have two more observations I want to make, butI'm going to make those observations when we change the problem slightly.In the remainder of this module, we're going to assume that the seniortranche is now on the hook for all losses between 7 and 125.So, it's not between 7 and 9, it's all losses between 7 and 125.What we will see then, and we'll see it on the next slide,is that the expected loss in this senior tranche,sometimes called a super senior tranche, will see that it's increasing in rho.And sure enough we can see that.So this is the green here.We see it is always increasing in rho, regardless of the value of q.And actually the reason for this is the same reason whythe equity tranche expected losses are always decreasing in rho.So the same intuition I gave will actually also apply in the opposite directionto the expected losses in the senior tranche.The final thing to note, and this might not be so obvious from the figure,because I'm not giving you the individual numbers.But the total expected losses on the three tranches,that is, the expected losses on the index.Remember, all of the index, now the index consists of all 125 names.And the three tranches are equity, 0 to 3,the mezzanine tranche, 3 to 6, and now the senior orsuper senior tranche is 7 to 125.So now these three tranches now all add up to entire index, all 125 names.And the point I'm making, and you can see it on the next slide,is that the total expected losses on the three tranches is independent of rho.This is not an accident.So what am I getting at here?Here's what I'm getting at.Let's pick this figure here q=3.If I fix a value of rho, say rho equals 0.1,and sum of the losses for the three tranches at rho equals 0.1,I'll be summing up maybe this number plus this number, plus this number.And that will equal to the losses at any other value of rho.So if I take rho equals 0.7, then this, this and this number here,the sum of these three, will be equal to the sum of these three numbers over here.Why is this occurring?Well, we can analyze it.We can show that this is no accident as follows.The expected losses, the expected losses using the risk mutual probabilities,so the expected total loss, Isequal to the expected value of the sum of the lossesfrom i equals 1 to 125 of the indicatorfunction that the ith bonder name defaults.I'll just use the capital letter D and E F to denote default.Now, I would normally multiply this by Ai(1-Ri), but,by assumption, we have said that the Ais are equal to 1.And the Ris are 0, so in fact this term here is just 1.So in fact, I can ignore this piece here, and I get that.Well this is just equal to the sum,From i = 1 to 125 of the expected value,Of the indicator function of the ith name defaulting.This is equal to,The sum from i = 1 to 125 ofthe probability of the ith bond defaulting.And, the important thing to notice here, is that this,the probability of the ith bond defaulting, well, this is equal to our q,but this certainly does not depend, On rho.And so we see that the expected total loss in the portfolio,which is equal to the total loss and the sum of the three tranches in this case,is equal to this quantity over here, and that does not depend on rho.And that's why we see this behavior I was describing a moment ago.However, it is worth pointing out that the allocation of these losses tothe three tranches, the three separate tranches, does indeed depend on rho.We can see, as before, that the expected tranche losses in the equity pieceare decreasing in rho, this will always be the case foran equity tranche with lower attachment point equal to zero.Similarly, we can see that the expected tranche lossesin the senior tranche are always increasing in rho.And this is true for any senior tranche with an upward attachment point of 100%,or in this case 125 units.

## 016.Understanding a CDO Tranche

### 029. The Mechanics of a    Synthetic    CDO Tranche

[BLANK_AUDIO] . In this short module, we're going todiscuss the mechanics of a synthetic CDO tranche.While we haven't actually described for you what a synthetic CDO tranche is yet,we will actually do that in a later module.In particular, we will distinguish between a cash CDO and a synthetic CDO.But for now, we're just going to go into the details of the mechanics, of how asynthetic CDO tranche actually works. So now let's discuss the mechanics of thesynthetic CDO tranche. I'm going to describe or explain for you,the distinction between a synthetic and a cash CDO in a later module.For now we're just going to discuss the details of a synthetic tranche.As I said, I will distinguished between the synthetic and a cache CDO, in thelater model. So recall there are N credits in thereference portfolio. Each credit has the same notional amount,A. If the ith credit defaults, then theportolio incurs a loss of A times 1 minus r.Where R is the recovery rate which is assumed fixed, known, and constant acrossall credits. A tranche is defined by the lower andupper attachment points, L and U respectively.So, we've already seen examples of L and U, L and U, 0 to 3 and so on.3 to 6, 6 to 9. Usually L and U are given as percentagesof the total portfolio notional amount. In our simple example on the previous twomodules, L and U were given as the number of losses.0, 1, 2, or 3, 4, 5, or 6, 7, 8 or 9, or so on.But, typically in practice, they're given as percentages.The tranche loss function, TL for tranche loss, superscript l and u, to denote thelower and upper attachment points are parameters of this function.So its a function of the number of losses in the portfolio L, is a function givenas follows. First of all we take the minimum of LA1minus R and U. So this, here, is actually the totalportfolio loss. So if the total portfolio loss exceeds U,then the tranche loss is given by U. After all, the tranche cannot lose morethan U. U is the upper attachment point, itcannot lose more than U. So if the total portfolio loss exceeds U,then this minimum is given to us by U. Otherwise the minimum is given by thetotal portfolio loss. Now the lower attachment point is L, sowe then have to subtract L from this minimum here.And finally we take the maximum of that last quantity and 0, and that gives usour tranche loss. It tells us for a given number ofdefaults, what loss is suffered by the tranche.So for example, suppose L is 3% and U is 7%, so we've got some sort of CDO asfollows, maybe there's an equity piece here, which is the 0 to 3%, we've got amezzanine tranche, which is maybe 3 to 7, and so on.Well, suppose the losses in the portfolio add up to 5%.Well, in that case, this piece represents the losses in the portfolio.The first 3% of losses are incurred by the equity tranche.But the next 2% of losses fall in here, and they are incurred by this tranchehere, with lower attachment point l equals 3%, and upper attachment point Uequals 7%. So, therefore, the tranche loss is 2%,and actually, that's 50% of the tranche notional.The tranche notional is 7% minus 3%, which is 4%.So, we've incurred 2% losses out of a total maximum loss of 4%.So, therefore, in this example we have lost 50% of the tranche notional.When an investor sells protection on the tranche, she's guaranteeing to reimburseany realized losses on the tranche to the protection buyer.In return, the protection seller receives a premium, at regular intervals from theprotection buyer. These payments ticky, typically takeplace every three months. So, when you see the word protectionhere, what you might want to do is think of it as being insurance.So protection, think of this as insurance.And what's going on here, is that one person is selling insurance, and theother person is buying insurance. So the person who's buying insurance, isinsuring against losses, in the underlying portfolio that impact theirgiven tranche. In return for providing insurance, theinsurance seller receives an insurance premium.And they receive that premium at regular intervals, from the protection orinsurance buyer. In some cases, the protection bar mayalso make what is called an upfront payment, we're not going to be concernedabout this. But sometimes they might make enoughfront payment, in addition to, or instead of the regular payment which might takeplace every three months. This is often the case, for example, inthe case of equity tranches which, as I said earlier have a lower attachmentpoint of zero. The fair value of the CDO tranche, isthat value of the premium plus upfront payment, if applicable, for which theexpected value of the premium leg equals the expected value of the default leg.So, just like a swap, the initial value of a CDO tranche position is 0.Now, if this doesn't seem very clear to you yet, that's fine, we're going to seea diagram of the next page, which will make it clearer still.And then in the next module, we're going to go through the premium leg and thedefault leg in more detail, so that hopefully the two legs of a CDO trancheposition, should become clear to you, and you understand exactly what is going on,with a CDO. Another point I want to make is thefollowing. We have already seen the tranche lossfunction, we're going to need to compute the expected tranche loss function, nordid it compute the value of the CDO. We actually already computed this, in ourearlier example, our one period example. We computed the expected tranche loss inan equity tranche, a mezzanine tranche, and the senior tranche.Well, the expression we used for that was just this ex, this expression here.So, it's equal to the sum from L equals zero to capital N, T L T of L times theprobability of L losses in the portfolio. And remember, we can compute thisprobability by conditioning on the random variable M, which makes the defaultevents of each name independent. So, we're, we were then able to computethis quantity, either using the iterative.In that case for a simple example, we saw that this was just a binomialprobability. But either way, we can compute this.This is the standard normal PDF, so we can compute this quantity using anumerical integration. So this gives us our expected trancheloss function. So now let's see what happens visuallywith a CDO. We've got a number of periods, so we'vegot a period here, here, here and so on. This is the premium leg.So these are the payments made by the person, or investor, who buys insurance,or buys protection. S is the annual premium, or spread perunit of notional. These here, are default events.We will see in the next module, that the tranche notional decreases after eachdefault. So, we, these vertical arrows representthe size of the payment. Because S is an annual spread, we have tomultiply be delta T, which is the length of an interval.Typically approximately one quarter, representing payments every three months.So the, the, the premium per quarter will be delta TS.It's paid on the notional of the tranche, and in fact it's paid on the outstandingnotional on the beginning of each period. So at this point, there haven't been anydefaults yet, any default's that have impacted to tranche yet.At this point we have a loss, and this loss impacts the tranche, so thisactually decreases the notional of the tranche, by an amount of 1 minus RA.and so we get decreased payments, after each default event.So a second default event occurs here, this default event also impacts thetranche, and that lowers the outstanding notional in the tranche.And so the insurance payments, or the premiums, are payed only on theoutstanding notional in the tranche. As I've said in the previous slide, thisis just a schematic, describing basically what goes on in the CDO.We have two legs. We have the premium leg, and we have thedefault leg. If you like, you can think of this likebeing a swap, where we've go the fixed payments and we have the floatingpayments. The fixed payments correspond to thepremium leg, they're not always fixed. The rate is fixed, the delta TS, butthey're paid on the outstanding notional. The default lagger like the floatingpayments, you're never sure what you're going to get in each period.Most of the time you'll get nothing, if there hasn't been any default event inthe tranche. But if there has been a default eventthat impacts the tranche, you will receive a payment.You will receive an insurance payment, for that event of 1 minus R times A.And we will see in the next module, that the way the CDO is priced, or in otherwords, the way the S value is calculated. It is calculated by equating the value ofthe premium leg with the default leg. And so the initial value of an investmentin a CDO tranche would be zero, and we're going to find what value of S makes thatvalue equal to zero.

### 030. Computing the Fair Value of a CDO Tranche

In the last module we saw the mechanics of a synthetic CDO tranche.We saw there was a premium leg and a default leg.Well, in this module, we're going to price the premium leg andwe're going to price the default leg.We're then going to set these two prices equal to each other.And as a result,we will be able to calculate the fair premium of a CDO tranche.So let's start with calculating the fair value of the premium leg.The premium leg represents the premium payments that are paid periodically bythe protection buyer to the protection seller.These payments are made at the end of each time interval andthey're based upon the remaining notional in the tranche.In this sense it is different to a CDS since the latter contractends as soon as a default occurs.Here in the CDO.A CDO can survive well beyond an initial default.Multiple names can default and the CDO, the CDO tranche,may need to pay out upon each default event.Formerly the time T equals 0 value of the premium leg,which we're going to call P subscript 0, 0 denoting T equal 0 on superscript,L U which refers to the lower and upper attachment points respectively.So this quantity is equal to what's on the right inside here of expression six.So we have s which is the annualized spread orpremium pay to the protection seller.So this would be a percentage, it might be 2%, it might be 3%, or it might be 10% fora chance where you expect to see many losses.But maybe it'll just be a quarter percent orsome very small number as well for a chance which is relatively safe.DT is the risk free discount factor for payment day T.Delta t is the accrual factor for date t.So typically, delta t would be approximately one quarter corresponding toquarterly payments and is the total number of periods in the contract.So for example, if the CDO lastsor has a maturity of ten years and payments are made quarterly.Then this implies n will be equal to 40.So what's going on here is that the fair value of the premium leg.This is the fair value of the premium payments made over the n payments.It's equal to S times delta t.The sum from t equals 1 to n of S times delta t.Remember, S is an annual spread or premium, sowe've gotta multiply it by delta t to get the payment made per period.So it's S times delta t.Times the expected notional remaining between periods T(-1) and T.So, remember the total notional of the is U minus L.So if U is 7% and L is 3%, then the total notional of the is 7 minus 3 equals 4%.The total losses in the tranche can't exceed U minus L.So this expression here is equal to the expected.Notional remainingat time period t- 1.And so the insurance, the s times delta t is made on this expected notion.Those payments, which occur at time T, they must be discountedback to time zero, and that's why we have this risk free discount factor here.Now I should mention I'm not going to worry about accrued payments and so on.And practice default events don't take place at the beginning orend of a three month period.They might take place in the middle.And maybe you might have some accrued payments as well butwe're not going to get into that.The other leg of the CDO tranche is the default leg.The default leg represents the cash flows paid to the protection buyerupon loses occurring in the tranche.Formerly, the time t equals zero value of the default leg,which we're going to call DL subscript zero for t equals zero,superscript LU, satisfies this equation here.Again, DT is the discount factor.Be the sum from t equals 1 to n, representing the end periods in the CDO,and so payments occur when there is a default in the tranche.And the expected payments at time t, is given to us by this.Because if you think about it, this is the expected tranche loss at time T minus 1.This is the expected tranche loss at time T.So the difference is the expected tranche losses in the periodfrom t minus 1 out to t.So these are the expected payments that must be paid bythe seller of protection or the seller of insurance by time t minus 1 and t sothese are the risk mutual expectant losses and the charge between these two periods.And we have to discount them back to time zero, using the discount factor in Dt.So while some programming is required,we can actually calculate these quantities very quickly.If I go back to the previous slide,I can see that I also have an expectation of a chance loss appearing here as well.So the key to computing the premium leg value andthe default leg value, is being able to compute these expectations here.Now if you recall, just a reminder since we know,that the Tranche Larousse function is given to us as follows.We know that TL subscript t superscript L, U, it's a function ofthe number of defaults in the underlying pool of bonds or pool of credits.We know that that is equal tothe maximum of the minimumlA(1-R) comma u minus L and 0.Now the only random variable in here is L, the number of losses in the portfolio.We also note that the expected value.Of the tranche loss,at time t, is equal to the sum,from l = 0, up to capital N TL Lu,T(l) times pl(t),pl(t) we saw in the one-factorGaussian model.This is equal to the integral from minus infinite to infinite of p superscript n,l, t, given M times the probability density functionfrom standard normal random variable, phi M, dM.And finally we saw that in general we could compute this.Using our iterative algorithm.That was the algorithm with the nested for loops, if you recall.We had a for, I think it was for i = 1, up as far as n.And then we had for j = 1 to i, and so on.So if you think about it, the big picture here is as follows.We want to be able to compute the fair value of a CDO tranche.In order to compute the fair value of a CDO tranche, we need to be able tocompute the fair value of the premium leg, the fair value of the default leg.And what we're going to do is we're going to set those two fair values equal toeach other to get the fair value of the spread s.But before we do that, we need to be able to compute the expected tranche lossfunction, and we can see, as we've written here, that this expected trancheloss function ultimately comes down to computing this integral here.And we can do this numerically.So, while we do need some programming, we do need to write some code to actualcompute this quantity, we can actually get it to run very quickly.And, in fact, this is the principle reason forthe Gaussian Copula model's popularity.It has many flaws, we may discuss a couple of them in later module if we have time.But the reason it's so popular is because it enables us toprice very quickly a security that is in fact very complex.Remember, in a CDO tranche, we might have a 100 names ora 125 names in the underlying portfolio.Each of these names have different risk neutral probabilities of default atvarious times.They all have different pair wise correlations and so on.It's a very complicated product, a very complicated security with many movingparts and this Gaussian copula model enables us to price the premium leg andthe default leg tranche very efficiently in practice.Okay let's move on to the final slide here.How do we compute the fair value of a tranche?Well, just like a regular swap, what we do is we determine the fair premium Sstar say, so that the premium leg is equal in value to the default leg.And so all we do is we equate six, which is this, this isthe fair value of the premium leg, we're going to equate this leg, With the fairvalue of the default leg which is given to us by 7, and we're going to solve for S.And we're going to call that solution S*.And so we get S* equals to this expression here.Now one thing to keep in mind with this expression here.This expression here is modeled independent.We did not need a model, we did not need a model to compute S*.S* follows just by grading the premium leg with the default leg, andthe quantities we need to actually compute S*, are these expectations here.I mentioned in the previous slide that we can compute these expectations numericallyvery easily using the Kopler model.So this is where a model comes in.So we need our model for this piece.Okay, and it's the Kopler model which became the standardin industry for computing these quantities.So as is the case with swaps and forwards,the fair value of the tranche to the protection buyer and seller at initiation,at the beginning of the contract, is therefore zero.It is easy to incorporate any possible up-frontpayments that the protection buyer must pay at time t equals zero.In addition to the regular premium payments.So that's also easy to handle but we won't get into it.Actually, it's also possible to incorporate recovery values andnotional values that vary with each credit in the portfolio.Here we've assumed that R i is equal to a constant R for all i.And we've also assumed that notional value A i is equal to A for all i.But again I just want to emphasize that we could still use the Kopler modeleven if these assumptions didn't hold.In practice, the way it works is similar to what we sawwhen we were looking at the implied volatility surface for equity options.In practice, we actually don't compute S star.We actually see S star in the marketplace.There would be a market for these tranches in the marketplace.We would see the fair spread as star in the marketplace.And what we would try and do is back out a correlation parameter,let's call it rose say, which meant that this right inside, or that the modelfair price S* or row was equal to the S* that we saw in the marketplace.And then row would be called an implied correlation parameter.So very analogous with what we saw with equity options andcomputing implied volatilities for a given strike and maturity.One point that's worth emphasizing is thatif this Gaussian [INAUDIBLE] model was somehow correct,then you should see the same correlation value for different tranches.In other words, suppose I compute the fair correlation fora chance with attachment points, say 3% and7% and then I can back out a correlation parameter row.Well I should see the same row if I change 3 to be 7 and I make 7 equal to 10 say.In other words, if the model was correct I should see the same value ofrho regardless of what values of L and U I use.But in practice this is not the case.We see a different applied correlation for different attachment points L and U.And in fact it's possible in some circumstances to not be able to backout and apply the correlation parameter at all.

### 031. Cash and Synthetic CDOs

Up until now we focused mainly on synthetic CDOs, well we haven't actuallydescribed yet what a synthetic CDO is, and we haven't compared it to what a cashCDO is. In this short module we're going todiscuss first cash CDOs, and then we will discuss synthetic CDOs, and describe thedifferences between these two types of CDO.The first CDOs to be traded were all cash CDOs, where the reference portfolioactually existed, and consisted of corporate bonds that the CDO issuer,usually kept on it's balance sheet. Capital requirements then meant thatthese bonds required a substantial amount of capital to be set aside to cover anypotential losses. Now sometimes the banks however oftenwanted to reduce these capital requirements.They didn't want to tie up capital with these bond portfolios.So, what they did instead was they converted the portfolio into a series ofCDO tranches, and they sold most of these tranches to investors.They usually kept the equity tranche for themselves.And therefore they actually kept most of the economic risks and rewards of theportfolio. If you recall, the equity tranche is theriskiest tranche. It has a lower[UNKNOWN] .0 and it couldhave been 0 to 2% or 0 to 5% or some such number.And so, most of the time many of these tranches or CDOs, all of the losses wouldhave occurred just in this equity tranche.So, effectively the equity tranche, incurred all of the economic risk andreward of the portfolio. However, by selling off these othertranches, the banks were able to reduce substantially the amount of capital theyneeded to set aside. And so, they're able to keep on theeconomic risk and reward, which is what they want to do, but they did not need toset aside an enormous amount of capital. And so, these first CDO deals weretherefore motivated by what is called regulatory arbitrage considerations.The idea is that they are arbitraging the regulations.Which said they would need to hold a substantial amount of capital for thiseconomic risk. But in fact what they did was, they justtranche the portfolio up, kept the riskiest tranche here, which meant theykept pretty much all of the economic risk in the portfolio.And they were able to substantially decrease the capital requirements withjust holding this piece of the portfolio. So, that's what regulatory arbitragerefers to. The cash CDOs however, must be managed,and the legal documentation can be lengthy.You've got what are called waterfall structures to manage and design.You've got what's called credit enhancement and so on, an other importantfeatures. So, what for example is a waterfallstructure? Well a waterfall structure, describeswhat happens to coupons prepayments for example, in the event of a loan pool or amortgage loan pool underlying the CDO. you might have some derivativessecurities inside the CDO in order to change some of the characteristics ofthe, the underlying cash flows. Maybe you've got some floating rate bondsin the underlying pool of bonds, and you want to convert them into fixed-ratebonds. Well you could use an interest rate swapto do that. So, you will often have extra factorsinside a cash CDO that need to be managed.Credit enhancement, on the the hand, refers to many CDOs.The issuer of the CDOs may want the traunches to receive better creditratings. a credit enhancement refers to methodsfor doing this. One common way of doing creditenhancement is to over-collateralized the CDO.What that means is, if the nominal notional of the CDO, say, let's say it's$100 million is the nominal notional of the CDO.Well the bank might actually put $101 million into it, so there's an extramillion dollars. And that extra million dollars would bereferred to as an overcollateralization amount.So, there is different ways to make the, the tranches seem a bit safer andtherefore, to get higher ratings from the rating agencies.We don't have time here to go into how these ratings agencies actually ratedthese CDOs, but I think it's fair to say that they didn't do a very good job ofthis. these structures are very, verycomplicated, the waterfall structures make them even more complicated.And the idea that you could actually create models To actually understand theriskiness of the securities is, is, is somewhat, somewhat optimistic to say theleast. But as I said we wont go into this issueany further. Once these cash CDOs came into the marketplace, it became clear. That there was an appetite in the marketplace for these products. Hedge funds, for example, were often verykeen to buy the riskier tranches, the equity tranches.And that's because the equity tranches having the most risk, also have thegreatest expected reward, or expected payoff in the future.So, hedge funds were often keen to buy the riskier tranches.Insurance companies and so on, often sought to purchase the triple-A ratedsenior and super-senior tranches. Remember, these senior and super-seniortranches are the safest tranches. So you rarely expect to see any lossesentering into these tranches. And so they're considered very safe.They were typically triple-A rated products.But maybe by selling insurance, on these senior tranches.The insurance setters might get 10 or 15 basis points more than they would getfrom buying triple-A rated products out in the marketplace.Maybe by buying triple-A corporate bonds. Maybe the coupons on those triple-Acorporate bonds, were just a little bit less than the premium they could earn byselling protection on triple-A rated senior and super-senior tranches.This appetite and explosion in the CDS market gave rise to so called synthetictranches, where the underlying reference portfolio is no longer a physicalportfolio of corporate bonds or loans. Instead, it was a fictitious portfolioconsisting of a number of credits with an associated notional amount for eachcredit. If you were confused by the distinctionbetween cash and synthetic CDOs, Imagine a series of football games for example.So, lets suppose Barcelona are playing, I don't know lets say Bayern Munich,Aresenal are playing AC Milan, Real Madrid are playing Manchester United.And let's say Juventus are playing Paris Saint-Germain.So, we've got four games here. Now, what we can do is, we can actuallybet, or speculate or, if you like, invest or hedge on the outcomes of these fourgames. And we can do that without anyoneactually owning these games. In fact, I'm not even sure what it meansto own a game. But it certainly doesn't stop us fromconstructing a bet, or a payoff, or a security, whose cash flows depends on theoutcomes of these four games. So, now you can imagine doing the exactsame, but instead of having these four football games.We replace them with four credits, maybe General Motors, maybe Ford, maybe IBM,maybe Siemens. And now we can construct securities whosepayoff depends on what happens to these securities.So, that's how a synthetic CDO works. We don't own the underlying bonds.We don't own, there isn't a reference portfolio of bonds on GM, Ford, IBM andSiemens and so on that the bank owns. We just refer to these credits, just likewe don't own these football games, we can still bet on the outcome of these games.Likewise we can invest in traunches whose payoffs depends on what happens toGeneral Motors, Ford, IBM and Siemens. And in particular whether these companiesdefault or not over a specified period of time.And, so, that's what I mean by a fictitious portfolio.We, there doesn't have to be an underlining physical portfolio of bonds,of the GM bonds, Ford bonds, IBM bonds and Siemas bonds.We can just see these names out in the marketplace, we can see at any pointwhether they've defaulted or not. And we can construct securities who'spayoffs depend on the default events of these underlying names, or thisunderlying fictitious portfolio. The mechanics of a synthetic tranche areprecisely as we described earlier. When we introduced the Gasling-Copplermodel, and we looked at that one period example, we were actually pricingsynthetic tranches. We were computing the expected trancheloss, on such a synthetic CDO. there are at least two features thatdistinguish synthetic CDOs from cash CDOs.Number one, with a synthetic CDO, it is no longer necessary to tranche the entireportfolio and sell the entire deal. For example, a bank could sell protectionor sell insurance, on a 3% to 7% tranche, and never have to worry about selling theother pieces of the reference portfolio. This is not the case with a cash CDO.In the case of a cash CDO, the bank would own all of the underlying bonds.If it's sold to the 3 to 7% tranche, let's say this one, it would still thenbe on the hook for the equity tranche and these tranches up above the 3 to 7%tranche. This is not the case with the syntheticCDO, because the underlying portfolio doesn't exist in the first place.The bank is just selling protection on a not, on a 3 to 7% tranche.And as I said it doesn't have to worry about selling the other pieces of thereference portfolio. But because of this we come to issue two.Because the bank no longer owns the underlying bond portfolio, it is nolonger hedged against adverse price movements.It therefore needs to dynamically hedge its synthetic tranche position.Typically we might do this or would have done this in the past using the CDSmarkets. But hedging and risk managing CDOportfolios is very difficult in practice. And this is true regardless of whether ornot you have a good pricing model. There are simply too many moving parts,there are too many names in the portfolio.There are too many individual default probabilities, you've got differentindustries and different correlations between securities and differentindustries and so on. These are very complicated securities andvery difficult to hedge dynamically and risk manage.

## 017.CDO Portfolios

### 032. Pricing and Risk Management of CDO Portfolios

In this module, we're going to discuss the pricing and risk management of CDOportfolios. We will focus mainly on the riskmanagement of CDO portfolios. Unfortunately, the risk management of CDOportfolios is an enormous topic in and of itself, and we won't have time to do itjustice in this module. But however, we will discuss some of theissues that arise. We will discuss some of the weaknesseswith the Gaussian copula model. We will also mention as an aside, thatlinear correlation, the correlation coefficient in and of itself is notenough to describe the dependent structure for multivariate distribution.So, this fact is lost on many people and we will emphasize it at the end of thismodule. Here's an example of a sample syntheticCDO portfolio. Across the top, we've got variouscolumns. So, the first column index, this containsa name, so CDX IG A, this actually refers to a reference portfolio.So, this is an index with a certain number of names in the index and thesenames are known. Typically, there would be a 100 names ora 125 names in the index. So, CDX IG A IG stands for investmentgrade, A is typically actually numbered, it could be eight, nine, ten, eleven andso on and different numbers can contain different reference portfolios.The second column is just a tranche description, it could be an equitytranche, a mezzanine tranche, senior trance, or it could be an index.This can be viewed as a tranche with a lower attachment point of 0 and an upperattachment point of 100 as we have here. And the next two columns indeed containthe attachment points, L for lower, U for upper attachment point.We have the maturity that is 10 years, 7 years, 5 years, 3 years, 4 years and soon. So, the materials can vary and we havethe notional amount so this is the notional amount of protection that we arebuying or selling. And these are the current prices andbasis points. Now, these are given, these are thespreads. The spreads, current market spreads ofthese tranches. the equity tranche prices are oftenquoted in a different format to reflect upfront payments and so on.But we're not going to concern ourselves with that.IG as I said, will refer to investment grade, HY, for example, refers to a highyield. So, these would be riskier credits orriskier bonds that are more likely to, to default.very often, there's substantial overlap in these portfolios.So, for example, IG A and IG B, each portfolio or reference portfolio willcontain 125 names or 120 names or so on. And in the case of A and B here,typically, there would be a very large overlap between the two portfolios.So, most of the names in A will also be in portfolio B, and so on.In practice, structured credit portfolios could contain many, many positions withdifferent reference portfolios, different maturities, and counter-parties.They also can have different trading formats, so as I said earlier, sometimesthese tranches trade in the, in the form of a spread, a spared that is paidquarterly, or a premium that is paid quarterly.This is the insurance rate if you'd like for buying protection or buying insuranceon the, the tranche, but sometimes, they can also trade in an upfront format andR, the running spread format. The ultimate payoff of such, of such aportfolio is very path-dependent with substantial idiosyncratic risks.They are very difficult to risk manage. they can also be very expensive to unwindand that is due to why bid-offer spreads. Over here, what I'm giving here is acurrent price but this should really be interpreted as the midpoint of thebid-offer spread. So, the bid on the offer will be oneither side of, say, 223. Maybe the, we'd have 210 and 240.And so, if you want to sell protection or if you will hid one side of the bid-offerspread, if you want to buy protection, you would hit the other side.So, if I'm, if I'm buying protection, I'm going to have to pay 240 basis point forthat protection. If I'm selling protection, I'm going toreceive 210, so that's the bid-offer, okay?And sometimes these bid-offer spreads can be very wide so actually unwinding such aportfolio can be very expensive, especially in times of market stress orwhen these portfolios, these synthetic CDO tranches aren't trading very often aswould be the case today. Computing the mark-to-market values ofthese portfolios can also be very difficult because market prices maybenon-transparent. I don't think I've used the phrasemark-to-market yet in this course. But just to be clear, mark-to-market isreferring to the current value of portfolio using current prices in themarketplace. So you're not using the historical priceat which you purchased a portfolio of securities, instead, you're using thecurrent market price for these securities.So, that refers to mark-to-market. And on this note, you might be interestedin the Belly of the Whale series on the Alphaville blog of the Financial Times.You can actually get to that blog via this link here.And while the Financial Times does have a paywall, so most of the articles aren'tavailable for viewing freely, their blogs are.And so, the articles in this series can be found here.This series refers to the so called London Whale.And in fact, the London Whale first came to attention because price levels in theCDX IG9 index. So, this an example of where we're usinga number. So it's the IG9 index.It diverts too much from other related price levels.In particular, it diverts too much given the CDX prices of the credits in the IG9portfolio. So, you'll see a lot of interestingmaterial in the articles that have been published on this series, on thisAlphaville blog. You won't be able to understandeverything in this series and that's in part because there's a lot of jargon andthere's a lot of references to positions that we can see.And indeed, there's references to communications that we can't see.Maybe there weren't e-mail communication but verbal communication between some ofthe players and so you won't always understand what's going on.But you will see a lot of discussion of value at risk, and Gaussian copula andthe synthetic CDOs in risk management. By [UNKNOWN] you've said this at thebeginning. But this London Whale came to attentionbecause of ultimately massive losses that occurred, in the, synthetic creditportfolio of the Chief Investment Office of JP Morgan.So, this is a very recent situation, where they lost 7 billion dollars out ofthe Chief Investment Office on synthetic credit portfolios.And reading this series is certainly of interest and certainly relevant to whatwe've been discussing in these modules. Risk management for structured creditportfolios is also very challenging. we've seen two types of risk managementto date, we haven't gone into either one in any real detail for time reasons butthey're certainly both very important. The first the scenario analysis wherewhat we did was we stressed the important risk factors for portfolio.We moved these risk factors to different level.We reevaluated the portfolio in these stress scenarios.Computed the profit and loss that would therefore arise, and figure out orevaluate overall risk of a portfolio based on the PNLs in the scenarios.So if we wanted to do a scenario analysis with the synthetic CDO portfolio, we'dhave to figure out first of all what are the main risk factors.Well that's a very difficult question to answer.There are so many moving parts here. it'll be hard to figure out what are therisk factors. Of course, overall credit spreads areimportant because credit spreads drive the individual default probabilities.And certainly, the riskiness of these CDO tranches increases as individual defaultprobabilities increase. So certainly, the overall level of creditspreads is important. But, what about the individual creditspreads? Some CDS spreads may increase, some CDSspreads may decrease, and depending on what happens, you will get very differentoutcomes for given CDO tranches. That, correlation, of course, is a hugelyimportant factor. In fact, the trading of synthetic CDOtranches is often called correlation trading because correlation as we saw, itdrives the value in particular of equity tranches, also super senior tranches.and so it's very important here to stress correlation appropriately.But in fact measuring correlation, even understanding correlation, whatcorrelation is, what this correlation of default times actually means, that's,they are difficult questions to answer. And it's very difficult to determine whatcorrelation risk factors are there and how you should stress them.Moreover, you need to determine, what are reasonable stress levels?How far should you stress a given factor? What's reasonable?What's not reasonable? What's like to happen, what's veryunlikely to happen, what's almost impossible to happen?You have to be able to answer all these questions in order to do a scenarioanalysis. Finally, suppose you could figure outwhat appropriate risk factors are and you could figure out what reasonable stresslevels for these factors are. Well then, how you going to reevaluatethe portfolio, your synthetic CDO portfolio in a given scenario whereyou've stressed these factors. Well to do that, you need some sort ofmodel. And as I mentioned before, it is verydifficult to find a good model. In fact, I think it's fair to say thatthere isn't a satisfactory model for pricing CDOs out there in themarketplace. The Gaussian copula model has been thestandard model but it is certainly a flawed model and has many, manyweaknesses. So, scenario analysis is certainly verydifficult. What about the Greeks?Well, we saw the Greeks when we discussed equity derivatives.We saw delta, gamma, vega, theta, and so on.Well, you can also come up with Greeks for synthetic CDO portfolios.You can figure out how much the value of the CDO tranche will increase if anindividual credit spread or default probability increases or decreases, andso on. So, you can certainly come up with Greeksbut there are many, many Greeks, you could argue you've got a separate Greekfor every individual default probability. You've got Greeks to correlation and soo. but you've basically got too many ofthem. You've got too many moving parts here.The Greeks are model-dependent and it would be very difficult really to riskmanage a portfolio based on the concept of the Greeks.In fact, there's an interesting article you can read here.It's from the Wall Street Journal back in 2005, which discusses some of the falloutof the downgrading of Ford and General Motors in May 2005.Certain investors, in some of these synthetic CDOs, found out that theirhedging, using the Greeks didn't work nearly as well as they anticipated whenFord and General Motors were downgrade, downgraded.Just as in the side, Ford and General Motors were part of, were members in thereference portfolio for very commonly traded [UNKNOWN] at that time, and sothere are inside, the reference portfolio for CDO tranches.and so, certainly some market people lost a lot of money when they thought theywere actually hedged when Ford and General Motors were downgraded.I should mention that, in fact, the Wall, the Wall Street Journal is behind thepayroll and so you may not be able to read this article but it depends.On one or two occasions I've been able to read it and I just Google it, other timesI can't, so maybe you'll be able to see it.And that said, don't believe everything you read in this article.in my experience, some of these articles which talk about fairly arcane andcomplicated details in, in finance, don't always get all the facts right.But the overall picture is pretty accurate and it's certainly aninteresting read. Liquidity risk and market endogeneity arealso key risks that must be considered, and that should have been considered inthe trading of CDOs and the risk management of CDOs.I've mentioned market endogeneity before. It basically refers to the idea, forexample, that if everybody is holding the same position, then that's a much riskiersituation to be in, than if only a few people hold a position.And that's because if everybody needs to exit that position at the same time, orin other words, if everyone wants to run for the exits at the same time, theneverybody wants to sell the security at the same time.There's no demand for it and the price will collapse.That's an example of this concept of market endogeneity.we've got a trade that's too crowded, too many people holding a position.Too many people wanting to get out of it at the same time, prices collapse.This certainly happened during the financial crisis.Other problems that arose in the whole structured credit area during thefinancial crisis were the massive overreliance on ratings agencies to ratesome of these tranches. And overreliance on models that reallyweren't worthy or that were, at best, a poor approximation to reality.you had issues related to just the behavior of organizations, the incentivesof individuals making big decisions in these organizations.All of these obviously played a very important role in the financial crisis.Very briefly I want to spend a little bit of time talking about copulas.We introduced copula in an earlier model when we discussed the Gaussian copulamodel. But we haven't had time really to spendon copulas more generally. I'm just going to say a little bit aboutcopulas here and the Gaussian copula model.So certainly, the Gaussian copula model is the most famous model for pricingstructured credit securities. There has been enormous criticism aimedat this model and most, if not all of it, is justified.With that said, some people like to say that they didn't understand theweaknesses of the Gaussian copula model until after the financial crisis broke.Well, I simply don't think that's true. There's nothing we've learned about theGaussian copula model that we didn't know before the financial crisis.So, to say or to plead ignorance that you didn't understand the model, that themarket didn't understand the weaknesses of the model after the crisis blew up orthe crisis took place, simply is not a well-founded statement.Many people fully understand the weaknesses of the, of the Gaussian copulamodel. Just to mention a couple of them, it's astatic model. By static, I mean, there are no dynamicsin the model. We just compute the expected tranche lossat a fixed period of time. There's no stochastic process here, weassume credit spreads are constant. we assume correlation is constant, weassume correlation is constant across the various names.There are problems with this model in terms of time consistency and so on.So I know this is a very brief aside, we don't have time to go into, into this inany more detail, but certainly, the weaknesses of the Gaussian copula havebeen well-understood. There has been a lot of academic work onbuilding better and more sophisticated models, but none of them are reallysatisfactory. It's an aside but I want to also makethis point. A common fallacy is that the marginaldistributions and correlation matrix are sufficient for describing the jointdistribution of a multivariate distribution.In others, what I'm saying here is, many people think that if you've got amultivariate distribution, the only thing that you need to know about distributionare the marginals and the correlation between the random variables.Well, that's not true. Correlation only measures lineardependence. On the next slide, we'll provide acounter example to this. So, in this slide, we've got twodistributions, two bivariate distributions.The first one is a bivariate normal distribution and the second one is what'scalled a Meta-Gumbel distribution. What I want to emphasize here is that ineach case the marginals are standard normal.So, the marginals in each of these are standard normal.Now, the plots aren't really drawn to an appropriate scale, maybe we shouldstretch the x-axis out here, because really the, the width, the length of thehorizontal piece here should be the same length as the vertical piece here.So, they're both, the marginals in all cases are were in 0,1.The correlation in each case is 0.7. So, what we have here are two bivariatedistributions which have the same marginals and the same correlations, butthey're very different. And one way to see they're different isthe following. The Meta-Gumbel distribution is much morelikely to see large joint moves. And the way to see that is to look formoves where the x and y variable are both greater than or equal to 3.These are up here, and up here. So, over in the multivariate normal, wesee there's only one move where both the x and y variable are both greater than orequal to 3. Whereas, over here, we see there are fivesuch situations. What we've done here, by the way, iswe've simulated 5,000 points from each of these distributions.So, five of those 5,000 points, or 0.1% of those 5,000 points resulted in extremejoint move. Whereas only 1 5th of that resulted in anextreme joint move in the case of the Bivariate Normal.Now, 0.1% might seem like a very small number.And indeed it is. But when it comes to figuring out losses,that 0.1% can be substantial.

### 033. CDO-Squared's and Beyond

In this module, we're going to go beyond CDOs and discuss more complicatedproducts such as CDO squared's and CDO cubed, and maybe even a little bit aboutABSCDOs as well. That point we're going to try and makehere is that the risk management of these products is incredibly difficult.And it is difficult indeed to see any economic justification for introducingthese products. Nonetheless, they were traded in themarketplace in the lead up to the financial crisis.And it is worthwhile seeing what they were and how they actually work.It should already be clear that structured credit portfolios consistingof CDO tranches can be difficult to risk manage.But at least there is a solid risk sharing motivation for the creation ofCDO's, and this is true for securitization in general.We mentioned earlier that the idea behind securitization is to package a series ofunderlying bonds or loans or whatever, into a set of new securities each ofwhich may have a different risk profile and which may appeal to a differentaudience or investor class if you like. And so, by spreading risk that way we canactually make the, the financial markets more efficient and so this is the theorythat justifies securitization in general. But the structured credit market quicklyran amok with the creation and treating of ever more complex securities.For example, products such as CDO squareds were soon developed.They were difficult to justify economically.they provided great examples of product risk whereby people didn't reallyunderstand the product that they were buying and model risk, and that reallymodels were completely inadequate for pricing these securities.Legal risk and so on. Why legal risk?Well, the actual contracts underlying these CDOs ran to maybe many thousands ofpages and so it's hard to believe that anybody fully understood what exactlythey were purchasing when they invested in CDO squared's and so on.Before discussing these classes of securities, these CDO-squared's, recallfirst how a CDO is constructed. So, we've got an underlying pool ofbonds, say 125 bonds. we might have what's called as wementioned earlier, a special purpose vehicle.Which is a legal entity into which we would place these bonds.And then from these bonds, we can construct the CDO.So the bonds form the underlying collateral for the CDO.And then the CDO is tranched up into an equity mezzanine and so on.Tranches and people can invest in these different tranches and get very differentrisk profiles as a result. So, that's how a CDO is constructed.How about a CDO squared? Well here's an example of a CDO squared.We're going to assume that a hundred CDOs, CDO number one up to CDO number100. We're going to take the mezzanine pieceof each of these CDOs. So we're going to assume the mezzaninepiece corresponds to attachment point of 3% up to 7%.And then we are actually going to construct a CDO square using thesemezzanine pieces. So the CDO squared is constructed frommezzanine tranches of underlying CDOs. So basically, you can think of thesemezzanine pieces as now corresponding to the bonds underlying the CDOs.So basically a loss will only occur in say the equity tranche here.When there is at least some loss in the mezzanine tranche of one of theseunderlying CDOs. If none of these underlying CDOs everexperience a loss in their mezzanine tranches then there will never be a lossanywhere in the CDO squared and in particular in the equity tranche here.On the other hand if all of these mezzanine tranches experience losses.In fact, if all of them are blown out, in other words maybe losses go right throughthe mezzanine tranches in all of these tranches, well then this CDO squared willface complete wipe out as well. All the way up through the[UNKNOWN]mezzanine and senior tranches. Remember the mezzanine tranches are theunderlying bonds, if you will, for this CDO squared.It's also worth pointing out that many bonds act as collateral for multipleCDOs. So behind this, remember there are bondsbehind each of these CDOs. And in many cases what you'll have is,you'll have a bond being in the reference portfolio for this CDO, but it might alsobe in the reference portfolio down here for this CDO.So there would be a lot of overlaps of names, of bonds going into thesedifferent CDOs. So this is just repeating in words whatwe showed visually on the previous slide. There's not much else to say here, solet's move on. Here's a question.How would you price and risk manage a CDO squared?Here are some considerations. And by the way a discussion of CDOsquared can also be found on the paper by[UNKNOWN] that I referred to in anearlier module. They discuss some of these issues thereas well. So here's some considerations.The legal contract governing each of the mezzanine tranches in the underlyingportfolio of CDO's could be on the order of 150 pages long.So, therefore, if you really want to do your due diligence, really understand thelegal details underlying a CDO squared, you would need to read approximately 100time 150, which is 15,000 pages of legal documents.To just say good luck. You should also of course read thecontract governing CDO squared. How do you keep track of the CDOsquared's performance? Just to keep track of the performance ofthe CDO squared, remember you're going to have to keep track of the performance ofall of these underlying bonds. You're going to have to feed theperformance of these underlying bonds into each of these 100 CDOs and figureout what's going on in each of these CDOs.And then based on that, you're going to have to figure out what's going on in theCDO-squared. In order to do that, you're probablygoing to have to write several thousand lines of computer code, and that is justto keep track of the actual performance. It is not to actually price theCDO-squared. Or to, risk manage the CDO squared.You might need a model to price it. In fact, it's hard to say that any modelreally could ever possibly price that CDO squared correctly or give you a goodsense of how much a fair value is for a CDO squared.So these are very difficult securities to manage.How would you perform scenario analysis? how would you estimate the value at risk?Or the conditional value at risk of a portfolio of CDO-squared's?It's it seems very difficult to even imagine doing such analysis.But why stop there? There are also ABS CDO's.An ABS CDO is an a, is a CDO where the underlying securities, the underlyingbonds are themselves acid backed securities.So going back to our CDO squared instead of having a CDO number 1 up to CDO number100 this could be ABS number 1 up to ABS number 100.And these ABSs could in fact be mortgage back securities.So there would be underlying pools of loans feeding into these ABSs.Which then feed into the CDO itself. Uhhh you can have CDO-cubes uhhhm.And why stop there? So here's how a CDO-cube would work.You got your n CDOs and a couple of slides ago we had n is equal to a 100.Now we've got n CDO's. From that we construct say 100CDO-squared. So imagining here that the n, number n isgreater than 100, so we can construct CDO-squared out of these n CDO'S maybeusing the mezzanine tranches from these CDOS.Now we have our CDO squares. Let's take the mezzanine tranches ofthese CDO-squared and construct another CDO that would give us a CDO-cubed.So, if your head is spinning at this point, it's not surprising.And yet, there were trades apparently on CDO-cubed in the marketplace leading upto the financial crisis. So, one other point I'll make about thefinancial crisis and the subprime crisis before, before ending this module is thefollowing. So there were securities, I mentioned inthe previous slide, called ABS CDOs. And very often, actually, it wassub-prime mortgage ABS's that were feeding into these CDOs.And so you can imagine this being the CDO, maybe there's equity mezzanine andso on. So, maybe this is the zero to 3% tranche.Maybe this is, I don't know, a 6 and 9% tranche.And maybe the underlying pool of securities that feeds into this CDO.Are some mortgage backed securities. So we've got a bunch of mortgage backedsecurities feeding in here. Well, an interesting antidote about thefinancial crisis is that the sub prime crisis actually didn't come suddenly tomany people. There were several money marketers,including banks and so on who had a good sense that the subprime crisis was comingdown the line. And one way to profit from that beliefwas to actually buy protection on the 0 to 3% tranche of an ABS CDO.So if you buy protection here, what will happen is that you're going to get paidoff. You're going to make money.If you see lots of defaults in the 0 to 3% piece, or lots of losses in the 0 to3% piece of this CDO. And if you expect the subprime crisis tocome down the line, then you're going to assume that the underlying mortgagebacked securities are indeed going to see a lot of losses.Because people are defaulting on their loans and so on.And if they're defaulting on their loans and you're seeing losses in theunderlying mortgage pool, then you expect to see losses inside this tranche aswell. And so you could profit from that bybuying insurance on this tranche. And so thats what some players did.They bought insurance on this tranche. But, when you buy insurance you've got topay an insurance premium. And the insurance premium which you haveto pay quarterly could be quite substantial.So rather than having to pay out this amount of money every quarter, some ofthese players or banks got clever and said, you know what, instead of payingout money every quarter on this tranche, why don't we sell protection or sellinsurance up here? On this tranche, say.and if you sell insurance on this tranche, well then you are going to betaking in a premium. And you could use the premium you take inhere to fund the insurance premium you have to pay out for your protection here.The only problem with that is because this tranche is much riskier than thistranche, you have to sell a lot more insurance up here to cover your paymentsdown here and that's what some players did.They thought that the sub prime crisis might blow through these tranches up tohere say, but that the higher tranches would be safe and that they would neverincur losses and so on. And so they thought it would be a goodidea to sell protection on these more senior tranches and use the premium tofund protection on the equity tranche. And so that was a good idea.It, it meant you didn't have to spend any money net on your position.The premium here was funded by the premium you're taking in up here.The problem was, that the subprime, crisis came along, and was much moresevere than anybody anticipated. And in fact, the losses didn't stop atthis point, or at least the mark-, market losses didn't stop at this point.The mark to market losses went like this, and blew out these tranches as well.And so the players who actually put on the straight, ended up losing an awfullot of money. Because they were selling protection on amuch larger notional up here than the notional they were buying protection ondown here. So this is just an aside.And the reason I wanted to mention it is, number one, many players actually did seethe sub prime crisis coming along and they used these ABS CDOs in order to makeplays on what was happening, or what might happen with the sub prime, with thesub prime crisis. But also it emphasizes how even if youropinion is correct, and their opinion was correct.The sub prime crisis was coming and it did occur.It can still be very difficult to execute a trade properly.So they executed the trade by buying protection down here, selling protectionup here but their execution didn't work. In fact, the sub prime crisis was worsethan what they anticipated. And some of these players ended up losingan awful lot of money as a result.

## 018.Liquidity, Trading Costs, and Portfolio Execution

### 034. Liquidity, Trading Costs, and Portfolio Execution

In this set of modules, set of three modules, we're going to talk aboutliquidity, how liquidity of assets affect trading costs, and how these tradingcosts have implications for portfolio selection.In the first module we're going to be mainly focusing on measures of liquidity,how do you set up a portfolio selection problem that takes liquidity intoaccount. What is liquidity and what is a liquidsecurity, is very hard to define in practice.What we do know is a liquid security is one that can be traded very quickly, hasvery little price impact, meaning when I try to put in an order to buy or sell, itmoves prices very little. And it can be bought and sold in largequantities. That means it has a very deep order book.There are different measures of liquidity.Some of the measures based on volume and these include the trading volume and theturn over which is defined as the trading volume divided by the shares outstanding.Both of these measures, try get, try to get at the idea.That liquidity refers to the fact that one can execute your trades quickly.So if something has a very high trading volume or high turnover, then my orderwill get executed very quickly. There are cost base measures which lookat the impact of liquidity on the cost of trading a particular set of securities,particular amount of securities. One of the measures that gets at this isthe percentage bid and ask price. An ask price is the price at which peopleare willing to sell a particular security, and B, the bid price, is theprice at which people are willing to buy a security.As always, the ask price is going to be greater than the bid price and thepercentage bid as spread is defined as A minus B, the difference.Divided by A plus B, divided by two. So the mid price times 100.A volume weighted average prices, is another quantitiy that gets us thisnotion of liquidity. So what happens is that you want to sella total amount of shares, v. This total amount gets split up intosmaller trades. We want to vm.And each of these treats get's executed at a different price.P 1 through P m. So the volume weighted price that you gotfor the particular order would be simply Pi, Vi, some from I going from 1 throughM, divided by the total volume V. So this quantity is known as the volumeweighted average price. It tells you the price that you ended upgetting. If you're trying to sell a particularcommodity, what happens is that the price start to slip downwards so you insteadof, P1 could be the opening price, Pm could be the price at which your last bitgot sold. Typically P1 is greater that P2 isgreater than P3 and so on. So the average price turns out to be lessthan the price that was existing in the market just before you put in your trade.Other authors have tried to get at the price impact function directly.There was a, the first of these functions was introduced by Lobe in 1983, calledthe Lobe price impact function. More recently, Kissel and Glance haveintroduced a price impact function, which measures how expensive or what is thecost of putting in a particular trait. In the next slide, I'm going to talkabout the Kissel-Glantz price impact function and in that context I'll tellyou what the Lobe function is as well. In the rest of this module, I am going toassume that we are going to be looking at basically, a cost based measures ofliquidity and we are going to incorporate those cost based measures into myportfolio execution of portfolio selection procedure to get at what is theoptimal. Choice for my portfolios.The trading cost function. The cost of creating a particular blockof shares is typically assumed to be separable across assets.Which means that it ignores the cross asset price impact.This is an assumption which is not valid anymore.There is cross price impact and in the last module of the series, we going to.Start discussing some ideas of why this cross-price impact occurs.And what can be done to sort of of take it into account in your asset allocationdecisions. So the Kissel-Glantz function says thatif I want to trade Q shares of a particular asset and the cost of.Trading these shares, meaning the slippage, the extra price that I have topay if I'm buying or the loss in price that I'm going to see if I'm selling isgiven by this function c of q. It has three components, the firstcomponent is just a constant, a three. So the cost is dependent on the totaldollar amount that I'm going to sell. Its depended on the volatility.So if, if a particular, there is no index I there, if a particular stock is veryvolatile you expect to pay more, prices move around.And so when you've put in your order to the time it actually got executed.You will end up getting a higher volatility.And then a third component that depends on basically the percentage of your tradeQ to the daily volume V. So Q over V is the percentage of thedaily volume that you are trying to take times 100 that gives you the percentageraised to the power beta. And these are some const-, constants A1.How does one estimate a function like that?What one does is postulates, that there are three factors in the regressionfunction. This is factor number one, volatility isfactor number two, and this is basically the intercept.And then one runs a regression. One records, over a history, of trades,how much extra cost did you end up paying for that particular trade.So Qt is a particular trade that was executed at time t, or trade t.PtQt should have been the price that you should have gotten.cQt is the extra price that you had to pay or the extra revenue that you lost.You divide that. That gives you one observation of thisregression function. And then you regress it to compute outwhat a1 is going to be, what a2 is going to be, what a3 is going to be.And this is what was proposed by Kissell and Glantz in mid 2000's, and this hassort of become the standard pro- standard function that people use for tradingcosts. There was another function the wasintroduced by Lobe before, and which was slightly different.And what he, what, in his model, the cost versus volume initially grew linearly,and then it grew with a power. So the cost was some alpha 1 times q upto sum q max. And then it was some alpha 2 to thepower, times q1 plus beta after Q max. And beta was estimated to beapproximately 0.65. So this is the cost under q, that's q,and this was the Lobe function. So the low function is was suggested in1983, and it was relatively simple. It did not take into consideration thevolatility. It did not take into consideration theaverage daily volume. But it was the inspiration that led toother liquidity functions later on, in particular the Kessell Glance function.And we will focus with Kessel Glance function in this module.Alright so once we have a price impact function, we can include that into ourportfolio selection problem. So there are two approaches tointroducing liquidity and portfolio selection.One approach is to do the usual portfolio selection, and then account for liquidityand executed traits. In the second module of the series we'regoing to talk about, how to include. Liquidity in executing trades.And the other approach is to incorporate liquidity concerns directly into theportfolio selection problem. And that way you're choosing position, soyou're choosing portfolios that will have low cost, of execution.The best practice is to do both, account for it with the portfolio selection andthen when you do trades. You account for it by trade execution aswell. So the generic problem that one solvesfor the second approach which is to incorporate liquidity concerns directlyinto the portfolio selection, is as follows.You take your usual mean variance optimization problem, so I have a currentposition Y. One transpose y tells me the total wealththat I have, x is a new set of positions. So in this particular problem, the x's donot add up to one. They are just dollar amounts, or anyother units, which add up to the initial amount of money that I have.Mew transpose x minus lambda x transpose x, this quantity, is our usual meanvariance. Objective.Mew, mew is the mean return and v is the covariance matrix, lambda is the risktolerance or the risk aversion parameter. Now instead of just stopping there, whatwe are going to do is subtract from it, at the trading cost.This is extra cost that I have to pay, and that actually reduces my mean return.And I'm going to add an eta to try to incorporate the effect that I can controlthe amount of liquidity cost that I'm going to incorporate into my portfolioselection problem. So some part of it I might include here.Some part I might handle while execution. Or I might just want to use eta as a wayto trade off between mean-variance returns and the trading cost.And what is Cxy, Cxy is the cost of moving from the current position y to thenew position x and we can write it as using the Kissel-Glantz function as thisexpression down here. XI minus YI is dollar amounts and that'swhy I've now divided by PI. And so to adjust vi to include the factthat it's now the percentage dollar transacted to the power beta.This sigma value remains the same. A3 remains the same.And xi minus yi is actually the dollar amount transacted.Now if you expand it, you end up getting. You can take the constant over here, itjust becomes xi minus yi absolute value. You can take this one and take out theextra part, so, it's a100 over pivi to the power beta, and xi minus yi to thepower 1 minus, 1 plus beta. Now, I have a function, I can incorporatethe function into my portfolio selection problem, and then, I can solve thatportfolio selection problem to compute what my new positions x are going to be.In the next module, which is going to be an excel module, I'm going to show youhow to solve setup, and solve this optimization problem and we're going toplay around a little bit with what happens when eta changes values and soon. In the rest of this module I'm going totalk about a very simple model that has become popular, that was introduced byAndy Lowe in one of his papers, and it's a easy model that incorporates someaspects of liquidating. So this approach was taken, is taken by apaper by Lo Petrov and Wierzbicki. And the title of the paper is veryinteresting, it's 11 PM, do you know where your liquidity is?The mean variance-liquidity frontier. What they do, is it that they ascribe toeach security a certain normalized liquidity measure.So let L [UNKNOWN] note the measure of liquidity where high values, implies moreliquidity. So, if you're talking about turnover,high turnover is a good measure. if you're talking about volume, and highvolumes is a good measure. When you're talking about trading costs,or bid ask spreads, you take the reciprocal of those numbers.So the high percentage bid ask spread is bad, low percentage bid ask spread isgood and therefore when you define this measure of liquidity in the modelintroduced by Andy Lo. You take one over the beta percentage,beta spread to define your LIT. And then your normalize this over acertain period. So what you do is you look at LIT for aparticular amount of time. You take the minimum value that thisparticular measure could take over all assets.So it's i-prime ranging over all assets and all times.And divided by the maximum value that can be achieved over all assets and all timesminus the minimum. So this number, whatever it is now,becomes a number between zero and one. So this lies between zero and one.They assumed in their model that all the wealth is in cash, and formulated threedifferent optimization problems that get at this notion of how do you incorporateliquidity into portfolio selection. The first method they call LiquidityFiltered Portfolio Selection, so you do the usual main variance portfolioselection, so one transpose X equals one,mew transpose X minus lambda would doX transpose VX. But now you insist that XI is equal tozero for all I's that do not meet a particular liquidity threshold.So L bar is your liquiddity threshold. And if doesn't meet that liquiditythreshold, you cannot hold that particular asset.Another one is to use a mean variance liquidity objective.again this time I'm just adding to it l i x i and then saying this is differentfrom the formulation on the previous page, because for, this is no longer acost, but this is a quality measure. So l i high is good, so I want to addthat liquidity measure instead of subtracting as if it was a cost.A third version that is suggested was liquidity constrained portfolios, so youdo not put a cost but you say that, LIXI over the average value of XI is greaterthan, equal to L bar. So difference between the first model andthe last one, is that the only thing this is measuring liquidity on a portfoliolevel, so this is a portfolio level measure.Instead of asset. In the first formulation over here, thisis asset by asset. If a particular asset does meet theliquidity threshold, you throw it away. In this particular case, you just want tomake sure that on overall portfolio level this happens.in that way. The expression for overall liquidity inthe portfolio is slightly different here, this is to prevent short positions inilliquid stocks, cancelling long position in other liquid stocks.And we'd, because of that, instead of taking just XI, we take the absolutevalue of XI. All of these portfolio selection problemscan also be solved in Excel in much the same way.That the fourth formulation is going to be solved.[BLANK_AUDIO]

## 019.Optimal Execution and Portfolio Execution

### 035. Optimal Execution

In this module, we will focus on a single asset and we will double up a model whichtakes into account the temporary price impact of a trade and the permanent priceimpact of a trade. And construct an optimization problemthat allows you to select a treating strategy that minimizes the cost of theexecution, and as well as the risk associated with this execution.In this module we are going to take the approach that we have decided aportfolio, that we want to trade to words.So this is a new position, we had an original position and now we want totrade to a new position. And we have computed this new positionperhaps by taking liquidity into consideration or perhaps not.And in one of the pieces of this over, over all trade, we have to sell a totalof capital x shares over at most t traits.I choose a certain number of trades that I can put and over those trades I want tosell these shares in order to have the least amount of trading cost associatedwith it. And in order to compute the trading cost,I need to have a model for trading cost and that's what we're going to developover this module. So, in order to model how going to trade,I'm going to introduce this notion of a trading strategy.So, N sub j would denote the number of shares that will be sold on the jthtrade. Capital N or bold face N, which is N1through N capital T will be called the execution sequence.It's just a complete sequence of execution that I will be interested in.Over the entire period, j going from 1 through capital T, the sum of all thetrades that I made must be equal to X, capital X, the amount that I wanted totrade. I'm going to introduce a new notion oflittle x, which is going to be the inventory.That is, the holdings at the end of a particular trade.So x sub zero will be capital X. x sub k will be the holdings at the endof not the jth trade, but kth trade. After the kth trade, I would have n1, n2,n3, up to nk. I subtract that from capital x, thattells me what is the holdings left over, and that's the inventory that I have.In order to understand how to choose these sequences, I have to bring in thisnotion of what happens to the prices. So let S hat k denote the price per sharereceived for the nk shares sold in the k-th trade.x hat, this S hat nk is going to be a function of all the trades, n1 throughnk. Note that it also depends on the tradethat you actually put in. And now in the next slide I'm going toset up a particular model for how these prices behave.And using those models, I'm going to try to understand how I can trade off variousimportant quantities that play a role in the execution of a particular stock.So this slide is perhaps the most important one in this module.I'm going to assume that the price impact, the impact on the price of mytrade is going to have two components. There's going to be a temporary priceimpact component, which is the impact of trade nk on its own price per share, Shat k. And a permanent price impact is theimpact of trade nk on all the future prices.And here's the model that's going to happen.Remember, I'm selling shares, so whatever I do tries to drag the price down.If I were buying orders, if I were putting in my orders then the, the wholestory will be a mirror image and I will start increasing prices because of mytrade and not decreasing prices. So let Sk denote the price that I observein the market, when I am contemplating the k-th trade.When I put in the K-th trade, the average price that I get for this trade is notgoing to be Sk but a smaller amount S hat k.This is the amount of money that I would get per share when I put in the tradehnk. Now, I'm going to assume that S hat k isgoing to be Sk minus hnk, it's something hn is a temporary price impact function.It defines what'll happen to my price by what amount the price is going to dip ifI decide to sell nk amounts of shares. Now what happens to the price in thefuture periods? This particular trade, nk, is going tohave an impact of what happens to price Sk plus one.And therefore, it's going to start having an impact on Sk plus 1, Sk plus 2, Skplus 3, all the way up through S capital T.And the model that we are going to say is the following.The price at the next time period is going to be some random walk to itscurrent price, plus a random walk component.So sigma is the variability or the standard deviation, zk is just IIDstandard Normal random variables. So without any price impact, thisparticular asset is just doing a random walk.If there was drift in the market, we can simply add another drift term.Typically, when ignores the drift term and claims that this trades are happeningover a certain period said that the price is not significantly drifting, but it isvarying. So Sk plus sigma zk tells you whathappens in the random walk. The expected cost term takes intoconsideration the fact that if I sell a large chunk it's going to have a priceimpact, and I won't get the revenue that I want.Rho, the term over here, is the trade off that trades off my concern for variancewith my concerns for trying to keep the cost minimized the cost that I end upgetting from it. The total revenue from execution, issimply the price per share for every trade times the number of shares sold inthat trade. So it's the sum of k going from 1 throughcapital T of S hat k, which is the price per share times nk, which is the numberof shares that we're trading. If you write out the expression for S hatk, it becomes Sk minus the term that corresponds to the temporary price impacttimes nk. So this term, we have taken it togetherand kept it over there. Then Sk has an expression.Sk is equal to S1, the initial price when we started trading sum from j going from1 to k minus 1 of all the random walk terms, minus nj, which is all thepermanent price impact terms, times nk. So if you unravel the sum and do it twodifferent ways, you end up getting the first term, which is S1 times the totalnumber that I sold. So this is the revenue that I expect toget if there was no price impact. I could just sh, sell everything all atone go, I get the current price. That's it, I'm done.Plus I get a term which corresponds to random walk.The random walk term starts to show what is going to happen, what the trade offbetween selling and inventory. So the random walk term has a term zdelta k that refers to the random term at time k, the random walk at time k and itaffects all the left over inventory at time k.So, this is not nk but xk, it's the inventory at the end of the k-th trade.Similarly the term that corresponds to the permanent price impact also af,affects, is affected by the inventory and not the current trade.So gnk, the trade at time k, is going to affect all the stocks that I have not yetsold, all the shares that are not yet sold, and sitting in inven, inventory.This is the revenue that was expected, that is the revenue that was realized, sothe difference between the two of them is the slip edge or the expected cost of thetrading strategy. So, the trading strategy Cn gives me acost, which is gnk times xk, which is the inventory plus hnk times nk.This is the expected cost, and therefore the term that corresponds with the randomwalk goes away. The risk or the variance of the tradingstrategy is that all the deterministic terms go away.Since the random walk terms were assumed to be IID standard normal, you get sigmasquared times the sum of the inventory from time 1 to time Capital T.Now we can define waht is called the optimal execution frontier, which is atrade off between expected cost and risk. So I want to minimize over all tradingstrategies, the expected cost, plus rho times the risk term.The time horizon capital T is also a variable, but in this particular case weare going to assume that Capital T is given and just optimizer of the executionstrategy. What this objective is basically tryingto do is the following. If I completely ignore variability, thenthe best thing for me to do is to sell equally, across the entire time horizon.That minimizes the amount that I sell on any given day and therefore thatminimizes my price impact. And we will see that on the Excelspreadsheet that is exactly what is going to happen.But if I spread it uniformly, what's happening is that I expose my inventoryto very high availability. And therefore the, the realized revenuecould be very far away from the expected revenue.If I want to control the variability, then I want to sell quickly, but then Ipay a cost in the expected slippage, or the, or equal until if my revenue comesdown. So I need to balance these two, and rhois sort of exploring the different points on the surface, that is a trade offbetween the expected cost and variability.What are some typical choices for the price impact function, for the permanentprice impact function typically one takes it to be linear.For the temporary price impact function, you can use the Kissell-Glantz functionthat we introduced in the last module, and we're going to be doing that in theexcel module that we, we'll be talking about very soon.

### 036. Portfolio Execution

In this last module on liquidity and execution we're going to talk about themain ideas that are important for portfolio execution.And focus on some of these ideas and how they're impacting, how portfolioexecution is done in practice. But we're not going to be looking toomuch into the details of any these problems.In this last module on portfolio execution and liquidity, I just want tointroduce some ideas that are relevant to portfolio execution.In this module we will not give you any strategies, or will not formulate anyproblems. But we'll just talk about really isissues that are of interest and importance in portfolio execution.So, the big problem that one is interested in is that, one has aportfolio x or a position x, they may not add up to 1.You want to move to another position, y over a certain number of trades capitalT. One of the various decisions that one hasto make in order to make this trade happen.First of all we have to decide what is a trade horizon?Is it one day, is it a week, is it a month, is it milliseconds?So that's a variable, depending upon what we decide.The strategies that one uses and the models that one constructs are going tobe different. Does one consider cross asset priceimpact? If I trade one particular asset, it'sgoing to impact the price of that asset, but does it impact the price of anotherrelated or maybe unrelated asset? How does one model this?Because if it is the case that my trades in one asset are going to map, affectanother asset, then I may want to construct my trades in such a way that Ihave offsetting pricing facts as I go along and perhaps reduce the amount ofslippage that I'm going to have. I'm going to have to think about what isthe difference between market orders. So these are orders that I put into themarket and I tell the broker to immediately execute.Or limit orders, where I tell the broker to put my order in a book called theLimit Book. And I will wait for my turn for my orderto be executed. The difference between these two is, oneof them I'm going to get the current price, it will get executed, but I'mgoing to possibly lose in the best possible price.In the other, I'm going to sit in the limit book.I don't know when I'm going to get executed.But if I'm going to get executed, I'm going to get a better price.And I still might be the case that my entire order may not get executed at aparticular time, but might be spread over lots of dates.So I have execution uncertainty, but I typically get a better price.How does one trade that off? What is the importance of dark pools inthese decisions? I'm going to defer the definition of adark pool for a few slides, but it's basically venues where the volume that isavailable for trade. And the prices at which this volume isavailable is not transparent. You cannot see it.And the reason one goes to the dark pool is because one wants to limit priceimpact. And another thing that is becoming moreimportant recently is this notion of portfolio being in balance.So the idea is that here's my portfolio. X that's where I started from.Here's the portfolio y, that I want to go to.There are many ways, many paths that I could take in this space to go from x toy. One extreme path could be that I firstsell asset 1, and then I buy asset 2. And I end up getting that path.Or first I buy asset 2 or sell, then sell the asset 3, that's another path.The difference between these two paths, is that the proportions of the assets,along the path, changes dramatically. If I do something like this, then it'ssort of, I'm keeping them in balance with each other.But if I do something proportional, I may have to constrain my trades which mean Imay not end up getting the best possible price.So, sometimes people think about having a, a sort of window around this, and yousay that your portfolio trades have to me in the window.Which means at any given time your portfolio must fall in this ellipse somewhere. There are many different groups that aretrying to develop strategies that will allow you to do this, and yet control theprice that you pay for execution. All of these aspects are not fullyunderstood. There are, these are active researchtopics that are going on right now, to understand cross-price impact.Understand the trade off between market and limit.how do you keep a portfolio balance and so on.Similar issues come up in high frequency trading, which is a topic that we havenot covered in these sets of modules. And the issues are where, where to placeorders in the limit book, how do you manage the risk of the inventory?This is sort of along the lines of how do you trade off between the risk.in the transaction where it says the expected cost of the transaction verysimilarly, in high frequency trading you are setting the limit book and takingwhatever orders hits you. And you want to make sure that at anygiven time, the inventory of offer that you're holding, is not very risky.So let's take all of these aspects one by one and try to sort of get out flavorfulwhat's going on there. Cross-asset price impact.There is now increasing evidence that cross-asset price impact is important.And that typical economic models that one is thinking about behind this is thatmarket-makers, who are typically assumed to be less informed about the prices orthe fundamental values of these assets as compared to speculators in these assets,attempt to learn the fundamental value of one asset from the order flow of relatedassets. So if there's an order flow that'shappening in a related asset, because the market makers are trying to infersomething about the fundamental value of a particular asset, by looking at relatedassets, that will have an impact on the price.This peculiar is, I strategically trade another assets in order to reduce tradingcosts, manage their risk, they want to keep their portfolio balanced.So when they are trading one asset, they might want to trade another asset to keepthe risk balance. And they may want to try to reduce theirdirect price impact by looking at other related assets.And because of that, the, the order flows in these assets become correlated.And when the order flows becomes correlated, the market-makers then lookat these correlated order flows. Order flows and try to set prices whichstart reacting to order flows of [UNKNOWN], nearby or related assets.This is sort of an intuitive idea for why there might be cross asset price impact.There is some initial theory by Kyle. But this area is not very well understoodand there is very little empirical work to justify many of the models.Some of the features that have been noticed is that cross-price impact isoften negative. Both direct and cross-price impact aresmaller when speculators are more numerous.If the volume is high, you expect this to go down, so, that's not very surprisingit's greater when the market-wide dispersion of beliefs is higher.So the beliefs are more uniform. Then these overflows have lessinformation, and therefore the cross-price, cross-asset pricing pactthat is driven by overflow information will be less.if the dispersion of beliefs is larger, then people are looking to theseoverfloes to get information about the values of different assets.And therefore the cross asset price impact could be higher.It's typically greater among stocks dealt by the same specialist, specialist dealsin a particular set of stocks. And sometimes order flows from oneparticular asset in that group, starts impacting the price.And the other one because the specialist also wants to do this management andwhich correlates the assets and therefore there's a cross asset price impact.The next thing that I want to talk a little bit about is Market orders versusLimit orders. We have referred to this limit book anumber of times in these modules. Here's a sort of a schematic picture ofit. A limit book is a database that keepsorders, that is buy orders or bids, or sell orders or offers, on a price timepriority basis. So the red, which are shown above theline are all ask side, or the sell orders.And what it's, what it's depicting is the order that are available.So here's a particular chunk of an order. This is the number of shares, this is thequantity. And it's available at this price.And at this particular price, there are three different quanitties that areavailable. This arrived earlier than that one andthen that one so this one has time priority, over all the other chunks thatare sitting at the same price. So for example, we just called the lowestprice at which somebody is willing to sell we just call the ask price.And at that particular price there was initially just one chunk of ordersavailable. Here's another chunk that came in andthis person said, I don't want to buy. So this is a sell order, this personcould have sold to somebody whose willing to buy but he doesn't want to sell itright now and she just goes and sits at the ask price and waits for what is goingto happen. Symmetric story over here on the buyside. This is the bid price.This is the price at which people are willing to buy.These are the orders that they, the amount that they are willing to buy.And here's a limit order, meaning that this person is willing to buy these manyshares at that price. And there is a priority again in terms oftime. So what happens in a market order?In a market order you can come in and start buying off of this limit book.So let's say that you want to sell something.When, and you want to sell a particular set of shares.Let's say you want to sell these many shares.When you arrive, there is somebody waiting on this side that is willing tobuy those shares at that price. So this much share gets deducted fromthat account and you end up getting, that this is the remaining volume.And the problem with the market order is that you end up getting the bid price forit. Where as if you had decided to put alimit order inside of this particular point, you would have gotten a higherprice. But, you would have to wait till somebodycomes along and is willing to buy you at the higher price.so there is this trade off between getting a better price versus havinguncertainty about when your order will get executed.So the market order picks up orders from the Limit book starting from the bid oroffer price, that is the best buy or sell order in the limit book.You get immediate execution, you get low revenue from selling and high cost frombuying. A limit order on the other hand, placesthe order on the limit book at a specified price.The execution time is uncertain, the revenue of the cost is higher orrespectively lower. So you get a better deal, but when basicexecution happens to become uncertain, whether and where to place a limit orderis a function of patience. Whether you're, this is an opportunistictrade or an immediate trade. Depends on the volatility of the pricebecause the entire order book moves back and forth depending upon what happens tothe mid-price which is approximately the price of the asset.If it's very volatile the order book is going to move quite a bit and your orderswill get deep orders and the limit will get traded.On the other hand if the volatility is low this is not going to happen.Sometime discount is giving the liquidity providers, so if you place orders onlimit book because you're providing liquidity, you get a discount.And that affects whether or not you're going to put a market order or a limitorder. Another little concept that's coming upand becoming very important is this controversy of dark pools.Dark pools are. Dark pools of liquidity are venues whereblocks of shares can be bought or sold without revealing either the size of thetrade or the identity of the trade until the trade is filled.By contrast, regular exchanges are called lit pools.They're transparent. You can see the order book.You can see how many shares are available at what price.Consequently, dark pools trading a wide market Impact.You don't know how many people are willing to sale.What is the order that is available? And as a result, because this informationis not available those orders do not impact the price.But with dark pools, because you don't know what the limit book looks like, ifyou put them in order the volume of the trade, the amount of your trade that'sgoing to get excluded and at what price it's going to be executed remainsuncertain. They have recently attracted a lot ofcontroversy because by some estimates dark pools are attracting about 11 to 12%of the volume of certain securities. And because that much volume is goingaway from the lit venues, it's impacting price discovery, and publicly tradedprice will no longer be fair. Dark pools have a winner's curse problem.A buyer who buys a big block in the dark pool knows for sure that there was muchhigher volume available. And so in some sense maybe what theyshould have done is let this volume go into a lit venue.Drive the price down, and then buy whatever they wanted to get from it.And as a result they could have bought at a better price on a lit venue but thereis a problem that the seller would not have come to a lit revenue, a lit venueif they have a very large trade to make. In 2009, SEC introduced new measures toincrease the transparency of dark pools, so investors get a clear view of stockprices and liquidity. So this is a concept that's, that'scontroversial, it's being pushed by a number of banks, particularly because italigns very nicely with the [UNKNOWN] desk, but it is something to keep inmind.

## 020.Optimal Execution in Excel and Real Options

### 037. Optimal Execution in Excel 1

In this module, I'm going to walk you through how to set up this optimizationproblem that involves a mean term, a variance term, and a liquidity cost term,and compute portfolios or positions that optimize mean variance and a cost term.So here's a fictitious example that has been created.I have 10 different assets. Here are the mean returns for theseassets. Here's the variance, covariance matrixfor these assets. And then I also computed the volatilitiesby simply taking the square root of these quantities and multiplying them by 100.Then I define something called volume. I'm not particular about what the unitsare. So in, in whatever are the base units,the volume is 10, 0.1, .01, and so on. So, the first asset is very liquid, andthe third asset is very illiquid according to these units.The other assets are somewhere in the middle and asset number nine is the mostliquid, it's about 100 units of volume per day.And the tension I'm trying to build up here in this example, is that theilliquid stocks, so this one for example, has high returns, so 7.17% return.And it's liquidity is 0.1, 6.75 return it's liquidity is 0.01.So, if we include, exclude concerns about liquidity, you should expect that youwould want to hold asset three and four. Asset six which has medium It has 6.289,so about 6.3% return and its liquidity is around three.So, this one asset six is a good trade off between both return and liquidity.And we would want to see how things change.Five point, asset nine, which is very liquid, doesn't have very high returnsfrom someone. So, here's the risk aversion parameterthat I'm going to be using for my portfolio selection, which is ten, it'sarbitrarily chosen. Here are the trading cost parameters.So, in my notes, I'm calling them a1, a2, a3.Here, I'm calling them alpha one, alpha two, alpha three, just because then, Ican name them appropriately. Alpha one is the factor that hits thenormalized paid volume, divided by the average beta volume, alpha two is avolatility term, and alpha three is just a interceptor.Beta is the power to which the percentage, of order to volume is raised,and it's typically around 0.65. So here's my initial portfolio.It's all ten units on all of these assets.And these are in the same units in which the volume has been quoted, so it'sacross the board uniform, and just to make things interesting I'm going toclear this. And keep it as the initial run.What about the trading costs? I'm going to use a formula.It's alpha one times 100 divided by b15, which is the average daily volume, andthe volume here I'm quoting not in per share, but in the total dollar amountstraded because I want to keep the units of the portfolio and the units of thevolume the same. So it's 100, divided by the daily volumein dollar terms, raised to the power beta, plus the absolute value of thedifference between the initial position and the final position, raised to thepower 1 plus beta. Alpha 2 times the volatility divided by100 plus alpha 3 times the absolute value of the difference in the two assets.The difference is, just to be very clear here, I'm looking at positions and not atportfolio, so I'm just going to change these names back to.All right. So, now I'm setting up the optimizationproblem. The mean return is the just a product ofthe final positions and the mean return vector up there.The variance, take the final position, multiply it by the covariance matrix, andmultiply the, the final positions once again and that will give you thevariance. The trading cost is just the sum of thetrading cost across various assets because I've assumed that the tradingcosts are going to be separable across assets.What about the objective? The objective is b31 which is the mean,minus lambda times b32, which is the variance, minus eta times b33 which isthe trading cost. So the first thing I'm going to do is I'mgoing to set trading cost parameter to zero.This eta to be zero. And what does that mean?It means that I'm going to ignore liquidity constraints and I want to seewhere does the portfolio selection move the asset.So we should typically see if I just look at returns, we should start seeing moreof an investment in asset three and asset four.Because they have high returns, but maybe not completely because of the covariancematrices and so on. So let's run the solver to try to getwhat it is, and what is solver going to do, it's going to maximize my objectivesubject to the constraint that the sum of the final position must equal the sum ofthe initial positions and I'm only allowing long positions here so, I'mgoing to make the variables non-negative. So I solve it.And you end up getting that basically the portfolio gets concentrated in assetthree about 22% there, 32% in asset four. 14% in asset six which is so this mediumone, 16% in asset seven, which has low liquidity and so on.So, this is the final position when I don't take liquidity into consideration.Now, let's put eta to be 0.1. So I have medium amount of liquidityconstraints in place, and I want to see what happens to the final portfolio.So, let's again ask for our solver to solve it.Once again, the, the problem remains the same except now my objective function haschanged because eta has been increased. So now, asset number four, which is notso liquid, but it still has a very high return, you end up still putting about30% there but it is much smaller. Whereas asset number three which haslower return and much lower liquidity, now you start reducing the amount thatyou're going to put in there. Asset number one, which didn't have muchof an investment before, but it has a pretty high liquidity, numbers about 10,ends up getting a good proportion. And the last one, asset number nine,which still, which has a liquidity of about 100 ends up getting a little bitmore position. Let's increase this to 0.5 and run itagain. And again, what it should intuitivelyhappen is happening. Six and seven, which have high returns,their money is being pulled out, and it's being spread across other assets whichhave high liquidity. And that's pretty much what I wanted toshow you in this module. You can take the approach that was byAndy Low and others and also set up an optimization problem which is verysimilar to this one.

### 038. Optimal Execution in Excel 2

In this module we'll walk through formulating and solving the optimumexecution problem that we introduced in the previous video module.In order to set up the problem, I arbitrarily took that the asset we aretrying to sell is the first asset. So the volatility of this one was readoff from the previous worksheet. And it was the worksheet of volatilitywas given in percentage so I divided by a 100 to get what the volatility numbersare. The volume is the typical daily volumethat I'm going to be using, and I need these two numbers in order to compute the[INAUDIBLE] glance's temporary price impact function.For the Permanent price function I took it to be gamma times n and the gammanumber was taken to be .001. The alphas and the deltas, thesecorrespond to the alpha here, corresponds to alpha two times B1 which is thevolatility plus alpha 3. This one corresponds to basically theconstant term in the temporary price impact function delta.I took I took it to be alpha1 plus the power divided plus beta.This is the other term that is involved in the temporary price impact function.And these 2 are used to compute what a temporary price impact function is goingto be. Okay, I have a total of a thousand sharesthat I want to sell. These are the various trades so, in trade1, in this particular setup, whatever I have, I sell 849 shares and in trade 2, Isell 104 shares and so on. And, should add up, and so this 1,000,this is a constraint that I'm going to put.In my portfolio selection, or execution problem.X is the inventory, so before anything gets sold the inventory is a 1,000.After I sell whatever is necessary, this is going to be simply initial inventoryminus the trade. Similarly over here it's going to be now.This inventory minus the trade and so on. So by the end, I must have inventoryequal to 0. In the beginning I have inventory equalto a 1000. All of these trades must add up to a1000. So, given the trade amount, I can computewhat the temporary cost is going to be, and what the permanent cost is going tobe. The temporary cost is simply alpha, whichis a linear term, times the absolute value of the trade, plus delta times thetrade to the power 1 plus beta. And the beta turned out to be 1.5, inthis particular case. And that has been read from the worksheetmean variance liquidity. What about the permanent cost?Permanent cost is going to be the linear term, so it's gamma times the trade,times the inventory, because any trade that I do, it's permanent price impact,effects all the inventory that is there at the end of the day.So that's what that term is going to be. The variance is simply going to be.Inventory squared times volatility squared, and that's what I'm going tosum. So the total trading cost is going to bethe sum of the temporary cost plus the sum of the permanent cost.The variance is going to be just a sum of these x variance terms.The objective I've said it to be basically, the sum of the trading costplus rho times the variance, and this is what I want to minimize.So let's start with row equals 0. So there is, I'm completely ignoringvariability in my calculations, and I want to see what is going to happen to myexecution strategy. When we talked about it in the module, wesaid that because I don't care about variability and the temporary priceimpact and the permanent price impact get minimized when you do equal, you shouldend up doing uniformly. And let's see whether that helps uphappening. Here are my constraints that I want tominimize the objective subject to the constraint that the total sale, totalamount of stocks that I share, sell, must equal 1,000.I had to put this extra constraint that any trade that is going to be less thanthe initial inventory just to keep the optimization problem bounded.I also made it on, all the unconstrained variables to be non negative which meansthat I cannot put an opposite trait. I can when I'm trying to sell along theway I'm not allowed to buy. But this is something that's worthexploring and may at least lead to some lower cost but I'm ignoring it.And now let's solve it. So when you started solver, it didn'tgive you exactly what we expected and that's because this is a non linearproblem and the solver doesn't get you exactly the solution that you're lookingfor, but it is going towards a solution of uniform trades.It's over 100 shares over all ten days, totaling to a 1000 shares.Now if I put rho equal to 1, which means that I'm starting to value variabilityand I want to minimize variability, but the weight is around 1.I solve it now. So you end up getting front loading theoptimal solution for this should be completely monotone but it's not exactlytowards the very end you see .50.53.66. It should be monotone but because it'slooking for a local minimum, it didn't exactly find it.Now, if I increase rho to be two, then it should try to reduce variability evenfurther which means that it starts front loading and pay.The cost that is necessary for it. So now, buy 912 shares and you end uppaying, which goes to give you a very high temporary price impact as well as apermanent price impact, and that's the cost you pay because you want to reducevariability. And pretty much that's what I wanted toshow you in this particular worksheet.

### 039. Real Options

In this module, we are going to discuss real options.These are options that are written on nonfinancial, more operational units.And they have optionality built into it. Meaning that we have the option of doingone particular set of operations, or another set of operations.And we want to use option theory to value an operation with built-in options.In this set of modules we're going to talk about how Option Theory can be usedto evaluate non-financial investment and decision problems.Some examples of this include the valuation the lease in a gold mine.We're going to go through this in detail, valuation of an equipment upgrade option.Also in the context of gold mine, we'll go through a detailed example of how onecould use Option Theory for calculating the value of such an option, valuation ofa drug development process, this could include options such that you could sellyour IP to another company, or options such that you it can increase theinvestment into a particular drug process and so on.Evaluation of a manufacturing firm that has the option of contracting itsfacilities to other manufacturers. The option here is to decide when tocontract out your facilities and how much of it to contract out.Depending up on the market conditions you could do that.And in order to figure out what the value of such a manufacture, manufacturing firmis, one has to, accurately describe the value of such an option.And we know that in order to calculate the value of an option, we have to definean discounted expected value according to the risk neutral measure.So one can apply that technique to value. A manufacturing firm.We'll go through simple examples of an evaluation of a tolling contract at apower plant, evaluation of a gas storage facilities, and so on.The real options paradigm wants to view a project as having many sources ofuncertainty. These could include market uncertaintiessuch as price for the product, demand for the product, industry uncertainties suchas mergers, mergers and acquisitions happening, innovations happening in theindustry, technical uncertainties such as research and development, when aparticular research breakthrough will happen, how will the development progresshappen and so on? Organizational uncertainties, keypersonnel might leave the company and what should the company do to react toit? Political uncertainties meaning there areregulatory changes, there could be wars, there could be government changes and soon. The real options paradigm wants to managethese uncertainties by adding flexibility to a project or to a company via options.And project management in this paradigm, is all about managing flexibility.So we will explore some simple examples of real options in these modules and getback to this idea of how to introduce flexibility, how to value theflexibility, how to optimally execute this flexibility, and so on.The example we'll be using is called a Simplico Gold Mine Case.This is example 12.7 from Investment Science in Luenberger.The set of the problem is as follows. We want to evaluate the value of a tenyear lease on a gold mine. The details are as follows.The price of gold, the current price of gold, is $400 per ounce, much lower thanwhat the current prices are right now. Each year, the price increases by afactor U, which is equal to 1.2 with probability P equal to .75, or decreasesby a factor D equals .9. With probably one minus B equal to 0.25.The cost of extracting gold is $200 per ounce.The maximum rate of gold extraction is 10,000 ounces per year.The interest rate R is 10%, so given the interest rate and given U and D above, wecan compute the risk neutral probability Q and that turns out to be two thirds.When we're doing this risk neutral probability, we're implicitly assumingthat we can buy and short sell gold. We're going to use a convention, that thecash flow, occurs at the end of the year. The revenue is the determined by theprice at the beginning of the year but this revenue appears at the end of theyear for bookkeeping purposes. So here are some details of themodelling. The current time, t, is equal to 0.The lease ends at t equals to 10. At the beginning of the 10th year we haveto return the mine back to the owners. And therefore, the lease ends.The states in each year is given by the gold prices at the beginning of the year.Let vts denote the value in state s at the beginning of the year t.It's the value of the lease in state s at the beginning of the year t.Since the lease ends in ten years, we know that v ten s is equal to zero.Now we want to compute, vts as as a recursion.So here's my time t, I'm sitting in a particular state s, and this state s isdetermined by the price of gold in that particular year.From this state I can go to two possible states.U times S, or D times S. The probability of going to U times S isQ, the risk-neutral probability, and the risk-neutral probability of going to Dtime S is one minus Q. I already know the value here.So I know VT plus 1 US, because I am doing a recursion backwards and similarlyI know VT plus 1 DS and I want to compute what is going to happen.I want to compute VTS. And the recursion is very simple.You take the revenue in year T. Plus the expected value that you wouldget, starting from time T plus 1 and onwards and discounted back by a factor 1plus R. The reason the revenue is also beingdiscounted by a factor 1 plus R is because we assume that the revenue occursat the end of the year and therefore it has to be discounted back by the annualinterest rate R. The revenue in ERT can be written verysimply to be the maximum of s minus c and 0 times the maximum rate at which you canproduce gold, which is g. What does this mean?If the current price of gold is greater than the cost of extracting gold, so sminus c is strictly positive, then you will extract gold at the maximum possiblerate. If s minus c is equal to 0, or less than0, then you will not operate the mine. So implicitly we are assuming that thereis no cost for shutting down operations in any given year.We can shut it down in one year, and reopen the mine the next year, and wedon't pay any cost for that. Since we're interested in pricing thislease, all the expectations with, must be with respect to the risk-neutral measure.Or the risk-neutral probability. And that's why we are highlighting thefact that here the expectation is with respect to the risk-neutral probability.Written out in detail this is Q times the value at the up state.That's 1 minus Q times the value of the down state.We know the value at time ten. We can compute it backwards using latticeto compute V zero of S, which is the value of the lease at time zero.In the next module, I'm going to work through this in an Excel spreadsheet andshow you exactly how this works out. Now we want to take this example a littlebit further. If you think about this example for amoment, it is actually a sequence of option.We don't do it in that way, we don't compute it explicitly in that manner.But it is a sequence of options. At the beginning of every year, I canlook at the price of gold and decide I have the option to either run the goldmine, or not run the gold mine. So, in every year, I have the option ofrunning the gold mine or not running the gold mine.And that option, has been implicitly calculated here.It's a maximum of S minus C and zero. I can choose which one I want to opt forat the beginning of every year. In the next example we will explicitlyinclude another option and then try to value it.So, this is an example with an equipment enhancement option.The details of the equipment upgrade are as follows.The cost of the upgrade is $4 million. It's a one time fixed cost.If you upgrade the equipment, the new rate of production goes up to 12,500ounces per year instead of 10,000 ounces per year.But at the same time. The cost of production goes up to $240per ounce instead of $200 per ounce that had existed before.This upgrade is an option, in that it can be exercised at any time over the leaseperiod, but once the upgrade is in place, it applies for all future years.When the lease ends they upgrade the equipment in the worst part for theminers, and the question is, what is the value of this upgrade option?So we're going to solve this in stages. First thing we're going to define, is a,value function with the in place. So V up will denote a value function.The value of the mine in state S at time T with the equipment upgrade already inplace. We can compute this using the samecomputations as we did for VS except that now we have to uses these new parameters,G up and C up. In order to calculate what V happens.Now, this is the value that you would get if the upgrade was already in place.But now you have to pay for the upgrade, and how does one model it?The upgrade is an American option that pays V up S minus $4 million if exercisedin state S on AT. We haven't upgraded equipment yet.We are sitting on a situation where the mine is operating, but the equipmentupgrade has not happened. If I decide to upgrade, I'll move to adifferent mine operating conditions at that particular time.So, here's my states s if I decide to upgrade.My value that I will get will be v up ts now, in this particular state.But in order to upgrade I will have to pay 4 million dollars so you end upgetting 4 million dollars as The cost that you pay for this upgrade.Once exercised, the equipment is upgraded and the mine is operating according topolicy corresponding to v up t, meaning that if we decide to operate a mine in vup t, we operate the mine once the equipment is placed.If we decide in a particular [INAUDIBLE] the cost.Of extracting gold is too high, we don't operate the mine,and so on.so let UTS define the value instead as in [UNKNOWN] with an upgrade option.This time, the equipment upgrade has not happened, we only have the option ofupgrading the equipment. So what do you do?In every state. And every time you have two actionsavailable to you. Either you exercise the option or youdon't exercise the option and you continue.If you exercise the option, the process stops.You move to the lattice that corresponds to the upgraded mine.You pay 4 million dollars for it and you manage the mine as if the equipmentupgrade was already in place. So that's the exercising option.If you continue, then you have not upgraded your cost of producing goldstill remains at 200. Your maximum rate at which you canproduce gold still remains as 10,000. And this recursion is just as if you werecontinuing with old equipment. And the decision now is which of thesetwo actions to choose, whether to upgrade or to continue.And we will show you in an Excel spreadsheet how these calculations aredone.

## 021.Energy and Commodities Modeling

### 040. Valuation of Natural Gas and Electricity Related Options

In this module, we're going to show you examples of natural gas and electricityrelated options, and show how option theory can be used to value operationswith built in optionality. In this module, we're going to talk abouttwo real options. The valuation of the natural gas storagefacility, and the valuation of a toning contract on a electrical power plant.And we're going to show you how some of the concepts of option pricing, can beused to evaluate situations where operations play a big important role.Caverns can be used to store gas and profit from temporal variation of price.So the idea is, you buy natural gas when the price is low, store it in a cavernand then pump it out, and sell it into the market, when the price is high.Typically, natural gas in the United States is used for heating purposes.And the demand and therefore the price of natural gas goes up in winter, whereas,in summer it's cheaper, so you buy in summer, and you sell in winter.The goal is to evaluate the value of a lease on a cavern with capacity C.So we have a cavern, here's my cavern I can pump gas into it, or I can releasegas out of it. And what I want to know is, what is thevalue of such a cavern? So let It denote the gas stored in thecavern on day, t. I would also refer sometimes to It, to bethe inventory. How much gas do you have?Let zt greater than equal to 0, denote the gas pumped out of the cavern.So whenever I am pumping gas out of the cavern, meaning I'm selling it to themarket, I'm going to assume that zt is greater than or equal to 0.When I'm pumping gas into the cavern, I'm going to assume that zt is less thanequal to 0. So, fzi denote the loss of gas, if zunits are pumped out when the gas volume, or the inventory in the cavern is I.Most of this loss. is because the gas is actually used todrive the pumps that are necessary for pumping in and pumping out the gas.Some part of it is leakage. Let P of D denote the price of gas attime T. Then the optimization problem that I aminterested in solving is the following. B of D is the price, Z of t is the amountI pumped out, fzt it, is the loss that happened at time T, when I pumped out CTin the inventory, or the amount that I stored was It.So this entire thing, that gives me the revenue from selling gas.This is the discount, and this is the expectation with respect to therisk-neutral method. Again, since I'm interested in pricing, Ineed to ensure that the expectation is with respect to risk-neutral measure.Not the real world probability, but then risk-neutral probability.What are my constraints? I need to make sure that the inventorylevel, always lies between 0 and C. These are operating constraints, theseare, this is where real, the real option part of the problem comes in.This is not a financial instrument alone. This is a financial instrument coupledwith something physical. And this says that the inventory has tobe positive, and cannot be more than the capacity C.Down here tells you the dynamics of inventory.Since I assume that zt is positive when I pull out, so the inventory and time tplus 1, is going to be simply it minus zt.The complicating factor in this particular problem is that zt, thedecisions of pumping out, ha, can be a function of past prices, and theinventory level It, could be a arbitrary function of past prices inventory levels.And, therefore, it's not something that I can compute at times 0, as the pricesevolve, I need to compute it dynamically, as we go along.This is not a new concept. Even with American option pricing, andthe gold mine equipment upgrade option that we saw in the last module, thisstory was there. We had to decide, as we went alongwhether we want to upgrade, whether we want to exercise our option, and so on.Except that here, we have to also keep into consideration what happens to theinventory, what happens to the cost of actually pumping in or pumping out thegas that I need. So we can set it up, as a dynamicprogram. So what does this dynamic program consistof? It consists of value functions.As in the case of option pricing, we have a value function that tells me what isthe value of being in a particular state. Except, in this particular problem, thereare two states. This is the gas price, and this is theinventory. The decisions that you make depend onboth the price and the inventory. And Vtip simply says, what is the valueof this lease starting at time t, when your inventory is i, and the gas price,the current gas price is p. It's a maximum of p of z minus f z i.So this is the current revenue. And this is the value from the future.This is the value of the future. And that is discounted back By E to theminus R, to bring it back into present dollars.Remember there was this constraint, that we needed to make sure that the inventorylies between 0 and C. We will put that in here, by making thisequal to minus infinity, if I minus Z is not in 0 to capital C.And that way, we can ensure that we never take decisions, where we are violatingthe constraints. How can one solve this dynamic program?We can use a binomial lattice for the price speed.So if that was the only state, we can do the backward recursion, that we've beenusing in the past. However, one has to innumerate allpossible inventory levels. Inventories are continuous variables,which not clear how to do that. You can use approximate dynamicprogramming, where the value function is approximated by factors.You can sometimes use stimulation-based optimization, where you simulate theprices from time 0 to time capital T. And then use some kind of predictivecontrol, to figure out how the inventory is going to behave, and how you're goingto get the value function out of it. I'm not telling you the details of howthese operations work. The point of this module, is simply toexpose you to problems where one is using option pricing, in situation's that haveto do with operations. Here's another example of a real option.Tolling agreements on a gas-fired power plant, allow a company renting a gaspower plant, to operate it, and then use, typically natural gas, to generateelectricity and to earn money, which is the difference between the cost ofnatural gas and the cost of electricity. What we want to evaluate in thisparticular problem, is the optimal operating policy for a company that isrenting a two regime gas power plant, over a time period 0 to T.So what does this two regime power plant mean?It means, that the plant can be operated in a low capacity mode.In which case, the output is Q lower bar, the gas consumption is H lower bar.In the high capacity mode, the output is going to be Q upper bar, and the gasconsumption is going to be H upper bar. The company does not own the power plantand, therefore, it has to pay rent to the owner's.If the power plant is shut down, it is not providing any electricity, then therent they have to pay is k. If the plant is being operated in the lowcapacity mode, then they have to pay rent k lower bar.And if they are operating it in the high capacity mode, then they pay rent k upperbar. The reason because, the rent is differentfor different states, is because implicitly in the rent, you are alsocapturing the maintenance cost. If it shut down, then the owner of theplant is simply taking rent from you, for allowing you the usage of the plant.If you run it on a low capacity mode, then the rent include both the cost ofactually giving you the operations, as well as the future cost of maintenancethat they will have to pay, because the plant was run.Presumably, if you run the plant at a high capacity mode, they have to do,maintenance more often, and therefore, they're interested in actions.And therefore, they try to get a higher rent from you.So what is the state of the plant? The state of the plant is either 0 or 1.Either it's on or it's off. If the plant is on, and you want to turnit off, you have to pay a ramp down cost of Cd.If the plant is off, and you want to turn it on, you have to pay a ramp up cost Cu.That actions that are available in given state, is to turn the plant on or turnthe plant off. So as before, in order to compute outwhat the value of a particular option, in this case, renting the plant, as well astrying to decide when to use the low capacity mode, and when to use the highcapacity mode, when to shut down the plant, when to bring it back.These are all options that are, can be used by the company while it's operatingthe gas power plant. So, in order to compute the value, we'llpostulate a value function. Let's say v t s d t t g t, so threestates now, is the optimal profit over the time, little t to capital T, with thecurrent state being s t, current state of the plant being s t, either on or off.Current price of electricity being Pt, and the current price of gas being Gt.So what I want to do now, is to set up an recursion for this problem.In order to set up this recursion, I have to tell you what happens when you takeactions. So let c(s,a) denote the cost of takingaction a when the plant is in state s. S takes two values, 0 or 1, a takes twovalues, 0 or 1. So plant is up or down, and action abasically says, either we bring the plant up or we bring the plant down.Let U S A denote the state of the plant, when action a is taken in state s.So here are the expression. If the state is 0, meaning that the plantis down, and we take the action as dow,n we do not bring it up, then the cost ofthis action is simply to pay the rent K. If the state was 0, and we decide tobring it up, then you pay the ramp up cost plus the rent K.If the state was up and you put it down, then you pay the ramp down cost plus therent K. Now, suppose the state of the plant wasup. And you continued operating it, you tookthe action of being up. Then, you have the option of deciding torun the plant either at the low capacity mode, or the high capacity mode.So this maximum, is actually is also evaluating an option.If you run it at the low capacity mode, you have Q lower bar as the production, Hlower bar as the consumption of gas, and K lower bar as the rent that you want topay. So this is, this is the profit in lowcapacity, and this is the profit, in high capacity.You take the maximum of these two, and decide that, that's the option that youare going to exercise. What about the next state?If the current state S is equal to 0, and the action A is equal to 0, the nextstate is 0. If the action is equal to 1, the nextstate is 1. If the action here is 0, the next stateis 0, action is 1, the next state is 1. So the next state is basically whateveraction that you do. The dynamic program that is going to beunderlying this, is that in a particular state SPD and GD, you take a maximumoverall possible action, so action takes value 0 or 1.The current cost of operating, so this is the current profit of operating,sometimes it's negative ,meaning that you just have to pay, and this is a futureprofit. This counted and again, risk-neutral,because we're interested in pricing. Now the stake here, consists of the priceof electricity, the price of gas and the state of the plant 0 1.One can solve this dynamic program by constructing a binomial lattice, for agas price and electricity price separately.If you want to get a correlations, then we'll have to correlate these twobinomial lattices. Each point in this lattice now willactually represent two different points. S equals to 0 and s equal to 1, meaningplant is down or plant is up. This is similar to the story that webuilt in for the defordable bonds. We had a term structure for interestrates, which was a binomial lattice, and in every state we split it up into twostates. Born alive, or born defaulted.Similarly, over here, we'll have a binary lattice, and every node will get split upinto two states. Plan up, plan down, we can do therecursion, and compute out what the values of option is going to be.Again, I'm not going to be showing you how to compute this in practice.It's a module, where we are trying to introduce this idea, that option theoryand financial engineering is starting to make an impact in other applications,where people have to also include the cost of operations.

### 041. Real Options in Excel

In this module, we'll go through the Simplico Gold Mine example that weintroduced in the video modules. The first half of this module is aboutthe operating option, meaning that the only thing that I'm trying to value is alease over ten periods and every year I have the option of either shutting downthe mine or operating it at the maximum possible rate.In the next half of this module we are going to value an equipment upgradeoption that is also valid over the ten years that we are trying to figure outwhen we will exercise it. And what is the net revenue gain that Iwould get from that option? So here are the details of the model.The current price of gold is $400 per ounce.It can go up by a factor of 1.2 or go down with a factor of 0.9.The interest rate is 10%. And therefore, from there I can calculateout what the risk-neutral probability of the up state is, and the risk-neutralprobability of the down state is. So that's going to be Q and one minus Q,respectively. The extraction rate, and cost are asfollows. The cost is $200 per ounce.The extraction rate is 10,000 ounces per year.So in order to decide when to operate this plant and when to shut it down, Ineed to have a lattice of gold. Whenever the gold price is greater than$200, I'm going to operate the plant. And I'm going to operate it at 10,000ounces per year. Whenever the price of gold is below $200I'm going to shut it down and not incur any costs.Here is the gold lattice, it starts with $400, it goes up to 480 or goes down to360 and so on. These are in thousands of dollars forups. Down here you'll see States where theprice of gold is lower than the $200 required to extract gold.And therefore in these States we are going to exercise the option of shuttingdown the mine and incurring no cost. In all the other States where the priceof gold is greater than $200, we are going to exercise the option of operatingthe plant, and getting the profits that we get from it.So here are, here is a value of the gold mine lease, in millions of dollars.At the beginning of the tenth year we return the gold mine back to the ownersand therefore the value at the beginning of the tenth year from the future isgoing to be zero. Now we start looking at what is going tohappen to a state before. So if we look at a particular state overhere, all we are trying to do, is we are using the formula that we had developedin the video modules. If I decide to operate the gold mine, I'mgoing to get K19 minus cost, which is the price at the current point, minus cost,times the maximum possible rate. But if this term, K19 minus cost, thecurrent price minus the cost of operating the mine happens to be less than zero, Iwill elect not to run the mine. I will exercise the option of shutting itdown, and get a zero from this term. So this max of K19 minus cost and zerotimes the rate tells you what is the one year revenue from operating the mine inthe optimal fashion. And that might include shutting it down.This next term, Q time offset K33 minus 11 and 1 minus Q times offset K3301basically computes what is the expected value from the future.It's Q times the value in the upstate plus 1 minus Q times the value in thedownstate, at time T plus 1, and all of it is divided by 1 plus the interest rateto bring it down to current dollar terms. So same thing is being done overe here atprevious times. Exactly the same thing and at the end ofthe day you end up getting that the value of this option turns out to be 24.07million dollars. That is total value that you couldgenerate from leasing this market. That's the fair price for the mine underthe circumstances that we are considering.Now let's go on to consider the case with an equipment option in place.So the story is the same. The gold price dynamics remain the same.You've got $400 per ounce today. They go up by a factor of 1.2, go down bya factor .9, and the risk neutral probability is 0.6.The interest rate is 10%. This lattice is exactly the same as itwas in the previous page. So now what we want to do, is figure outwhat is the value of an option that allows us to upgrade the equipment anytime between time zero, which is now, and time ten, when I return the mine back toits owner. As we detailed in the video module, inorder to compute this, I want to think of it as an American option on two differentmines. So I've got the mine which is operatingas it does currently, with $200 per ounce as the operating cost, 10,000 as themaximum extraction rate. At any given time I can exercise myupgrade option and move to another mine, which has $240 per ounce as the operatingcost, but 12,500 as the maximum possible rate.In order to do this, we showed in the video modules, I have to first calculateout the value of a gold mine with the equipment option already in place.And that's what I'm dong over here. This is the value of a gold mine leasewith the cost equal to 240 and the rate equal to 12,500.This is the value where the equipment upgrade has already happened.Again, the calculation is the same as before.You start with all zeroes and then you back calculate.You back calculate as K16, which is the cost of gold, or price of gold, minus thecost of operation, which in this case is 240, times the maximum rate, which is12,500. And Q time the upstate plus 1 minus Q thetimes table divided by the interest rate, which is 1 plus the interest rate.Calculate it backwards and you end up getting various values of the variousstates in this particular latice. Now we want to value what happens to thegold mine with an equiment option in place.You start off with 0s here. In the beginning of the 10th year youhave to give the gold mine back, whether you upgraded the equipment or not, andtherefore the value you end up getting is 0.Now lets see what happens to this particular state.It's a complicated formula, so lets go through it one by one.There are two different MAXs, there's one term over here.So this term is the same expression that we had for figuring out what to do with agold mine where the operating cost was 200 and the operating rate or the maximumrate at which you could extract gold was 10,000.So this particular maximum, all it's saying is that if I continue to use thecurrent mine, meaning not upgrade, then I still have to decide whether I wouldoperate the mine or not, and that corresponds to the max of K16 minus 200and 0, and if I decide to operate, I'm going to run it at the maximum possiblerate. And then I need to figure out what'llhappen in the future. The second term over here, this maximum,refers to the fact that now I have the option of moving from this lattice pointto the lattice that corresponds to an upgraded mine.So instead of staying on this lattice, I'll move to the upper lattice.But in order to move the upper lattice, I have to pay a cost of $4 million.So, K35 is the value that I would get, in this upgraded lattice, which is 20.73,but I have to pay $4 million for it, and therefore, I have to decide whether it'sworth it. If you look at what happened over here,the value here is 20.73, the value here is 16.94.If I had decided to upgrade, I would have got 20.73 minus $4 million which is16.73. In this particular state I can get $16.94million simply by continuing. So its worth it for me to continue, andnot pay the extra $4 million. Same thing we go backwards.Calculate out exactly the same calculations here we here.What is the maximum profit that I could get by continuing with my current mineoperations? Or I can upgrade by paying $1 million.The value here is 29.88. Which is 33.88 minus 4, so it appearsthat at least in this particular state, we will jump up, and in a little bit I'mgoing to show you how exactly the exercise boundary's going to becalculated. We calculate this backwards, startingfrom ten all the way down to time one, and at time one we get a time zero whichis the initial state we end up getting that the value of the gold mine with theequipment option in place is $24.63 million.And if you compare this to the lease without the equipment option, it's $24.07million. So it turns out that it is having thatoption, that equipment option is valuable.And the value of that is approximately $0.6 million.The thing to think about is that we can consider two different situations.One situation where we have the option in place, and another situation where we areforced to upgrade at time zero. If we are forced to upgrade at time zero,we will get $27.02 million, which is the value that I get with the upgraded mike,minus $4 million, so we would, I would only get $23.02 million.Whereas, with an option in hand, I can get $24.63 million.And the difference between these two comes from the fact with an option I havethe flexibility of when I excersize the option.So it will turn out that the various states, when the price of gold is high,and therefore I expect to make a lot of profit, it makes sense for me to pay theextra operating cost of $40 per ounce in order to get the extra rate ofextraction, which is 2500 more. So in order to decide where we are goingto extract, we just compute the two value functions.So, if you look at the genetic one over here, what we are doing is we are lookingat the value function of exercising my option versus the value function ofcontinuing. If the difference between them ispositive, I'm going to exercise. If the difference is negative I'm goingto not exercise. Negative or zero I won't exercise.So if you calculate this out, you end up getting a exercise frontier, which is thestates at which you are going to exercise.

## 022.I

### 042. Review of Basic Probability

>> We're now going to review some of the basic concepts from probability.We'll discuss expectations and variances, we'll discuss Bayes' theorem, and we'llalso review some of the commonly used distributions from probability theory.These include the binomial and Poisson distributions as well as the normal andlog normal distributions. First of all, I just want to remind all ofus what's a cumulative distribution function is.A CDF, a cumulative distribution function is f of x, we're going to use f of x todenote the CDF and we define f of x to be equal to a probability that a randomvariable x is less than or equal to little x.Okay. We also, for discrete random variables,have what's called a probability mass function.Okay. And a probability mass function, whichwe'll denote with little p, it satisfies the following properties.P is greater than or equal to 0, and for all events, A, we have that theprobability that x is in A, okay, is equal to the sum of p of x over all thoseoutcomes x that are in the event A. Okay.The expected value of a discrete random variable, x, is then given to us by thisover here. So, it's the sum of the possible values ofthe random variable x. These are the xi's, weighted by theirprobabilities, p of xi. So, that's the expected value of x.If I was to give you an example. Suppose, for example I tosses a dice.So, it takes on 6 possible values. Okay, 1, 2, 3, 4, 5, and 6.Okay. And it takes on each of these values withprobability, so that's wp, with probability 1 6th, with probability 1 6thand all the way down 1 6th. So, in this case, for example, theprobability that x is greater than or equal to 4 is equal to, well, it's 1 6thfor 4, 1 6th for 5, and 1 6th for 6, so that's equal to 1 6th plus 1 6th plus 16th equals 1 half. Likewise, we can compute the expectedvalue of x. In this case, it is equal to 1 6th times 1plus 1 6th times 2, and so on, plus 1 6th times 6.And that comes out to be 3 and a half. Okay.So, we also have the variance of a random variable.It's defined as the expected value of x minus the expected value of x, all to besquared. And if you expand this quantity out, youcan see that you'll also get this alternative representation, so that thevariance of x is also equal to the expected value of x squared minus theexpected value of x, all to be squared. Okay.So, there, a discrete round of variables, probability mass function, and so on.So, let's look at a couple of distributions.The first distribution I want to talk about is the binomial distribution.We say that a random variable x has a binomial distribution, and we write it asx tilde binomial, or bin n, p, if the probability that x is equal to r, is equalto n choose r times p to the r by 1 minus p to the n minus r.And for those of you who have forgotten, n choose r is equal to n factorial dividedby r factorial times n minus r factorial. So, the binomial distribution arises, forexample, in the following situation. Suppose we toss a coin n times, and wecount the number of heads. Well then, the total number of heads has abinomial distribution and we're assuming here that these are independent cointosses so that the result of one coin toss has no impact or influence on the, theoutcome of other coin tosses. The mean and variance of the binomialdistribution are given to you by these quantities here.So, the expected value of x equals np, the variance of x equals np times 1 minus p.Now, there's actually an interesting application of the binomial distributionto finance. And it actually arises in the context ofanalyzing fund manager performance. We'll actually return to this examplelater in the course. But let me just give you a little flavorof it now. So, suppose, for example, a fund manageroutperforms the market in any given year, with probability p.And that she underperforms the market at probability 1 minus p.So, we're assuming here that the fund manager either outperforms orunderperforms the market, only two possible outcomes.And that they occur with probabilities p and 1 minus p respectively.Suppose this fund manager has a track record of ten years, and that she hasoutperformed the market in eight of these ten years.Moreover, let's assume that the performance, the fund manager performancein any one year is independent of the performance in other years.So, a question that many of us would like to ask is the following.How likely is a track record as good as this outperforming eight years out of ten,if the fund manager had no skill? And, of course, if the fund manager had noskill, we could assume maybe that p is equal 1 half.Okay. So, actually, we can answer this questionusing the binomial model, or the binomial distribution.So, let x be the number of outperforming years.Since the fund manager has no skill, then there are ten years, and the total numberof outperforming years x, is then binomial, with n equals 10, 10 years, andp equals a half, okay? So, we can then compute the probabilitythat the phone manager does at least as well as outperforming in eight years outof ten, by calculating the probability that X is greater than or equal to 8.So, what we're doing here is calculating the probability that the fund managerwould have 8, 9, or 10 years out of 10 in which she outperformed the market.And that is given to us by the sum of these binomial probabilities here.So, these were the original binomial probabilities on each slide, and we summedthem from r equals 8, to n. And n, in this case, of course, is 10,okay? So, that's one way to try and evaluatewhether the fund manager has just been lucky or not.One can compute this probability and if it's very small, then you might concludethat the fund manager was not lucky and that she had some skill.But actually, this opens up a whole can of worms.There are a lot of other related questions that are very interesting.Suppose there are M fund managers, how well should the best one do over theten-year period if none of them had any skill?So, in this case, you don't have just one fund manager as we had in this example sofar, we now have M of them, okay? And it stands to reason that even if noneof them had any skill, then as M gets large, you would expect at least one ofthem or even a few of them to do very well.Well, how can you analyze that? Again, you can use the binomial model andwhat are called order statistics of the binomial model to do this.And we'll actually return to this question later in the course.Okay. So, let's talk about another distributionthat often arises in finance and financial engineering, that is the Poissondistribution. We say, that x has a Poisson lambdadistribution so lambda is the parameter of the distribution.If the probability that x equals r is equal to the lambda to the power of rtimes e to the minus lambda, divided by r factorial.And for those who have forgotten factorials, I also used it in the binomialmodel a while ago. R factorial is equal to r times r minus 1times r minus 2, all the way down to 2 times 1.Okay. So, this is the Poisson distribution.The expected value and the variance of a Poisson random variable are identical andequal to lambda. So, for example, we'll actually just showthis result here. It's very simple and the mean iscalculated as follows. We know that the expected value of x isequal to the sum of the possible values of x, so these are the r's, times theprobability that x is equal to r and r runs from 0 to infinity.We can calculate that as follows. So, we have the summation of r and theprobability that X equals r. We know from up here, okay, and we cansubstitute that down in here and now, we just evaluate the sum.The first thing to notice is that when r equals 0, this term in the sum is equal to0. So, we can actually ignore the 0, thefirst element, the 0 element and replace the summation running from r equals 1.So then, we get this quantity here. We can cancel this r out with the first rup here and write, this is r minus 1 factorial.We can also pull one of these lambdas out here leaving us with a lambda to the rminus 1. And now, if we look at this quantity here,this summation here, we see that this is the same as changing this to run from requals 1 to r equals 0 and replacing r minus 1 with r and r minus 1 factorialwith r factorial here. This total we see is equal to the sum ofthe probabilities. These are the probability that x equals r,so this is the sum of the probabilities that x equals 0, x equals 1, x equals 2,so this is equal to 1. The total sum of probabilities must beequal to 1, so this is equal to lambda. Okay, let's talk a little bit now aboutBayes' theorem. Let A and B be two events for which theprobability of B is nonzero, then the probability if A given B, and this isnotation we'll use throughout the course, this vertical line means it's aconditional probability. S,o it's the probability of A given that Bhas occurred, well, this is equal to the probability of A intersection B divided bythe probability of B. Alternatively, we can actually write this,this numerator probably of A intersection B, as being the probability of B given Aby the probability of A. So, this is another way to write a Bayes'theorem. And finally, if we like, we can actuallyexpand the denominator here, the probability of B, and write it as thesummation of the probability of B given Aj, by the probability of Aj.Let me sum over all Aj's. For the Aj's, form a partition of thesample-space. What do I mean by partition?Well, I mean the following. So, Ai intersection Aj is equal to thenull set, for i not equal to j, and at least 1 Ai, at least, at least one Ai mustoccur. And, in fact, because Ai intersection Ajis equal to the null set, for i not equal to j, I can actually replace thiscondition with the following, exactly one Ai must occur.Okay. So, that's Bayes' theorem.Let's look at an example. So, here's an example where we're going totoss 2 fair 6-sided dice. So, Y1 is going to be the outcome of thefirst toss, and Y2 would be the outcome of the second toss.X is equal to the sum of the two, and that's what we plotted in the table here.So, for example, the 9 here comes from the 5 on the first toss and 4 on the secondtoss. So, 4 plus 5 equals 9.So, that's X equals Y1 plus Y2. So, the question we're interested inanswering is the following. What is the probability of Y1 beinggreater than or equal to 4, given that x is greater than or equal to 8?Well, we can answer this using this guy here on the previous slide.So, this is equal to the probability that Y1 is greater than or equal to 4 and X isgreater than or equal to 8, divided by the probability that X is greater than orequal to 8. Okay.So, how do we calculate these two quantities?Let's look at the numerator first of all. So, we need two events here.Y1 must be greater than or equal to 4 and X being greater than or equal to 8.Okay. So, the first event is clearly capturedinside this box here, okay, because this corresponds to Y1 being greater than orequal to 4. So, all of these outcomes correspond tothat event. The event that X is greater than or equalto 8 corresponds to this event or these outcomes.So therefore, the intersection of these two outcomes, where Y1 is greater than orequal to 4 and X is greater than or equal to 8, is this area here, which is verylight, so let me do it a little bit darker.So, it's this area here. Now, each of these cells is equallyprobable and occurs at probability 1 over 36.There are a total of 3, 4, 7, plus 5, 12. So that's 12 cells here.So, the numerator occurs with probability 12 over 36.And the, the denominator, the probability that X is greater than or equal to 8,well, that's what we highlighted in the red here.And the probability of that occurring, well, there's 12 plus these 3 additionaloutcomes equals 15 outcomes. So, that's 15 over 36, and that is equalto 4 over 5. So, that's our application of, of Bayes'theorem. Okay.So, let me talk a little about continuous random variables.We say a continuous random variable x has a probability density function, or a PDF,f. If f of x is greater or equal to 0, andfor all events, A, the probability that x is in A, or the probability that A hasoccurred is the integral of the density, f of y, dy over A.The CDF, cumulative distribution function, and the PDF are related as follows, f of xis equal to the integral from minus infinity to little x of f of y dy.And, of course, that's because we know that f of x, by definition, is equal tothe probability that X is less than or equal to x, so this, of course, is equalto the probability that minus infinity is less than or equal to X, is less than orequal to little x. So, this is our event A here and thisdefinition here. So, A is now integrated from, A is now theevent minus infinity less than or equal to the random variable x, less than or equalto little x, so that's what we have over here.So, it's often convenient to recognize the following, that the probability that x isin this little integral here, x minus epsilon of 2 and x plus epsilon over 2.Well, that's equal to this integral, x minus epsilon over 2 to x plus epsilonover 2 times f of y dy, okay? And if you like, we can draw, somethinglike this. So, this could be the density, f of x.This is x here, maybe we've got some point here which is little x, and this is xminus epsilon over 2. This is x plus epsilon over 2.So, in fact, what we're saying is that the probability is this shaded area, and it'sroughly equal to this value, which is f of x times epsilon, which is the width ofthis interval here, okay? And, of course, the approximation clearlyworks much better as epsilon gets very small.Okay. So, there are continuous random variables.Let me talk briefly about the normal distribution.We say that X has a normal distribution or write X tilde N mu sigma squared if it hasthis density function here. So, f of x equals 1 over root 2 pi sigmasquared times the exponential of minus x minus mu, all to be squared divided by 2sigma squared. The mean and variance are given to us bymu and sigma squared respectively. So, the normal distributions are veryimportant distribution in practice, its mean is at mu, its mode, the highest pointin the density is also at mu and approximately 95% of the probabilityactually lies within plus or minus 2 standard deviations of the mean.So, this is approximately equal to 95% for a normal distribution.Okay. So, this is a very famous distribution.It arises an awful lot in finance. It certainly has its weaknesses and we'lldiscuss some of them as well later in the course.A related distribution is the log-normal distribution.And we will write that x has got a log-normal distribution with parameters muand sigma squared if the log of x, is normally distributed with mean mu andvariance sigma squared. The mean and variance of the log-normaldistribution as given to us by these two quantities here, and again, the log-normaldistribution plays a very important role in financial applications.

### 043. Review of Conditional Expectations and Variances

We're now going to review the concepts of conditional expectation and conditionalvariances. We'll see that conditional expectationsidentity as well as the conditional variance identity, and we'll see anexample where we put them to work. This material is useful because we willuse it later in the course when we discuss credit derivitives.When x and y be two random variables, then the conditional expectation identitystates that the expected value of x can be calculated as follows.We first compute the expected value of x conditional on y and then we actuallycompute the expected value of that quantity.Likewise, the conditional variance identity states that we can compute thevariance of x as the summation of two quantities.First of all, we can compute the expected value of x given y, and then compute thevariance of this quantity. And then, also compute the variance of theexpected value, sorry, then compute the variance of x given y and compute theexpected value of this quantity. Okay.One thing I want to emphasize here is that the expected value of x given y, and thevariance of x given y, are both functions of y, and are there for random variablesthemselves. So for example, I actually could writethis as g of y, say, so this is also a g of y, and maybe the variance of x given y,I could write as h of y. So g of y, and h of y, are randomvariables. So in fact, I can write the expected valueof x, as being the expected value of g of y, okay.And, I can write the variance, of x, as then being equal to the variance, of therandom variable g of y. Plus the expected value of the randomvariable h of y. Okay so there the conditional expectationand conditional variance identities and they can be very useful in manyapplications. So we'll see one application here.So, we want to compute a random sum of random variables.In particular we're going to that w equal to x1 plus x2 and so on up to xn where thexi's are IID with mean ux and variance sigma x squared.But where n is also a random variable and this random variable is assumed to beindependent of the variable xi's. So the question that arises is thefollowing. What is the expected value w?Well I can compute the expected value of w using the conditional expectationidentity. In particular the expected value of w.Well, over here I can write that as being equal to the expected value of theexpected value of w given n. And this quantity here inside here is w.Okay. So the expected value of w, given n, ifyou think about it, the expected value of w, given n, is equal to the expected valueof this summation, i equals 1 to n of the xi's.And because n is a constant, given n, I should have an n here, okay.This is equal to the sum, n, i equals 1, of the expected value of the xi's, andthis is equal to, well this is equal to mu x.And there's n terms, so that's n mu x. And that's where this comes from here.Okay. So now the mu x is a constant.We can take it outside the outer expectation over here, and we're left withthe expected value of N. So that's how we compute the expectedvalue of w. How about the variance of w.Well, we can compute the variance of w by using the conditional variance identity.So this is the variance identity here. We've already calculated the expectedvalue of w given n. It's equal to n times mu x, so that's whatthis quantity is down here. The variance of w given n, well that's thevariance of this quantity given n. These are n IID rounding variables and thevariance of n IID rounding variables is simply n times the variance of one ofthem, which is sigma x squared. And so we get n times sigma x squaredhere. So now, the variance of mu x times n, wellmu x is a constant, so it comes out the variance, outside the variance is asquare. And we're left with mu x squared times thevariance of n. And over here, sigma x squared is aconstant, and it comes outside the expectation, and we're left the expectedvalue of n. So that's how we compute the variance ofw. So here's an example with chickens andeggs. A hen lays n eggs where n is plus on withparameter lambda. Each egg hatches and yields a chicken withprobability p independently of the other eggs and then.Let k be the number of chickens. So the first question I want to ask is,what is the expected value of k given n? And of course one of the reasons I want toask this question is because I want to introduce indicator functions, which areoften very useful in probability, and in fact we'll use them later in the course.We'll be using indicator functions later in the course to describe the event ofcompanies defaulting on their bonds. So we'll use it to compute the expectednumber of defaults in the basket of bonds for example.So it's a good place right now, we could add here right now to introduce theseindicator functions. So what we're going to do is we're goingto write the total number of chickens, k, as being the sum from I equals 1 tocapital N times one subscript hi where hi is the event that the ith egg hatches.Okay. So in particular, one subscript to hi.This is the indicator function, and it takes on 2 possible values.It takes on the value 1 if the ith egg hatches.And it takes on the value 0 otherwise. So in fact that's an indicator function ingeneral it takes on two values one and zero.One if the event in question occurs zero otherwise.In this particular example the event in question is hi which is the event that theith egg hatches. Okay so we've written k as the sum from iequals 1 to n of these indicator functions.It's also clear that the expected value of one of these indicator functions is easilycomputed. In particular, it takes on the value 1with probability p. It takes on the value 0 with probability 1minus p, and so this is equal to p. So the expected value of the indicatorfunction 1 hi is equal to p. So now the expected value of k given n isthe expected value of this quantity which is k given n and n is a constant at thispoint because of conditions on its value. So, we can just take the expectationinside the summation and get this, but we know the expected value of 1hi is equal top. There's n of these terms, so we get np.So therefore the expected value of k given n equals n times p.Which of course is what you'd expect if you've got n eggs and each of them occurswith probability p. You would expect the total number ofchickens to be n times p. Okay.So now, we can use the conditional expectation form to compute the expectedvalue of k. The expected value of k is equal to theexpected value of the expected value of k, given n.But that, we have calculated there. It's np.So now, the expected value of k is the expected value of np.P is a constant. So it can come outside over here.And the expected value of n? Well n is Poisson we're told and if werecall, the expected value of a Poisson random variable is equal to lamda and sothat's why we get the lamda down here. And so we see that the expected number ofchickens is equal to lambda times p.

## 023.II

### 044. Review of Multivariate Distributions

>> We're now going to review multivariate distributions.We'll talk about multivariate CDFs, multivariate PDFs, conditionaldistributions, and so on. Much of this material is a little tedious,a little dull, but we thought it was worthwhile collecting it all and having itin one place for your review if it crops up later in the course.Okay, so let's get started. Let x be a vector of random variables, x 1up to x n. We say the joint CDF of x is given to usby the following. So, the joint CDF, Fx of little x is equalto the probability that X1 is less than or equal to little x1.X2 is less than or equal to little x2. Up to xn being less than or equal tolittle x n. And from this joint CDF, we can actuallycalculate the marginal CDF, so for example, the marginal CDF of Xi is givento us by just plugging infinity into all of the components in the joint CDF exceptfor the ith component which is little xi. Okay, so we can go from the joint CDF tothe marginal CDF. It is also straightforward to generalizethe previous definition to joint marginal distributions.So for example, if I want the joint CDF of just xi and xj, I can also recover thatfrom the joint CDF of 1 up to xn by placing infinity in all of the arguments,except for the ith argument where I have xi and the jth, where I have xj.We also say that x is a joint PDF or probability density function, f subscriptx, if we can write the joint CDF as an integral like this.So, this is just the way we, we, we capture our joint CDF by integrating outthe density function by appropriate limits.Okay. We can also talk about conditional CDFs.So what we're going to do is we're going to partition our vector x1 up to xn intotwo components. The first component is x1, which containsx1 up to xk. And the second component is this boldfacex2 which contains xk plus 1 up to xn. And then we can talk about the conditionalCDF of x2 given x1, and in fact, it's defined as following, as follows.So the conditional CDF of x2 given x1 is equal to the probability that the randomvector x2 is less than or equal to little x2 conditional on x1 being equal to littlex1. If x is a PDF, f of x, then theconditional PDF of xx2 is given to us by this quantity here.So it's the joint PDF divided by the marginal PDF of x1, which we can alsowrite like this. Okay.And the conditional CDF, f of x2 given x1, can be determined by integrating theconditional PDF. So this is our conditional PDF, and we canintegrate this out with respect to uk1 up to un and that will give us ourconditional CDF. Okay, independence.We say the collection x is independent if the joint CDF can be factored into theproduct of marginal CDFs. So in particular the joint CDF here in theleft hand side is equal to the product of the marginal PDFs over here on the righthand side. Similarly, actually, this implies that ifx is a PDF fx, then we can also factorize the joint PDF into the product of themarginal PDFs over here. We can also see from one, and one is hereon the previous slide. So we can use this, okay, to see that ifx1 and x2 are independent, then the conditional PDF of x2 given x1, well by 1,that's equal to this ratio here. So the joint PDF of x divided by themargin PDF of x 1 and by independence here, we can replace the joint PDF by theproduct. Then these two cancel and we're left withthe marginal PDF of x2. So what we're saying here is that if x1and x2 are independent then the conditional PDF of x2 given x1 is simplythe marginal PDF, f of x2. In other words, having information aboutx1 tells you nothing about x2 when x1 and x2 are independent.Okay. Some implications of independence.Well,and I expect we're all familiar with this, but let's, let's go through itanyway. Let X and Y be independent randomvariables. Then for any events A and B, theprobability that X is in A and Y is in B, well, that factorize into the product ofthe probability of X being an A times the probability of Y being in B.More generally, for any functions, f and g, independence of X and Y implies theexpected value of f of X times g of Y is equal to the expected value of f of Xtimes the expected value of g of Y. And in fact, 2 follows from 3, okay?So the implication goes that way and it's easy to see this, because we can writethis probability of X being in A and Y being in B as the expected value of theindicator function of X and A times the indicator function of Y and B.Just to remind ourselves what is this indicator function, while it takes on twopossible values, it takes on the value 1 if X is in A and it takes on the value 0otherwise. So therefore, the product of these twoindicator functions is 1 or 0 and will only be 1 if X is in A and Y is in B.Okay? That occurs with probability X and A, andY and B. So this statement here is correct.Okay, so we've got this first line. And now we can use the independents X andY in condition three to break down this expectation down into the product of thesetwo seperate expectations. Okay.But of course, this expectation is the probability that X is in A and thisexpectation is the probability that Y is in B.So indeed we do see that we can go from three to two.Okay. More generally, if X1 up to Xn areindependent random variables, then we can write the expected value of f1 of X1, f2of X2, and so on up to fn of Xn. That factorizes into a product of nseparate expectations. The expected value of f1 of X1 times theexpected value of f2 of X2 and so on. Random variables can also be conditionallyindependent. For example, we say that X and Y areconditionally independent given Z, if the expected value of f of X times g of Ygiven Z is equal to the expected value of f of X given Z times the expected value ofg of Y given Z and I should mention this is for all functions f and g.Okay, and in fact, this idea of conditioned independence, we're going tosee later in the course, because it's used in the, well, the now infamous Gaussiancopula model for pricing CDOs. So just to give you a brief idea of how itmight be used in a bond context or a CDO context, let Di be the event that the ithbond in a portfolio defaults, okay? So we'll assume that there is a portfolioof n bonds. Okay.It's not reasonable to assume that the Di's are independent.You might ask, why is that? Well, if you think about it, there will beall sorts of macroeconomic factors or industry specific factors, which willcause defaults to actually be dependent. So for example, maybe some industrycrashes that might cause not just one firm to default but multiple firms in thatindustry to default. And so, it doesn't make sense to assumethat these events, these Di's are independent.But, we might be able to say that they're conditionally independent given some otherrandom variable zed. Zed, for example, might reflect someindustry factor. Some, some factor that governs how well aparticular industry is doing. In that case, if we assume that thedefault events are conditionally independent given zed, then we can writethe probability of D1 up to Dn given Z as being the product of these factors here,probability of D1 given Z up to probability of Dn given Z.And it's actually often easy to compute these quantities.So we'll actually be using this kind of idea later in the course, as I said, whenwe discuss the Gaussian copula model for pricing CDOs.We'll also see it in a couple of other applications as well.Okay, so very briefly, I also want to mention the mean vector and covariancematrix of a vector round the variables X. I hope we're all familiar with thisalready, but let's go through it anyway. So the mean vector of X is simply thevector of expected values, expected value of X1 up to expected value of Xn and thecovariance matrix of x is. Well, this matrix of covariances.Okay, so, formula is expected value of X minus expected value of X times X minusexpected value of X transposed. And just to be clear, this is an n by 1vector, and this is a 1 by n vector, so the product is n by n.And we get an n by n covariance matrix, with the i, jth element of sigma being thecovariance of Xi and Xj. The covariance matrix is symmetric that ofcourse is because the covariance of Xi, Xj is equal to the covariance of Xj and Xi.And this diagonal element satisfies sigma i greater or equal to 0, and of course,the diagonal elements are just the variances.So this is equal to the variance of Xi and variances are always nonnegative.It is also positive semi-definite, so this is a, an important well-known property ofa covariance matrix, in particular, it means that X transpose sigma X is greaterthan or equal to 0 for all vectors X and Rn.The correlation matrix row X is similar to the covariance matrix except it has as itsi, jth element, the correlation Xi with Xj itself is symmetric, positivesemi-definite, and has 1's along the diagonal.And just to remind ourselves, the correlation of Xi and Xj, is equal to thecovariance of Xi and Xj, divided by, well, the square root of the variance of Xitimes the variance of Xj. Okay.For any matrix A, which is a k by n matrix and a k by 1 vector A, we can take alinear combination of AX plus little a and we can compute the mean of this vector.So the mean is a times expected value of X plus little a and the covariance matrix ofthis new vector of random variables is a times the covariance of X times Atranspose. And of course, five actually implies thisresult, which you're probably familiar with, that is the variance of aX plus bYequals a squared variance of X plus b squared variance of Y plus 2ab thecovariance of X, Y. Note that if X and Y are independent, thenthe covariance of X, Y equals 0, but the converse is not true in general.And some people tend to forget this, but it is not in general true that if thecovariance of two random variables equals zero, then those two random variables areIndependent. That is not true.

### 045. The Multivariate Normal Distribution

>> We are now going to discuss the multivariate normal distribution.The multivariate normal distribution is a very important distribution in finance.It crops up in many different applications including, for example, mean varianceanalysis and asset allocation, as well as geometric Brownian motion and theBlack-Scholes[UNKNOWN]. So we say an n-dimensional vector, X, ismultivariate normal with mean vector Mu and covariance matrix Sigma; if the PDF ofX is given to us by this quantity here. Okay, so the PDF is equal to 1 over 2 pito the power of n over 2, times the terminant of the covarience matrix raisedto the power of a half, times the exponential of this quantity up here.And be right that X is multivariate normal Mu, sigma.The little subscript n here, denotes the dimensionality of the vector x.The standard multivariate normal, has mean vector mu equal to 0, and variancecovariance matrix equal to the n by n identity matrix.And in this case, the xi's are independent.We can actually see that, because in this case we can write, the joint PD f of x, asbeing equal to the product. I equals one to in.One over route to pie e to the minus a half x i squared.And that follows just from this line here because mu equals zero so this termdisappears, and Sigma is just the identity.So, in fact, you just end up with a sum of xi squared divided by 2.So as we saw in an earlier module on multivariant distributions.If the joint PDF factorizes into a product of marginal PDF's, then the randomvariables are independent. Okay.The moment generating function of x is given to us by this quantity here.So phi subscript x of s is actually a function of s.Okay this vector s. And it's the expected value of e, to the stranspose x. Okay, and this is equal to e to the s,transpose mu, plus a half s transpose sigma s.Now, you're probably familiar with this in the 1 dimensional case, we'll just recoverhere. Suppose x is really just a scale of randomvariable, then the moment generating function of x is equal to the expectedvalue of e to the sx, and it's equal to e to the s mu plus the half sigma squared ssquared. And this is the case where x is normalwith mean mu and variance sigma squared. So this is the moment generating functionof the scalar. Normal random variable.This is, it's generalization to a multivariate normal random vector, x.Okay. So, we call our partition we saw in anearlier module. We can break x into two blocks of vectorsx1 and x2 as such. We can extend this notation, notationnaturally. So we can write Mu equals 1 2, and equalsto This sigma 11, sigma 12, sigma 21, sigma 22 and they are the mean vector andcovariance matrix of x1, x2. So we have the following results on themarginal conditional distributions of x. The marginal distribution of amultivariate normal random variable is itself normal.In particular the marginal. Distribution of Xi is multivariate normalwith mean vector Ui and variance covariance matrix sigma Ii.So for example X1 is multivariate normal, in fact it's k components, mu 1, sigman 1,1. And similarly X2 is multivariate normal.Mu 2, sigma 2, 2, and this is n minus k components.And we have here an example of the bi-variance normal density function, wherethe correlation beween x1 and x2 is 80%. If we rotate the service you can see thecorrelation of 80 percent the large values of X 1 are associated with values of x 2like all values of x 1 are related to all values of x 2.So we can also talk about the conditional distribution assuming sigma is positivedefinite. The conditional distribution of themultivariate normal distribution is also multivariate normal.In particular x 2, given that x 1 equals little x 1 is multivariate normal withmean vector mu 2.1. In the variance, covariance matrix, sigma2.1. Where mu 2 1, is given to us by thisexpression here, and sigma 2.1 is given to us by this expression here.And we can get some intuition for this result, by just imaging the followingsituation; so we've got X one down here. We have X two over here, and imagine weplot some points from X one and X two if you like, we generate X one and X two fromsome distribution, from the bivariate normal distribution, in particular.So the mean of X one is, let's say mew one and the mean of X two is mew two.Okay. Now what if I tell you that we observethat X 1 was equal to this little value X 1.Well if that's the case, then you can come up here and you'll see that X 2 is morelikely than not to be in this region as. I'll circle them right here.So in fact you would expect the conventional mean x one equals little xone to be maybe somewhere around here . And this would be near 2.1 okay?Likewise you can see just from this. Again, that the variance of x2 would haveshrunk. Because knowing something about x1 wouldgive us information about x2, and that would decrease our uncertainty about thelocation of x2. And in fact this expression here tells ushow to actually do that. This mathematically.So, so they're conditional distributions. A conditional distribution of amultivariate normal is again, multivariate normal.We also mention that the linear combination, ax plus a, of multivariatenormal random variable x, is normally distributed with mean, a times theexpected value of x plus little a, and covariance mix, matrix a times covarianceof x times A transpose.

### 046. Introduction to Martingales

>> In this module we're going to introduce Martingales.Martingales play a very important role in finance.They won't play a hugely important role in this course, but they will crop up now andagain and it's worthwhile understanding what they are and seeing one or twoexamples of Martingales. We're going to have the followingdefinition of a Martingale, a random process, Xn is a martingale, with respectto the information filtration Fn and probability distribution P, if these twoconditions are satisfied. The first condition is just a technicalintegrability condition which states that the expected value of the absolute valueof Xn must be finite for all n. The really important condition, iscondition two here, which states that the expected value of Xn plus m, given Fn, isequal to Xn for all nm greater than or equal to 0.A quick comment on what I mean by information filtration.So the information filtration, Fn, is just a complicated way of recognizing theinformation we have at time n. So Fn will denote all of the informationin our model that we know at time n. So usually, you will actually, it'd be thecase that Fn is equal to the information given to you by X1 up to Xn.So basically, it's just recognizing that at time n, we've already seen the valuesX1 up to Xn. Returning to condition two here, we seethat what this is really saying, is that the expected value of X, at any time inthe future, is equal to its current value today.And so, Martingales have often been used to, to model what are called fair games,they've got a rich history in gambling, for example.Because this condition here, models the idea of a fair game, so your futurepay-off, or your expected future pay-off, is equal to your current wealth today, Xm.We define a sub martingale, by replacing condition two with a greater than or equalto sign, And we define a super martingale by replacing condition two with a lessthan or equal to sign. A martingale then is both a sub martingaleand a super martingale. Here's our first example of a martingale.We can construct one from a random walk. Let Sn be equal to the sum of the Xi'sfrom i equals 1 to N, where the Xi's are IID with mean mu, then we can set Mn equalto Sn minus n times mu, and in that case, Mn is a martingale.We can see this because of the following, the expected value of Mn plus n,conditional time n information, is equal to, what we have over here on theright-hand side. So recall, Mn plus n will be equal to Snplus m, minus n, plus m times mu. So this here is Sn, and here's our m plusm times is mu. Well were taking this expectationconditional on time n information, so in that case, what we can do is, we can takeout the first nxi's, because they're known to us as a time end, so we can take themoutside the expectation. And what we're left is the expectation oftime n, of the sum of the xi's from i equals n plus 1 up to n plus m.Well, the xi's are IID, so knowing the value of the first nxi's tells us nothingabout these. We also know that they've got mean mu, sotherefore the expected value of this sum here, is equal to m times mu.We also have the n plus m mu over here. Now when we simplify all of this, thism-mu will cancel with this m-mu, we're left with the sum of the xi's and i equals1 minus n times mu, and of course, we see that this is equal to Mn.So in fact, we have shown that the expected value of m, subscript m plus n,conditional on time n information is equal to Mn, and so it's a Martingale.In this example, we're going to consider what we will call a Martingale bettingstrategy. Let x1 x2 and so on be IID randomvariables, where xi can take on two possible values, it can take on 1 or minus1, in each case it takes on that value with probability 1/2.So you can imagine xi representing the result of a coin-flipping game, you win $1if coin comes up heads, and you lose $1 if coin comes up tails, that assumes that youbet, $1 on the game. What we're going to do now is to considera doubling strategy, where we keep doubling the bet until we eventually win,once we win, we stop and our initial bet is $1.So the first thing to note, is that the size of the bet on the nth play is 2 tothe n minus 1, and that's because of the following, so on the first play, we bet $1which is equal to 2 to the 0. On the second play we bet $2, becausewe're doubling our bet, and this is equal to 2 to the power of 1.On the third play of the game we would double our bet again, so we would bet 4,and that's equal to 2 squared, and so on. So we can see that every time you playedthe game, we've doubled our bet and so the play, the size of the bet on the nth playis 2 to the n minus 1. That of course assumes we're still playingat time n, because we will only be playing at time n if we haven't yet won the gameup until this point. Let Wn denote the total winnings after mcoin tosses, And assume we start off with W0 equals 0.What we're going to show, then, is that Wn is a Martingale.To see this, first note that Wn can only take on two possible values, it can onlytake on the value 1, or it will take on the value minus 2 to the n plus 1, andthat is true for all n. Why is this the case?Well, consider the following two situations.The first situation is as follows, suppose we win for the first time on the nth bet.Well in that case, Wn is equal to minus this sum here.Where does this sum come from? Well, we've lost $1 on the first bet, $2on the second bet, and so on, up to 2 to the n minus $2, on the n minus first bet.Then on the nth bet we win and we win 2 to the power of n minus 1.Remember 2 to the power of n minus 1 is the size of the bet on the nth game, sotherefor these are our winnings at time n, if we win for the first time on the nthbet. If you actually compute this sum, justusing the, the formula for summing a geometric series, remember it's a to the 1minus r to the power of n, all over 1 minus r, that's the general formula.In this case, this translates to 1 times 1 minus 2 to the power of n minus 1 dividedby 1 minus 2, and that is equal to 2 to the power of n minus 1 minus 1, which iswhat we have here. So W n, if we win for the first time onthe nth bet, is equal to minus 2 to the n minus 1 minus 1, plus 2 to the n minus 1,this term cancels with this term and we're left With 1.Thereafter of course, we're always left with 1 because we stop playing the game assoon as we win. So the other situation that can arise, isthat we have not yet won after n bets, in that case, the winnings, Wn is equal tominus 1 plus 2 and so on up to 2 to the n minus 1.It's 2 to the n minus 1 because we also lost the nth bet, so in fact this is aminus, this becomes a minus down here, and we get this quantity here, we sum it upand we get a sum of minus 2 to the n plus 1.So therefore these are the two possible values of Wn, 1 and minus 2 to the powerof n plus 1. To show Wn as a martingale, we only needto show the following, that the expected value of Wn plus 1, given Wn, is equal toWn. And this follows by an iteratedexpectations argument. And the reason is as follows, suppose wewant to calculate the expected value of Wn plus 2 given Wn.Well in that case, we can write this as the following, the expected value of theexpected value of Wn plus 2, given Wn plus 1, all given Wn.Now this term inside here, is equal to Wn plus 1 by this result here.So by star, with n equals m plus 1, so by evaluating star but not taking n equals mplus 1 we get that this inner expectation here equals Wn plus 1.So therefore, this is equal to the expected value of Wn plus 1, given wn andof course, this is equal to Wn again by star.So in fact, for any value of little n, we can show that this result holds, justusing this iterated expectations argument we did here.So all we need to do to show that Wn is martingale, is to establish star, andthat's what we'll do now. There are two cases to consider.The first case is where Wn equals 1. Recall, we have shown that Wn can onlytake on two values, the first value is 1. So if Wn equals 1, then actually we stopplaying the game, because it means we've already won at some point, we've stoppedplaying the game and therefore, Wn is always equal to 1 in every period after wehave first won. So in this case, the probability that Wnplus 1 equals 1, given Wn equals 1, is indeed equal to 1.Which means, the expected value of Wn plus 1, given Wn equals 1 well it must be equalto 1 because that's the only value it can take.It takes on this value 1 with probability 1, so the, this expected value equals 1,which is equal to Wn. The other situation that can occur, isthat Wn equals minus 2 to the power of n plus 1.If that's the case, then we will bet 2 to the power of n, on the n plus first toss.So in that case, Wn plus 1 will be either 1, if we win the n plus first toss, or itwill be minus 2 to the power of n plus 1 plus 1, and this follows from ourarguments on the previous slides. Wn plus 1 will take on this value withprobability a half and it'll take on this value with probability half, and thatfollows because it's a fair coin, we win with probability a half and we lose withprobability half. So therefore, we have these twoexpressions here, from which it immediately follows that the expectedvalue of Wn plus 1, given Wn equals minus 2 to the power of n plus 1, it is equal to1, with prob-, with probability a half and is equal to minus 2 to the n plus 1, plus1 of probability a half. If we sum these two together, we get minus2 to the n plus 1, and that of course is equal to Wn.So in both possible cases, case 1 and case 2, we have shown that the expected valueof Wn plus 1, given Wn, is equal to Wn. And so we have shown that Wn is aMatingale. Now let me mention this example is quitecomplicated, but it was worthwhile introducing because it is easy togeneralize this example to the case where you allow random bets on each play of thegame, as long as those bets only depend on what you've seen up to that point, youwill actually still get a Martingale. For a final example, we look at somethingcalled Polya's Urn, we won't go through all the details, in fact, you can completethe details yourself. Considering urn, which contains red ballsand green balls, so we've got some urns like this, there are red balls in thereand there are green balls inside this urn. And at each time step a ball is chosenrandomly from the urn, if the ball is red, then it's returned to the urn with anadditional red ball. If the ball is green, then it is returnedto the urn with an additional green ball. So what we're going to do is we're goingto see that there are n plus 2 balls in the urn, at time n.And this follows, because we begin with two balls, and after every play of thegame we add an additional ball, either an additional red ball, or an additionalgreen ball. So we have n plus 2 balls in the urn,after time n. Let Xn denote the number of red balls inthe urn after n draws. Then, if Xn is equal to k, Xn plus 1 canonly take on two possible values, it will take on the value k plus 1, or the valuek. It will take on the value k plus 1, if theball withdraw on the nth plus 1 play is a red ball and that will occur withprobability k over n plus 2, k because there are k balls-, k red balls in the urnand n plus 2 because n plus 2 is the total number of balls in the urn.Likewise Xn plus 1 would be equal to k given Xn equals k, if we draw a greenball, because if we draw a green ball we will not be adding an additional red ball.So Xn plus 1 equals k, given Xn equals k that occurs with probability n plus 2minus k divided by n plus 2. And now, what we claim and what you caneasily check, is that Mn, which is equal to Xn divided by n plus 2, is aMartingale.

## 024.III

### 047. Introduction to Brownian Motion

>> We're now going to introduce Brownian Motion.Brownian Motion is a very commonly used stercastic process in finance.It is the process that underlies the Black-Scholes methodology and we're goingto discuss it now. So, let's define our Brownian Motionfirst. We say that a random process or stercasticprocess xt where t greater than or equal to 0 is a Brownian motion with parametersmu and sigma if, for the following fixed times: t1 less than t2 up to tn.The following increments: xt2 minus xt1, xt3 minus xt2, up to xtn minus xtn minus1, if they are mutually independent. For s greater than 0, xt plus s minus xt,must have a normal distribution with mean mu-s, and variance sigma squared s.So notice mu and sigma are the parameters of the Brownian motion, and the increment,so this is an increment of length s, it's xt plus s minus xt, that increment musthave mean, mu-s variance sigma squared s and be normally distributed.And the third condition that must be satisfied is that xt is a continuousfunction of t. In other word, if I was to plot and we'llsee this in a moment, Brownian Motion, okay through time, in fact it's actually alot more jagged than I've shown you here, but it actually never jump.So I can draw a path of Brownian Motion with my pen never leaving the page.And that's what I mean when I say xt is a continuous function of t.We say that xt is a b-mu sigma Brownian motion.Mu is the drift, okay and sigma is the volatility.Property number one, is often called the Independent Increments Property.So they're among the first people to introduce Brownian Motion from amathematical viewpoint as we've defined here.Were Bachelier in 1900 and Einstein in 1905, it's interesting that Bachelier,very little is known about him, he was a French mathematician and in fact, it turnsout he, he has had a great role to play in, in, in finance.He was trying to model stock prices on the Paris stock exchange way back in 1900 andhe tried to introduce the idea of a Brownian motion to do that.So it's very interesting to see, that a concept as important as Brownian motion,which is used throughout the physical sciences and engineering was actuallyintroduced by Bachelier in a financial context.Wiener, in the 1920s, was the first to show that it actually exists as a welldefined mathematical entity. So Brownian motion, it's a hugelyimportant stochastic process, and it plays a very big role in, in finance as well.Some other pieces of information when mu equals 0 and sigma equals 1, we havewhat's called a standard Brownian motion. We will use wt to denote a standardBrownian motion, and, we also assume that it begins at 0.So w0 is equal to 0. Note that if Xt is a b-mu sigma Brownianmotion and X0 equals little x then we can write Xt equals little x plus mu-t plussigma Wt, where Wt is our standard Brownian motion.We therefore see that Xt, is normally distributed with mean x plus mu-t andvariance sigma squared plus t. Because of course, if Xt equals this, thenthe expected value of Xt is equal to the constants X plus mu-t plus sigma times theexpected value of Wt. Wt is a standard Brownian motion, so hasmean mu equals 0 times t, so this is equal to, X plus mu-t and the variance of Xt.Well the constants don't matter, they don't factor into the variance, so thevariance of Xt is equal to sigma squared times the variance of Wt.And the variance of a standard Brownian motion has sigma equals 1, So it's equalto sigma squared times t, and that's where we get this calculation from here.So here's a sample path for Brownian motion.I've been simulating this Brownian motion by simulating these increments, which arenormally distributed between t equals 0, and t equals 2 years.So this axis represents, a time period of 2 years and I've been simulating aBrownian motion. I've-, assuming it's-, I've been assumingit starts at a hundred, so I'm thinking maybe of a security price, although youwouldn't model a security price as a Brownian motion typically, but for thepurposes of this demonstration you can think of doing so.So, that's one sample path, here's another one.We can see there's lots of different behavior, very jagged, In fact if I was tozoom in here, you would see that jaggedness still up here.Key thing to note is that these paths they're continuous, even though they'revery jagged none of them jump, okay so again, I could draw one of these paths,and make sure that my pen never leaves the page.It doesn't suddenly jump from here down to here, okay?So Brownian motion is continuous, the paths of it are continuous.On this slide, I want to introduce an important fact about Brownian motion, butbefore I do so, let us review by what we mean by an information filtration.For any random process, we will us Ft to denote the information available at timet. And then Ft for all values of t greaterthan or equal to 0 is called the information filtration.And we actually discussed this in a previous module when we spoke andintroduced, when we spoke about and introduced Martingales.This quantity here, this expectation, conditional on Ft, then denotes anexpectation conditional on the time t information that's available to us.And usually, it would be very clear what that information is.So really, this, this information filtration ss just a mathematical way ofdescribing what is intuitively obvious to us anyway.The important fact I want to introduce is the following.The independent increments property of Brownian motion implies that any functionof Wt plus s, minus Wt is independent of Ft.In other words, knowing all of the information available at time level t,that tells us nothing about the increment Wt plus s minus Wt.So that in the predictor means that Wt plus s minus Wt is normal with mean 0 andvariant, variance s, and that's in-, and that's even conditional on time Ftinformation. So let's do a calculation with BrownianMotion. We probably won't use this calculationduring the course, but there's no problem in doing such a calculation, and it helpsimprove our intuition of what's going on with the Brownian Motion.So let's compute the expected value at time 0, conditional times 0, informationof Wt plus s times Ws. Well we can use a version of theconditional expectation identity to obtain the following.So Wt plus s, I can rewrite this as Wt plus s minus Ws plus Ws.Okay, and then i'm multiplying by Ws outside, so that's this second Ws outhere. I can multiply through this Ws throughthe-, this term here and break it down into two terms.I get Ws times this term, so that's what comes into the first term here, and then Iget Ws times Ws is Ws squared, and that goes to that term, so this goes here.So now I've got two terms. Well the first thing is, let's deal withthis guy first. I claim that the expected value of Wssquared is equal to s, how do I know that? Well I know that because of the following.I know, that s is equal to the variance of Ws, but the variance of Ws is of courseequal to the expected value of Ws squared minus the expected value of Ws all to bsquared. But the expected value of, Ws is equal to0, because it's a standard Brownian Motion, so therefore the variance at w sis just the expected value of Ws squared, and that's equal to s as we've seen overhere.So that handles this second term on the right hand side of 9.How about the first term? Well a version of the conditionalexpectation identity implies the following.So I want to compute the expected value of Wt plus s minus Ws times Ws, so what I'mgoing to do is first condition on time s information.So I can actually rewrite this expectation by conditioning first of all in time sinformation, I get dou-, Wt plus s minus Ws times Ws, conditional on time sinformation this Ws term can actually come outside this inner expectation, which iswhere it is over here. And I'm left with, inside the innerexpectation with Wt plus s minus Ws. But that important fact over here.So let's call this star. That important fact tells me, that thisguy is normal with mean 0 and variance, in this case t.So therefore, the expect-, and it's independent of Fs.So therefore, this quantity here, this inner expectation, has expected value 0,and that's where the 0 comes from, and so I get 0 here.And so, therefore what we've shown, is that the expected value of Wt plus s,times Ws, is equal to s.

### 048. Geometric Brownian Motion

>> In this module we're going to discuss Geometric Brownian Motion.Geometric Brownian motion is a very important Stochastic process, a randomprocess that's used everywhere in finance. We have the following definition, we saythat a random process, Xt, is a Geometric Brownian Motion if for all t, Xt is equalto e to the mu minus sigma squared over 2 times t plus sigma Wt, where Wt is thestandard Brownian motion. So we've discussed Brownian Motion, in aseparate module, so you can look at that module, if you'd like, to remind yourselfwhat a Brownian Motion is. But one thing to keep in mind with theBrownian Motion, is that Wt, has got a normal distribution, with mean 0, andvariance t, This is one of the properties of a Brownian Motion.Recall mu the drift, sigma the volatility, and write Xt till GBM mu sigma.An interesting observation to make is the following, let's take a look at thisexpression, but let's replace t with t plus s, if we do that, we'll see that Xtplus s equals X0, and in fact I should have had an X0 here.So Xt plus s equals X0, e to the mu, minus sigma squared over 2 times t plus s, plussigma plus Wt plus s. And now what we can do, is we can rewritethis expression up here in the exponential.We can subtract a minus Wt, and add a Wt here, and we can break this summation upinto t times this plus s times this. If we do that, we get this term here inthe right hand side, but what's interesting is that this quantity here, isactually equal to Xt. So we can write Xt plus s equals Xt timesthe exponential of mu minus sigma squared over 2 times s plus sigma times Wt plus s,and this representation is very useful, it's in fact very useful for simulatingsecurity prices, when those security prices follow a Geometric Brownian Motion.This quantity here, Wt plus s minus Wt, well that's just a normal random variablewith mean 0, and variance s. Moreover, it is actually independent of Xtand this follows from the independent increment property of Brownian motion thatwe discussed in that other module on Brownian motion.So that means for example, suppose that we wanted to generate values of a GeometricBrownian Motion at time 0 and at time t, bit also may be at these intermediatetimes may be delta, 2 delta, 3 delta, and so on.Well, what we can do, so we want to generate x delta, x2 delta, x3 delta, andso on. Well, what we can do is we can actuallysimulate the Geometric Brownian Motion at these time periods by just simulating, andzero delta random variables, that's very easy to do in standard software, you caneven do it easily in Excel. So you could generate a sample path ofyour Geometric Brownian Motion or a sample path of your stock.You start at time zero with x zero which you know, and then you get x delta, usingthis formula here, with t equal to 0 and Wt plus s minus Wt, well that's just equalto a normal mean 0 variance delta random variable, so that would give you x delta.You could then get x2 delta by taking t equal to delta and s equal to delta, soyou will get x delta plus delta is x2 delta, that's equal to x delta times thisquantity again here. And again, to generate this term you couldjust generate a standard normal random variable, with mean zero and variancedelta. So it's actually very useful simulating aGeometric Brownian Motion and we may return to this again, later in the course.Here's a question, suppose Xt is a Geometric Brownian Motion with parametersmu and sigma, what is the expected value of Xt plus s given little t?Well from equation 10 of the previous slide, we know that Xt plus s is equal toXt times the exponential of this term here.Well, at time t, all of this is known to us, so we can take this outside theexpectation, and we're left with this times the expected value of each of thesigma Wt plus s minus Wt. Well this term here, as I've already said,is normal with mean 0 and variance s, so all you're trying to do when you computethis expectation, is actually compute the moment generating function of a normalrounding variable. How many have seen that before?Suppose Zed is normal with mean a and variance b squared.Then it implies that the expected value of e to the s times Zed is equal to e to thea s plus a half, b squared times s squared, so this the moment generatingfunction of a normal rounding variable. And we can just use the standard result uphere, to recognize that this must be equal to e to the sigma squared over 2 times s.This term, cancels with this term, and we get this expectation equals e to the mu stimes Xt, so that the expected growth rate of Xt, is in fact, mu.Here are some sample paths of Geometric Brownian Motion.The important thing to notice with these paths, is that they are continuous, theyare very jagged. If I was to zoom in, I would still seethat they are very jagged and they are continuous as I said, so they do not jump.I can draw any one of these paths, by keeping my pen on the page.The following properties of Geometric Brownian Motion, follow immediately fromthe definition of Brownian Motion. Recall that we saw the following, so weknow that Xt plus s, is equal to Xt, e to the mu minus sigma squared, over 2 timess, plus sigma times Wt plus s minus Wt. Okay so what are these three properties?Well the first property states, that these ratios xt2 over xt1, xt3 over xt2 and soon, they're mutually independent. And that follows, because if I divideacross here by Xt, I can see I've got the only random variable here is thisincrement, and the independent property, independent increments property ofBrownian Motion will actually imply this first property here.The second property is, the property I mentioned on the previous slide that isthat the paths of Xt our continuous as a function of t, they do not jump.The third property states, that the log of Xt plus s over Xt has got a normaldistribution as follows, and that also follows from equation 10, which I'verewritten here. So I can easily see that the log of Xtplus s divided by Xt is equal to, well it's just this term up here in theexponent, it's equal to mu, minus sigma squared over 2 times s, plus sigma timesWt plus s, minus Wt. This guy is normal with mean 0 andvariance s, and so this quantity is normal with mean mu minus sigma squared over 2s,and variance sigma squared s, which is exactly what we have here.A couple of observations about Geometric Brownian Motion.It is clear #1, that if Xt is greater than 0, than Xt plus s is always positive forany value of s greater than 0. And again, let's write out equation 10here just to see this more clearly. It's, so this is our equation 10 from anearlier slide. We can see that if Xt is greater than 0,then of course the exponential of this would be greater than 0, and so then Xtplus s would be greater than 0. So if we are using a Geometric BrownianMotion to model stock prices, then we can see that the limited liability of a stockprice, i.e., the fact that the stock price cannot go negative, is not violated.Another observation, is that the distribution of Xt plus s divided by Xt,only depends on s and not on Xt. In fact, this was clear, from the previousslide where we had this result here. The log of Xt plus s is a normaldistribution, and this normal distribution does not depend on Xt, it only depends ons and the parameters mu and sigma. And this is nice, because we wouldn'texpect returns to depend on Xt, so we can view this as being the return on a stockthe return between times t and t plus s and we don't expect in general that thisreturn should depend n the current value of the stock.So again, this is another nice property that Geometric Brownian Motion has, thatis generally reflected in stock prices as well.So these two properties suggest that Geometric Brownian Motion might be areasonable model for stock prices. And indeed, Geometric Brownian Motion isthe underlying model for the famous Black-Scholes option formula that we willalso see in this course.

## 025.IV

### 049. Review of Vectors

>> In this module we'll review vectors. I will go over definitions of vectors,what are row vectors, column vectors. We're going to define linear independence,bases, transposes, inner products, lengths of vectors or norms.All of these concepts are going to be needed for doing some of the elementarylinear algebra that's needed in this course.What's a vector? It's just a collection of real numbers.You can collect them, and put them in a row or you can put them in a column.So here is an example of a row vector. Where I've put everything as a row here'san example of a column vector and if you notice carefully both of these vectorshave n components. So we will call a vector to have ncomponents if it consists of n real numbers.A row vector or column vector and we will denote any of these vectors by the symbolr to the n. R to the n means that every component is areal number and they, there are n of them in the place.To just fix ideas it might be easier to think in terms of R2 which means these arevectors with just two components and it's easiest to think of these vectors asbelonging to a plane. And we're used to calling this plane bythe x axis and the y axis. So think of x axis being one of thecomponents of the vector. Y axis being another component of thevector. So, let me just give you some examples ofvectors that we going to use later on in this module.So, here's one vector. It's x component or the first component isgoing to be one and the second component is say going to be equal to two.So that the vector will be this vector. At the end of the dot the dot correspondsto a y axis of two and x axis of one. So was labeled this as V.This will simply be the vector one two. The first component equal to one in thesecond component equal to two. Here's another example.The x axis, or the first component equal to 4 and y axis equal to 1.So that's that point, and I'm going to be connecting it with this vector.And in the rest of this module, I'm going to referring to this vector as w.It has 4 in the first component, and 1 in the second component.By default in this course unless otherwise specified we will assume that all vectorsare column vectors, that is all the components have been arranged as a column.So we now know what a vector is, they are collections of real numbers without, bydefault it's going to be a column vector. Now we want to understand what can werepresent using these vectors, what happens with them and so on So the firstthing that we want to do is multiply these vectors with real numbers and add them up.So v1 and v2 are vectors. And I want to multiply them by a realnumber, alpha 1. And a real number, alpha 2.And then get a final vector w. So, to give you an example, here is myvector, v1. One, here is my vector V two.And just to fix ideas, each of these V one and V two actually lives in R to thethree. Why R to the three?Every component is a real number, and there are three components.So the three refers to the fact that there are three components.I'm going to multiply them by two real numbers, so two is going to play the roleof alpha one. 4 is going to play the role of alpha 2.And what do I do? I take these real numbers, multiply themcomponent by component and add them up. So, in order to get the first component, Itake the 2, multiply it to the 1, take the 4, multiply it to the 0.I get 2 times 1 plus 4 times 0 equals 2. That gives me the first component.If I want to go to the second component then I take the 2 and multiply it to thesecond component 1. Take the 4 multiply it to the secondcomponent which is also 1, 2 times 1 is 2, 4 times 1 is 4 add it up together you get6. Want to go to the third component the samething, 2 times 0. 4 times z, 1, 2 times 0 is 0.4 times 1 i 4. You get a total component 4.So when you write a vector w as a combination of vectors v1 and v2, we'regoing to say that this Vector w is linearly dependent on v1 and v2.Why the linear? Because I'm multiplying by a real number,and adding them up. Other words are, w's a linear combinationof v1 and v2. Get another word.W belongs to the linear span of v1 and v2. All of these 3 things mean the same.Linear dependency, linear combination, linear span.Now, we'll, in the next set of ideas, we'll need a concept of linearindependence. When can we say that we cannot write avector as a linear combination of other vectors.To fix ideas, let's again go back to r2, and I'm going to use my favorite twovectors, v and w. So here's my vector v and here's my vectorw. For now we don't really need what thecomponents are so I'm not going to bother with that.Now we want to understand what does a linear span mean, what can I, what kind ofvectors can I generate by scaling the w? What can I do by multiplying w by arealnumber? And you can convince yourself very easilyThat all the vector that you can get, are going to be on that straight line.When you scale it up you get, by a positive number you get up the line if youmultiply by a negative number you go down the line.Similarly all the vector that can be gotten as linear combinations of v rely onthis straight line. Now we want to ask ourself can I representv as A multiple of w. Clearly that's not true because I can't, Ican't, when I scale the w I get points on this line, v doesn't belong to that lineso I can't do anything about that. Similarly, w is not written as a linearcombination of v and therefore we'll say that v and w are linearly independent.Let's throw in another vector now, x. It's again a vector in r 2 and I want toask myself, is this linearly independent of v and w?Is it possible that x can not be written as a linear combination of v and w?Again it's very easy to convince yourself that if you just draw a line parallel tov, you can write, your vector x as a combination of vector that starts from theorigin, it's aligned to the vector w and comes up to this point.So therefore, this vector is some alpha 1 times w.This vector here is, is parallel to the vector v.So I can write it at sum scale multiple alpha 2 times v.And because, now, x is the sum of this vector and that vector, you end up gettingthat x is actually equal to alpha 1 times w, plus alpha 2 times v which means that xis linearly dependent, LD just for short, linearly dependent on v and w.In fact we'll see in the next slide that in R2 if I give you any 2 linearlyindependent vectors you can write any other vector as a linear combination ofthese 2. And that set of vectors, say these two, vand w, would actually be called a basis. So that's the next concept that I want tolearn about vectors. A basis is a linearly independent set ofvectors that spans the entire space. Any basis for Rn, meaning a vector whichhas n components, has exactly n elements. So basis for Rn has exactly n elements.In the last page I showed you an example of R2, and this should have just twoelements. V and W are linearly independent, therewere two of them, and therefore I know, that this must be a basis.Now it will turn out that its much easier to think in terms of a standard basis.What's a standard basis is shown here. Its a collection of vectors such that theyhave only one in one of the components and all of the other components are equal tozero. So the vector E1 will have 1 in the firstcomponent, the vector E2 is going to have a 1 in the second component, and thevector En is going to have a 1 in the last, or the nth, component.Now if you give me any vector W which belongs to Rn meaning that it has ncomponents, I can very easily write it as a linear combination of E1 through En.Why, because in each of these vectors is exactly one element that's not zero.So if I want to get the first element of w, right?I have to, say, take it to be w1 times e1, because everything else has zerocontribution. If I want the second component, right, Ihave to take w2 times e2, nnd so on up to wn times en.And therefore, this basis. I can split any vector w as a linearcombination very easily. And we will see that, in practice, theseterms ought to be very convenient. Again, to put it in perspective.Here's r2. Here is my x asix.Here is my y axis. And when I showed you in the first slide,x axis refers to the first component. And y axis refers to the second component.So the vector e1 is just this one. It has one component one in the xdirection and zero in the y direction. E2 is this one, it has a component one inthe y direction and zero in every other direction and it's very easy if I take avector x, all I have to do is drop it down here and This, this length down here onthe x-axis is x1, on the y-axis is x2. And it's a very easy way to combine.But any other set of linearly independent vectors, two of them will make sure thatthis is going to be a basis. So, again, this was v, and this was w fromthe last page. And v and w is also a basis.This is also a basis. And E1, E2, which is are these 2 specialones, are also a basis. The second basis is special.And we'll just call it the standard basis, because it turns out it's very convienentto work in terms of this basis. Alright.So, so far what do we know? We know what are vectors.We know linear dependence, we know linear independence.We know that if I am a vector in Rn, meaning it has n components, I can find abasis of n linearly independent vectors, such that every vector can be written as acombination of these. So what's the next concept?The next concept that we want to learn, is that of a length of a vector.Vector. So let's start with the basics.And then we'll generalize is to what I want here.So, if I give you r2. And let's take a vector which has the xcomponent equal to, let's say, 4. And the y component equal to, let's say.So this vector, has a representation four, three.Then our high school trigonometry tells us that the length of this vector is nothingbut 4 squared plus 3 squared. So I'm taking the x-axis and squaring it.I'm taking the y-axis and squaring it. Square root.So that gives me 16. Plus 9 square root which gives me 25square root equaled to 5. So that's nice.I have a, I have a definition of length. What does this definition of lengthsatisfy? It satisfies several properties.It satisfies that the length of any vector is always great than equal to 0.If the length of a vector is equal to zero, then that vector itself must bezero. So you cannot have a vector which is notequal to zero who's length is equal to zero.And the intuition follows from this triangular expression as well.If I scale a vector by an amount alpha it doesn't matter whether I scale itpositively or negatively. The length just gets scaled by theabsolute value. So, here's the idea here's the value ofvector v if I double it. >> I get this vector if I multiply it byminus 2 I get that vector, the length of this vector and the length of that vectoris the same. The direction has changed, but the lengthremains the same. That's what this absolute value does.The third one here. Tells you the relationship between lengthsof additional vectors and the original lengths, and this is known as a triangleinequality. The way you remember this geometrically isthat if you've got one vector here, you've got another vector there, the sum of thevectors is this one, the length, this length is always going to be, let's callit l. Three is always going to be lessthan equalto L1 plus L2. This is the basic geometic fact L3 has tobe less than equal to L1 plus L2. And this particular fact is encapsulatedin this little >> Statement over here, and that's why it's also called the tirangleinequality. Now mathematicians have looked at thisconcept of length, this particular concept of length that I've been talking aboutwhich is take each of the components, square it, add it up, take the square rootand now they're calling it the I2 norm. The 2 stands for the fact that I'msquaring it and take the square root and you'll notice that the properties that Iwant. The fact that the length is greater orequal to zero. The fact that triangle inequality holds.The fact that if I scale things remain the same is true for other definitions oflength. Now, since I am taping this in New York,I'm going to try to tell you about a particular notion of language, which iscalled the L1 norm, otherwise known as the Manhattan distance.I'm sitting at a particular point here, I want to travel to another point, I canonly go In blocks north and south or east and west, and I want to figure out howmuch do I need to walk in order to get from this point to that point.So I have to walk from this point to this point and then walk from that point tothat point. So this distance is 4, that distance is 3,so the L1 distance, or the L1 length, or the Manhattan distance is 4 plus 37.The L two distance is five because I can sort of cut across.The L one distance is seven. L one also satisfies all the properties ofa norm or a length and therefor it's sometimes convenient to encapsulate all ofthem as just norms and lengths. For the purposes of this course we willmostly be focusing on L two. But I just wanted you to know, that thereare other definitions of length, that are interesting, and sometimes becomeimportant in applications. Alright, now we know vectors, we knowlinear combination, we know lengths. Now we want to go to the next concept,which is that of an angle. And in order to get to an angle, I have tointroduce this idea of an inner product or a dot product.So the dot product of any two vectors v and w, so v and w are vectors in Rn.They have n components. So the dot product between v and w issimply going to be taking the ith component of v, taking the ith componentof w, multiplying them together, and adding them up.For those of you who are experts in Excel, this is nothing but sum product, take theproduct of the components and add them up. The sum product function in excel isnothing but an inner product or dot product.If you review back, into the last slide we had defined the L 2 norm there to be everycomponent's squared square root and that can now be written that length L 2 norm ofthe vector is simply take the vector v, take its dot product.So v, dot product with v, and take the square root.So now we want to understand an angle between these two vectors, so to do that,here's a picture. Here's my w, here's my v, here's an angletheta between them. So in order to understand how the innerproduct relates to the angle, the length of this vector is The length we, thelength of this vector is w. So that inner product of v and w, simplyis, take a, take the component of v along w and multiply to the length of w.So if you drop down an orthogonal point over here, this component.Is exactly equal to the norm, or the length, of v cosine of theta, and that I'mgoing to multiply with the length of w, and that should give me v dot w, whichends up giving me the cosine of theta Is exactly equal to vw divided by the norm ofv, and the norm of w, or the length of v, and the length of w.And, to emphasize the fact that these are all 2 norms.I'm just going to put a 2 there. All of that is encapsulated in this slide.Cosine of theta is v.w divided by v and w. And this is true, not just in our 2, butin our n. You an define angles in rn.I'm going to show you in the next module that v dot w is actually a combination oftwo operations, the transpose operation and the matrix multiplication operation.But that has to wait until we get to the module of matrixes.So that pretty much brings us to the end of the introduction to vectors.This is all we need to do in terms of vectors, and this is all we're going to beusing in the course. In the next prerequisite module, the next,the module that comes up next, we're going to review concepts about matrixing

## 026.V

### 050. Review of Matrices

>> In this module, we're going to review matrices.We'll define matrices, we're going to define operations such as transposes,inverses. We're going to talk about linearfunctions, and how they are related to matrices.We're going to define concepts such as rank, which will play a role later on inthe course in defining complete markets, and hedging instruments.To start at the very basic, what is a matrix?A matrix is simply a rectangular array of real numbers, and we represent the matrixby the number of rows, and the number of columns.So I'll walk you through some examples. So this matrix a, has 2 rows, row 1, row2. It has 3 columns, 1, 2, and 3, andtherefore, we're going to call it a 2 by 3 matrix.2 rows, 3 columns, 2 by 3 matrix. Its elements, I'm going to index by therow index and the column index. So if you have, if I'm talking about anin, an element called a 1 2. So the first index is going to be the rowindex. The second index is going to be the columnindex. So, it's going to be row 1 column 2.So that's the number that I am talking about.So, a 1 2 is equal to 3. Similarly, if I talked about anotherelement a 2 3, so remember the first index refer to the row, so we're talking aboutthe second row. The second index is going refer to thecolumn. The third column, so that's this elementdown here, so a 2 3, is equal to 5. So every matrix is a rectangular array, wesay a matrix is an m by n matrix, if it has m rows and n columns, so that's downhere. So this is the general a that I'm talkingabout. This particular matrix has m rows.So if you look at a partic, elements over here, it goes from a 1, 1.And remember, the row index always comes first.So it's a, 1, 1, a, 2, 1, and so on, these dot, dot, dot means, and so on.A m 1, it has n columns so the column index comes second.It's a 1, 1, a 1 2, a 1 3, and so on, and a 1 n, and the last one is a m n.Here's another example; b, it has 1 row and 3 columns, that's a row vector.In the col, in the module and vectors, we noticed that there were two kinds ofvectors, so column vectors and row vectors.Row vectors have row equal to 1, and a many number of columns.Column vectors have column equal to 1, and several rows.So here's an example of a column vector; w equals, 3, 4, 1.3 rows, 1 column, so either, I can think of it either as a vector in r 3, or as amatrix in r 3 times 1. The second 1 says it's got 1 column and 3rows. So the first thing that I want to do, isintroduce an operation called transpose. Transpose really takes rows to columns andcolumns to rows. So, the easiest way to start thinkingabout it is to think in terms of column vectors and row vectors.I've got a column vector here, v. It's got 1 column and 3 rows, 1, 2, 3rows. If I take it's transpose, if I put theoperation transpose on this vector v, I'll go from column to row.So v transpose is simply this row vector. Now, we want to do the same thing, tomatrices. I want to pretend that the matrix isnothing but a collection of columns. I'll take every column and flip it andmake it into a row, and that's what transpose does.I have a column 2, 1 over here, I'm going to flip it, and make it a row, 2 1.Same thing that I did with the vector. I have 2 6 4, 2 6 4, 2 1, 2 1.I take the second column, and I flip it, I get the second row.I take the third column and I flip it, I get the third row.So columns go to rows and vice versa, rows go to columns.It's, it's symmetric in that sense. More generally, here's a matrix a which isr m times d. To remind, to remind you once more, m isthe row index, d is the column index. So it has m rows and d columns.If I put the transpose operator, that's what this is doing, I'm going to take thiscolumn and transform it into a row, and that's what I'm going to do to everyone ofthem. So now, after the transposition is done,you end up getting that the number of columns becomes the number of rows, andnumber of rows becomes the number of columns.And so a matrix which is in r n times d, ends up being a matrix in r d times m.In the module on vectors, we had learned, that the inner product between 2 vectors,involves a transpose and a multiplication, so we figured out the transpose part.It's going to take a column vector into a row vector.Now we're going to try to see what happens, how do I multiply matrices?So the next concept is that of a matrix. So I've a matrix which is rm times d.So it's the, the row index is m, the column index, I'm going to put them in redjust to make, emphasize the fact. The column index here is d, the row indexfor the matrix b that I'm going to multiply to it, must be the same as thecolumn index of a. The inner multiplication dimension shouldbe the same, otherwise it cannot multiply these matrices.And the column index of b could be anything, say p in this particular case.So when you multiply these matrices, you get a new matrix.So the inner index that was there this d index, it disappears, and the new matrix cthat you end up getting, is going to be in m times p.So the m in the row index, becomes the row index here, and p which is the columnindex, becomes a column index there. So you end up getting a matrix which is inr m times p. The inner dimensions have to be the samein order the multiplication to happen. And when the multiplication happen, thatdisappears. There's a general formula for how to getthe elements of c, but before going there, let me give you some examples, so thatthis idea becomes clearer. So I've got 2 matrices down here.I've got this matrix, which is in r, 2 times 3, 2 rows, 3 columns.This is a vector, but I'm going to treat it as a matrix, which is an r 3 times 1, 3rows and 1 column. Now, if I apply the general rule that Ijust talked about, I should end up getting a matrix, which should be r 2 times 1,because I end up getting that the inner dimension which is the same for the multi,for the vec, matrix a and the matrix b. That will disappear and the outerdimensions are what are going to define the product.So this is the matrix c that I'm going to get, that's in r, 2 times 1, as Iexpected. So, how do I get the elements of thismatrix c? What I do, is I take the rows, andmultiply them to the corresponding columns.So in order to get c 1, 1, so I have, this is the row index, this is the columnindex. In order to get this element c 1, 1, I'mgoing to take the first row of a, and multiply it to the first column of b.I've got the first row, I've got the first column, and what does it mean to multiplya row and a column? I multiply them component by component addthem up, sum product. So I take the 2, multiply to that 2.I take the 3, multiply to 6, take the 7, multiply to 4.And that's what I have written up here. 2 times 2, plus 3 times 6, plus 7 times 4.In order to make it clear what I'm trying to do here, the elements in the bracketscorrespond to the column, the elements outside the bracket corresponds to therow, and the first component ends up being 50.So let's look at c 2 1. Second row, first column, same story.So I've got the second row here, and that's going to multiply the same column,and I'll get elements 1 times 2, 1 times 2, 6 times 6, and 5 times 4.And, if you multiply, multiply all of that together you get 58, and that's how matrixmultiplication works. So let's now go back and look at the moregeneral case about matrix a, which is r m times d.I've got a matrix b which is r b times p, their inner dimension disappears.I get a matrix c, which is r m times p. If i'm looking at a particular element c ij, this is the row index, that's the column index.How do I get this element? I take the ith row of a and multiply it tothe jth column of b. So the ith row of a, is a i 1, a i 2, therow index remains the same all the way through.Over here, I have b one j, b two j, up through b d j.So these last indices actually should be d not n.If you multiply them together using the rule that we just generated, I'm going tomultiply this element with that element and component wise, and then add it up.We'll end up getting, this is the same as the sum over l going from 1 through d, a,i, l, b, l, d, which is exactly what we have done down here.So once we know how to multiply matrixes, I can start simplifying a lot of things.L 2 norm, remember, in the modular and vectors we talked about L 2 norm?We had said that L 2 norm is the sum of the components squared, square root.We'd also shown that this is nothing but a dot product square root.Now I'm going to show you a different interpretation for it.So I've got a vector 1 and minus 2. It's, L 2 norm is 1 squared plus minus 2squared square root. I'm going to write that as 1 minus 2,that's a row vector times 1 minus 2, which is a column vector, and why do I do that?Because if I write out the expression for what this multiplication means, its thefirst component times the first component, second component times the secondcomponent, square root. So that's 1 squared, plus minus 2 squared,the same thing as down here. Now this row vector, I can also write itas, this vector, 1 minus 2, which is a column vector transpose, a transpose takesit to a row. Now we have the same vector, a vector 1minus 2 transpose times itself square root, and that's what is written downhere. The inner product between 2 vectors isnothing but take the first vector, take it's transpose, and multiply it to thesecond vector. This is a reminder, we had said in the, inthe module for vectors, that if I don't specify it, every vector is a columnvector. So, w is a column vector, v by itself is acolumn vector, I take it's transpose, I get a row vector, row vectors times acolumn vector always gives me a real number.And that's why the inner product turns out to be the real number.Alright. We know what our matrices now, therectangular arrays of numbers. We know how to take its transpose, we knowhow to take its multiplication. Now we want to take the next step, and tryto figure out what can matrices do, how are matrices and vectors connected to eachother? And their connection turns out to be,coming from linear functions. So that's our next component of thismodule, linear functions. I'm going to call a function linear, if ithas the following property. I take a vector x, and I take a vector y,I multiply this vector by a number alpha, and I multiply the vector y with thenumber beta, beta and alpha are real numbers.Back in the modular on vectors, we had talked about that alpha x plus beta y isanother vector. All we do is making, multiply everycomponent of x by alpha, every component of y by beta, and add them both componentby component. So, now alpha x plus beta y is a newvector. I'm going to take the function at this newvector. If it so turns out that for any choice ofx, any choice of y, any choice of alpha and beta, the function evaluated at thiscombination vector, is nothing but the same combination of evaluations of x andy. So, what's, what's important in terms oflinearity, is that in one case I'm taking the liner combination inside the bracket,in the other case I'm taking the linear combination outside the bracket, and the 2answers are the same, alpha x plus beta y. The function evaluated at this vector doesnothing but the function evaluated at the vector x multiplied by alpha, plus thefunction evaluated at the vector y multiplies by beta.If this is true for all x, y, alpha, beta the function is linear.There is a simple theorem, we won't get into it, that a function is linear, if andonly if, I can write that function as the multiplication of the vector by a matrix.So f of x is a linear function, if and only if, I can find some matrix a, suchthat f of x is nothing but a times x. It's just a multiplication by a matrix a,and that's why this is the next mod, next component to understanding what matricescan do. So, if I want to have a linear functionfrom r 3 to r, I have to take vectors in r 3, and I have to get a number in r.So what should be a? So this multiplication, if a is going tobe an r tie, m times d, and x is going to be an r d, a times x is going to be avector in r to the m. Now, I want to map r 3, to r andtherefore, the row index of a should be 1, and the column index should be exactlyequal to d in effect, this should be a row vector.So here's a particular row vector 2 3 4, just as an example, if you look at thecombination, if you look at the multiplication of 2 3 4 to the vector x1X2, x3, you end up getting 2x 1, plus 3x 2, plus 4x 3.It takes vectors and maps it to real numbers.Take it one step further, here's another matrix a.Now this matrix has 2 rows and 3 columns, it's going to multiply a vector with 3rows. And you'll end up getting another vectorwhich has 2 components. Why 2?Because the row index is 2. So again, component by componentmultiplication. 2 times x1, plus 3 times x2, plus 4 timesx3, that gives you the first component. 1 times x1, 0 times x2, 2 times x3, thatgives you the second component, and that's what linear functions are.Linear functions take vectors, multiply them by a matrix, and give another vector.So, in most of this course, we won't really be interested in just functions,we'll be interested in constraints, we'll be interested in sets of vectors that aredefined by functions. These might be portfolios, these might bevalues of options, these might be other kinds of things that are, random variablesand so on. So we're going to talk about 2 differentkinds of constraints, a linear equality. It would mean all those vectors x, suchthat they satisfy some linear equality. This is a linear function, it's equal tosome given vector b. We'll all talk about linear inequalities,which means that all vectors x, such that ax is less than, equal to b.When I mean less than here, I mean component by component.So I'm going to say a vector 2, 3, is less than equal to a vector 4, 5, becausecomponent by component, 2 is less than 4, 3 is less than 5.But the same vector 2, 3, is not less than equal to the vector 4 1.Why? Because the first component is less than4, but the second component is not. So therefore, this vector is not less than4 1, but this vector 2 3, is less than 4 5.So if I say a vector a x, meaning the vector obtained by multiplying, a to x, isless than or equal to b. I mean that by component by component thatvector should be less than b. Why did I only show you 1 inequality?Because, if you had an inequality, which is going the other way, ax greater thanequal to b, that's nothing but minus a x, less than or equal to minus b.So, without loss of generality, I can just look at 1 side of the inequality, it turnsout that it becomes easier to keep track of various things, if I just look at 1side of the inequalities. Alright.I've got linear functions, I've got the notion of linear constraints.Now the next concept that I want to know about matrices, is what can linearfunctions do? How complicated can a set can linearfunction generate? And, that's going to be important when westart talking about spans of matrices, and how we can think in terms of what thesespans do. So the next concept that we're going tolearn is that of a rank of a matrix. There are 2 notions, I call them rank of amatrix, and a row rank of a matrix. Let's look through the examples, and we'llcome back and look at more general ideas. And another related concept to rank, isthe range of a matrix, and we'll, we'll try to make all of this clearer by lookingat an example. So, down here is an example, I've got amatrix a, which is a 2 by 3 matrix, 2 rows, 3 columns.We know that this matrix induces a linear function, and what that linear functiondoes is it takes a vector x which is in r3, so x is in r3, meaning it has threecomponents. If you multiply this vector by the matrixa, you end up getting a vector ax, which is in r2.So, it maps 3 dimensional vectors into 2 dimensional vectors.This concept is important when we talk about ranges.But before we get there, let's start talking about a column rank.Column rank, I want to look at the rank, columns of this matrix, and ask myself,how many linear independent columns are there.How many columns can I take and write, and still leave them linearly independent?So I know for a fact, that because the columns are 2 dimensional, meaning thateach column is an r 2, I can at most get 2 vectors.Back in the module, for vectors, we had talked about linear independent, and wesaid that in r 2, 2 vectors can be linearly independent, and the third vectorwill become linearly independent. So at most, I can get 2 columns that arelinearly independent, but it turns out, that for this particular matrix, only 1column is linear independent. Why?Because if I take the first column, 1 2, I can get the second column simply bymultiplying the first column by 2. I can get the third column by simplymultiplying the first column by 3. So the second and the third column are notlinearly independent of the first column. So the column rank, which is the number oflinearly independent columns, is 1, because I can only get 1 column.Now let's do the same thing for the rows, and we end up getting a concept of a rowrank. So, here's my row 1, now it turns out,that if I take that row and multiply it by 2, I get the second row.So the row rank is also equal to 1. That's not a coincidence, there is atheorem which says that their row rank and the column rank are equal always for anymatrix. So it turns out for this matrix the rowrank is equal to 1, the column rank is equal to 1 and the rank itself is justequal to 1. So, next let's look at this notion ofrange. So, what we want to do, is we want tounderstand what does this matrix a do to the vectors in r3.So, now I want to think of this matrix not really as a matrix, but as a functionsince taking vectors in r3 and mapping them into vectors in r2.What kind of vectors I can get? What is the largest set of vectors that Ican generate by this transformation? So, it, I'm going to multiply them bydifferent components, so the vector ax is going to be equal to x1 plus 2 times x2plus 3 times x3. The second component is going to be equalto 2 times x1, plus 4 times x 2, plus 6 times x3.That is what this vector a x 3 is going to be.So, x1 plus 2, times, x2 plus 3, times, x3 times 1, gives me the first component, x1plus 2, times x2 plus 3, times, x3 times 2, gives me the second component.So every vector that I can generate by multiplying by the vector x, is of theform some real number, let's just call it lambda, times the vector 1 2, and that'sexactly what is written down here. The range of a, the set of all vectorsthat I can generate by multiplying to the right hand side of a, by sum vector x, isall the vectors of the form lambda times 1 2.What does that mean? Now, going back to the notion r2 is thisplane, one chooses the second component is equal to 2, the first component is equalto 1, that's this vector 1 2. In, in the r2 plane, all the, all thevectors that are possible, are represented by this r2 plane.But this matrix a, can only generate vectors on the straight line, nothing elsecan be generated by multiplying it by the vector x, and this is exactly what itmeans to have a rank 1. Rank 1, means that although the vector issitting in r2, meaning that it has 2 components, really it's a one dimensionalthing, that's what this 1 dimensional line tells me.On the other hand if this matrix a had rank 2, then that would tell me, that Ishould be able to generate everything in r2.Because it would, it would mean that there are two independent vectors that I couldgenerate, and I know that in r2, using 2 independent vectors, I can generateanything, and so on. In the in this course, we will never getdown to the details of how do I compute the rank, and so on.We'll work mostly with the, sort of the idea of what a rank is.And the idea that I want you to keep in mind is, the rank tells you the rich.Higher rank means that you can get a lot more things out of this linear function,lower rank means that you get less out of this linear function.In the next module, we're going to start talking about hedging, and bringing anoptimization problem. And, there we'll notice that the rank, ofthe matrix will tell me how many different payoffs can I, can hedge.Before we finish this module on matrices, there's 1 last concept, and that's ofinverse. If I've got a matrix a, which is a squarematrix n by n, both the row column, row index, and the column index is the same.And the rank of the matrix is n, meaning that all the columns are linearlyindependent, all the rows are linearly independent, then, this matrix isinvertible. What does that mean?It means that there exists a matrix a inverse, such that a inverse times a, isthe same as, a times a inverse, and which is the same as identity.So this i, remember, was identity.

## 027.VI

### 051. Review of Linear Optimization

>> . In this module, we will be walking througha review of linear optimization using a hedging example.We are going to see how there are two kinds of optimization problems, somethingcalled a primal optimization problem, something called a dual optimizationproblem, how they are related. And we also introduced the idea of LaGrangian relaxation. Here's the hedging problem that we areinterested in. I've got d assets.So take d, just to fix ideas, take d to be 3 or 4.But some number of assets that are there in the market.The price of these assets at time 0 is r to the d.It's some price vector, which has d components, where every component tells methe price of that particular asset. At time t equal to 1, the market outcomesare uncertain. I don't know what, which state the marketis going to be, it's going to be in one of m possible states.So here's the situation at time T equal to zero, and I'm in state zero, And I couldgo to one of n different possible states. Go from one, two, all the way to, down tom. What do I mean by a state?For my purposes, state is simply telling me what are the different prices that canhappen. So I'm going to characterize every stateby the prices of the asset in that particular state And I can do it in 2different ways. I could either tell you, what is the priceof all the assets in any given state, Or I can tell you the price of a given in allpossible states and we'll flip between these two ideas as we go through.We'll use the power of matrices to see what it means, sometimes, it's easier torepresent it one way, Sometimes it's easier to represent it the other way.And understanding it both ways gives us an insight of which one is more beneficialfor the particular application that I'm looking for.So, to motivate that, I'm going to define something called Sj.So S sub j, will be a column vector, and it will tell me the price of asset j inall possible states, So it's s1j, s2j all the way down to smj.J is fixed, it's asset j and the number of states would ran-, go from 1 to m.Now how do I represent all the assets in the market?I'm just going to take these column and stack them.S1 would refer to the column corresponding to S, asset one S2, asset two and so oneup to S D. If I write them out in gory detail, youend up getting this matrix. The matrix has M rows, because it's got Mstates, its got D columns because its got D assets.And what going on here, every row here, tells you the price of all the assets in aparticular state. So what I've circled here, are the pricesin state 1, S1d, 12S, 11S, 12, all the way up to S1D.Genetically, somewhere it's going to be Sm1, Sm2 , all to Smd.So every row tells me what happens to all the assets in a given state, every columntells me what happens to a particular asset in all the different states.Alright, so that's how I'm going to describe my market.At times 0 I know the price, at time 1, which is the place where the market opensagain, I don't know the price, it's uncertain, it's going to be one of npossible states, but I know that if the state is given to me, what the prices are.Now you might think that this is a very simple representation of the market, andindeed it is. But it turns out, that even in the mostmodern methods, of risk management, like value at risk, and conditional value atrisk, people represent what happens to the market By a model which looks very muchlike this. Except instead of talking about states,we'll talk about simulations. I'm going to simulate returns and I'mgoing to say, depending on all of these different scenarios, what happens?But essentially the, the main ideas are going to be captured by this simple toymodel. Alright, I know what happens to the asset.Now, what I want to do with these assets is to hedge an obligation.I'm going to walk through what does hedging mean.So, I have an obligation. What is an obligation?It's a vector x in rm. Why m?Because the obligation depends on the state.In a good state I might had to pay more, in a bad state I might had to pay less.So depending upon which state occurs, I'm going to pay an obligation xi, if thisstate i occurs. And what I want to do, is I want to buy aportfolio now, I want to buy a certain number of shares of the assets right now,in order to have enough money to pay my obligation.So, I'm going to choose a portfolio theta. Theta-1 through theta-d are going to bethe number of shares that I'm going to purchase of each of these assets.I'm going to allow for the possibility of short selling, so thetas could benegative, or I'll buy them long, which is, when thetas are positive.And I want to do, I want to choose this portfolio, so I can hedge the obligationthat, That I'm interested in hedging. So I'll step you through what it means andwhat, what hedging will ensue and then we'll go to what is the linearoptimization problem that we end up getting.Okay! So at time 0, I'm going to put, buy aposition theta at rd. Why d?Because it's got d different assets. So theta J's the number of shares ofassets J that I purchased, where J goes from 1 through d.What's the cost of this purchase? The cost of the position theta, is simplythe price of every asset times the number of shares that I produce.A lot of those assets! So it's pj times theta j, sum from j equalto 1 through d. It's the inner product of the vector p,with the vector theta. And we know that inner products arenothing but p transpose times theta. What happens at time t equal to 1?So, if a state i occurs, then I'm going to liquidate my position.And when I liquidate positions, I'm going to sell the assets.And what's going to happen? In state i, the price of asset j is s, i,j, I hold theta j positi-, shares of this asset, so by selling asset j I get Sijtimes theta j But I'm going to liquidate the entire portfolio.So j I'm going to sum from 1 equal to d and that's the amount of money, that's thepay-off that I'm going to get in the stake.Its just Sij time theta j sum from j equal to 1 through d, That gives me yi.And if you just think about it for a moment, if I stock up all the pay-offs asa vector. If I call a vector y to be y1, y2, all theway up to y m, the pay-offs in the m states This is nothing but the matrix S,Times the vector theta. Just to remind you, this is my matrix S,it has prices for every state as rows. So the payoff in the first state would bethis row times the vector. And the second state would be this rowtimes the vector. And that's exactly what is being donehere. Sij, as j goes from 1 through D, is a row.You take the i'th row, multiply it by the vector, you get the payoff in the i'thstate. And therefore, the vector y is simply thematrix, times theta. Now I want to look at this, in a differentway. I want to think of this, as notmultiplying row, row by row but column by column.So, instead of looking at this matrix S, as row by row as we have done so far, I'mgoing to put them in columns. I've got the column for the first asset,column for the second asset, column for the d asset and, that's going to multiplytheta-1 theta-2 up to theta-d. And you can see that this multiplicationis nothing but, this row, times this column, so you'll get theta j times Sj.J is summed from 1 through, that should not be an n, but a d.It goes from j equals 1, through d. Interpreting it this way, you end upgetting a different interpretation of what is going on.Now, the pay-offs ys are nothing but linear combinations of the columns.So vector y, will, I can represent, I can generate a particular pay-off, if it's inthe range of the matrix S. Remember in the concept, we had introducedthis concept in the model of matrices, that a vector y, belongs to the range, ofs, if these are all vectors s-theta, where theta is in, r to the d.And therefore, y belongs to the range of S.And remember, we had also introduced the notion of rank.We had said, that rank tells me how rich that space is.Can I, how many different vectors can I generate in the range?So if the rank of the matrix S is n, is equal to m, meaning all possible pay-offscan be generated, then I can hedge everything.If on the other hand, the rank of the matrix s, is less than m, that means thereare certain pay-offs. There are certain pay-off vectors that cannot be generated because they can not be produced as if I'm make, taking the matrixS and multiplying it to theta. So that's the concept that's going to playa role in the course.We're going to talk about complete markets and incompletemarkets, and that has to do with the rank of this matrix.Before we get there, here's a simpler notion.We'll say that a pay-off y hedges x, if y is greater than or equal to x.Component by component, the pay-off that I've generated using my portfolio isgreater than the pay-off that I need to hedge or give-, the payoff that I need togive at time 1. Alright, now comes our first optimizationproblem. What's the optimization problem?I want to minimize the price of the portfolio such that it hedges myobligation. I want to minimize p transpose theta, suchthat s-theta is greater or equal to x. And, what are some features about thisoptimization problem? The objective!What I'm trying to maximize or minimize is a linear function, linear function oftheta. The constraints!Constraints, and what thetas that I can choose, are again linear constraints, astheta must be greater than or equal to x. Linear or inequality.So any optimization problem, which has a linear objective function, eitherminimization or maximization it doesn't matter, and all the constraints are eitherlinear inequalities, as is the case here, or linear equalities.We will call that problem, a linear optimization problem, or a linear program.It turns out that linear programs are very rich, there's a rich theory about them,and you can do a lot of interesting things with them.You can model lots of problems, you can solve them very efficiently, you can get alot of interpretation out of them. So the one thing that we're going to focuson in linear optimization, and the interpretation of linear optimization isthe notion of duality. And what do I mean by the notion ofduality? For every linear program, I can writeanother linear program which is intimately connected to it, and this connection iscalled duality. So I've got a linear program here minimizex, c transpose x, Ax greater than or equal to b.Here's another linear program. Maximize B transpose U, A transpose Uequal to C and U is greater than or equal to 0.Min goes to max. Now, for the purposes of this course, youwill not be responsible for how I generated the dual linear program from theprimal linear program, or the second linear program from the first linearprogram, we will give you that in the course.The only thing that you're going to be responsible for is, to understand therelationship, and we'll emphasize this again during the course.They're here from-, some of the interesting resolve that comes from thisduality concept. The first thing is something called weakduality. What it says is that this minimizationproblem. So the way I, the picture that I have, Iwanted to keep in mind is that here's my value P.For all feasible values, for all xs, such that Ax is greater than or equal to wha-,b, I get some numbers on this side. Why do I get greater?Because I'm trying to minimize. So I get the lowest possible number is p.I've got another number d. Which is the value of this second linearprogram down here. For all Us that are feasible, meaning thatsatisfies A transpose U equal to C, and U is greater than or equal to 0, I'll getvalues that are less than this D. Why?Because this is a maximization problem. The largest possible thing that I can getis B transpose U, is going to be equal to D.The first theorem says, that in fact, this picture that I'm drawing is correct.That P is going to be greater than D. There's no reason for it to be that way,they could have crossed. But the nice thing is, if you constructthe dual linear program correctly, and in the next slide I'm going to show you asimple example. Again let me emphasize you're notresponsible for knowing it. Just walking through the exercise, andunderstanding how I'm going to use the duality.So the primal and the dual are intimately connected; the optimum value of the primalP is greater than equal to the optimum value of the dual D.And because this is true, you end up getting a chain of inequalities that arevery good. We know that c transpose x is greater thanequal to p. Why?Because I''m trying to minimize c transpose x, so for any feasible x,anything that satisfies the inequality Ax greater than equal to b, I'll get a valuegreater that b. The second piece is also true, D isgreater than equal to b, transpose u because I'm trying to maximize b transposeu. And the inner part comes because of the vduality. So now this gives you a very interestingway, if I can find an x, and I can find a u, such that c transpose x is close to btranspose u, then I know that the x must be very close to optimal, And u must alsobe very close to optimal for the dual. Why?Because P is greater than, equal to D, if these two at, points are very close, itmust, it must be that P is also very close to c transpose x, which means that it'soptimum. Similarly, b transpose u must be close toD, which means that is optimum. You end up, you can go one step further,and say that when either P, or D, is finite, either the primal value is finite,or the dual value is finite, then in fact, they must be equal.And finally, the reason why we call them dual, is because if you go from the primalto the dual, and from, you take the dual of the dual, you get back the primal, andthat's why they're called dual linear programs.Going a little bit further. Here's another pair of primal dual linearprograms that we'll be, that we'll be using in the course.Minimize over x, c transpose x, Ax equals b, they, it's equal to maximize u, btranspose u, A transpose u equal to c. And this equality, I'm putting it there toemphasize the fact that there is strong duality between them.But to keep in mind that this equality holds only if you can show that eitherthis one, p or this one, b is finite. So if p, or d is less than, is less than,is not equal to let's say, plus infinity or minus infinity, in that case these twovalues are the same, and in that sense they are equal.So, the last piece in this module, we're going to walk through and tell you how toconstruct a duel, it's a very general concept called La Grangian relaxation.And we'll use that in the next module on non linear programming, as well.So here's the problem. The primal problem is, minimize ctranspose x, Ax, greater than or equal to b.Now I'm going to take a vector u, which is greater than or equal to zero.And so u is component wise greater then or equal to 0, and remember Ax is going to begreater than equal to b. So Ax minus b is component wise greaterthan equal to 0, you take some vector which is component wise greater than equalto the oh, multiplied to another vector that is component wise greater than equalto 0, you end up getting a number, which is greater than or equal to 0.So I'm subtracting it, so I'm getting a number, which is less than c transpose x.So this linear program, which has a changed objective function involving thisvector u, is going to have a value, which is going to be less than equal to P.B transpose U does not involve the decision x, it does not involve theminimization, the minimization is going on over x, it does not involve x, so I pullthat out. I end up getting a new problem, which isminimize c minus a transpose u times x. And what happened to this constraint?I threw it away! Why did I throw it away?It's complicated. I don't know how to deal with constraints,so I threw it away. But I'm guaranteed that if I throw awaythese constraints my set over which I can optimize, the xs over that I can chosebecome larger, and therefore this minimum only becomes smaller.So I end up getting that this quantity, is going to be smaller than the previousline. Now, because I don't have any constraints,I have a very simple problem. I've got some vector, let's call thisvector d. I've got d transpose x.So I want to minimize d transpose x. So here's my d vector.I want to minimize this, d transpose x, and I can choose my x to be anything.So what am I going to do? I'm going to choose my x to be in thenegative direction and going off to infinity.Here's my b, here's my x! If I multiply d and x together I get avery large negative number. So if I have vector d which is not equalto 0, I can make this optimization problem equal to minus infinity and that's whatthis says. If d is not equal to 0 and, just toemphasize d's equal to c minus A transpose u, if this is not equal to 0 you get tominus infinity. If in fact, d is equal to 0, which meansthat c is equal to A transpose u, then I can't do anything over here.This vector is equal to 0, I multiply to any other vector, I'll get a 0.So you end up getting that this minimization problem has a value equal to0. And p is greater then equal to b transposeu. Now u is arbitrary, the only thing that Ineeded to do was, which is missed over here, is that I needed to have that u mustbe greater than equal to zero. So now, you have p must be greater thanequal to maximize b transpose u, which is the value here, provided A transpose u isequal to c and u is greater than equal to 0.That immediately gives you a weak duality, a little bit more work gives you a strongduality. So here's the connection.Max-, minimize C transpose x, Ax greater than or equal to B is equal to maximize Btranspose U, A transpose U equal to C, and U greater than equal to 0.That's what we derived over here. What we did, we dualize constraints, andthis word will show up some times during the course.Dualize means I take the constraints and multiply them by a variable which has aparticular sign. We had a constraint Ax minus b, Imultiplied by a vector of u which is greater than equal to 0, that'sdualization and then I'd relax the constraint.I have this constraint Ax greater than equal to b, I didn't like it, it was toocomplicated, I threw it away. I'd relaxed them!And by doing dualization and relaxation, you end up getting something called a LaGrangian relaxation, which gives you duals, And gives you some very niceproperties that we'll explore more in the course..

### 052. Review of Nonlinear Optimization

>> In this module, we are going to talk about nonlinear optimization.We will review unconstrained optimization, and then briefly talk about constrainedoptimization and in particular, Lagrangian relaxation and its two applications.One on some utility maximization problem and another one on a mean-varianceportfolio selection problem. Let's start with unconstrained nonlinearoptimization. What does unconstrained mean?It means that I'm allowed to choose any vector that I like to try to minimize afunction. To keep everything general, we will assumethat I've got a function f of x, and what is x?X is a vector, in Rn. It's a vector with n different components.It's a unconstrained problem so I can minimize my f of x, the function, over theentire space. It turns out that for non-linearoptimization, we have to differentiate between two kinds of minimum problems.Ordinarily, we just want to find a vector x which takes the minimum possible value.So, here's a picture. I've got a one-dimensional function.Here's my x, here's my function f of x. Now, when I'm trying to minimize thisfunction f of x, all I need is this point. This is my point x star the minimum.It's the global minimum. It's the best point that I want in theentire real line. But as we'll go through this lecture,note, we will see that, when it comes down to nonlinear programming, we try to findthese points by looking at derivatives. By taking first derivative, which willgive me the gradient, or the second derivative, which will give me the Hessianmatrix. Derivatives, unfortunately, can look onlyin the neighborhood of a point. They can't go look far away, becausederivatives are defined by taking limits of points coming arbitrarily close.So, in order to be able to work with derivatives, we have to have anothernotion, which is that of a local minimum. So, this point here is a local minimum.Why is it a local minimum? Because if I just go in a neighborhood ofthis point, if I look for points that live in this little interval around here, thenfor this little local neighborhood, this point is actually optimum.It is true that if I leave neighborhood I get other points that are better, x starover here is a global optimum point. And therefore, that's better than thislocal optimum point or at least as good as the local optimum point.But within this interval, I can't get any other point.So, for nonlinear optimization, we have this notion, two different notion.Global optimum point, that's where we want to get to.Local optimum point, which are locally optimum, that's what we can get because weuse derivatives. So now, we are going to describe what arethe conditions that we need in order to get a local minimum.Remember, local means only in the neighborhood.It means that these criteria are given by taking derivatives.A point is a local minimum if the gradient at that point is going to be 0, meaningthat, what's a gradient? It's a vector, remember this function?Is a function from Rn, meaning that it's got a vector x, which has n components.Therefore, the gradient is simply the partial derivatives.I take the function, I take the partial derivative with respect to the firstcomponent, the partial derivative with respect to the second component, partialderivative with respect to the nth component and stack it up as a vector.When I say that gradient is equal to 0, I mean that every component is equal to 0.Here's a simple example. Let's take F of x is equal to 2x squaredx1 squared plus 3x2. So, the partial of f with respect to thefirst component, is going to be 4x1. The partial of f with respect to thesecond component is going to be equal to 3, because the x2 goes away.So, the gradient is going to be 4x1 and 3. So, when is it equal to 0?That means, that x1 must be equal to 0. So, for any local minimum, it must be thecase that x1 is equal to 0. But that's not sufficient.We have to take a matrix of second derivatives, and that matrix must bepositive, semi-definite at any local minimum, and positive definite, if youwant to be sure, that, that point is a local minimum.How do I construct this matrix? I take the partial derivatives and stackthem up as a matrix. First component, remember, for any matrix,this is going to be the one, one component.So, I take the partial derivative with respect to x1 and take another partialderivative with respect to x1. This point here is 1, 2, so I take thepartial derivative with respect to x1 and then a partial derivative with the respectto x2. Just a, just to recall that if a functionis twice differentiable, meaning you can take two derivatives then it doesn'tmatter the order in which you take the derivative.Whether you first take it with respect to x1 and then you take it with respect to x2or vice versa. And we'll see an example in a moment.You stack them up on the matrix, that matrix must have all non-negativeeigenvalues. We won't get into the detail ofeigenvalues because we don't really explicitly need it.They can be easily computed in MATLAB. You can just give a command called eig, itwill tell you the eigenvalues of the matrix.If all the Eigenvalues are non-negative, then it'll turn out that it's a localminimum. If it turns out that all the eigenvaluesare strictly positive, then it's definitely a local minimum.Now, functions that are going to be useful are called convex functions and when weuse these functions, we are going to remind you in the course.But the picture that I have, I want you to keep in mind is the function is convex ifit looks like this. I take any two point and I draw thestraight line joining those two points and the function.The straight line lies above the function. So, this is a convex function.Here's a function that is not a convex function because if I take these twopoints and join them, that's not lying above the function.So, convex functions are particularly nice if I'm trying to minimize a convexfunction that I don't even have to check the Hessian.I just get the gradient, set it equal to 0 and I'm done.We'll walk you through to two examples of what is going on here.So, first example is unconstrained nonlinear optimization.Here's the problem that I want to solve. I want to minimize over x in our two, twocomponents, this function. X1 squared plus 3x1 x2 plus x2 cubed.I first take the derivative and set it equal to 0.I get 2x1 plus 3x2 as the partial derivative with respect to x1.I get 3x1 plus 3x squared as the partial derivative with respect to x2.I set it equal to zero, and I solve it. The first equation tells me how x1 and x2are related. I plug that into the second equation.That gives me a quadratic, which has two roots.It turns out that the two roots are x equal to 0 or x equal to minus 9 over 4,and 3 over 2. So, the first component is minus 9 over 4.The second component is 3 over 2. If I take the partial derivative, thesecond partial derivative, I take this one and take its partial derivative withrespect to x1, I get 2. I take the same and I take the partialderivative with respect to x2, I get 3. For this one, if I take the partialderivative with respect to x1, I get 3 but I should have known that already becauseit doesn't matter the order in which I take derivatives.So, the off diagonal-terms are always the same.If I take this,[UNKNOWN] take the second derivative with respect to x2, I get 3times 2, 6x2. If I plug x equals to 0, which means x2 isequal to 0, I get this matrix. That's not positive definite, so it's nota local minimum. It has actually one positive eigenvalueand one negative eigenvalue. If I put x equal to minus 9 over 4, 3 over2, it turns out that this matrix is positive semi-definite, meaning it hasnon-negative eigenvalues and, in fact, it's positive definite, meaning that ithas all positive eigenvalues, and therefore, I know that this is a localminimum. That's all that we need to know as far asthis course goes about unconstrained nonlinear optimization.Take the gradients that are equal to 0, figure out what's happened to the Hessian,or the second-order matrix. Next, we want to take this idea and applyto constraint problems. So, here's a constraint problem.A typical problem like this will show up in a utility maximization problem.I have two different things that I could do.I could either invest in 1s, one particular business or another particularbusiness and I have a total wealth of 12. So, x1 plus x2 equals 12.If I put money into the first business, I get 2 times log 1 plus x1 as my return.If I put it in the other business, I get 4 times log 1 plus x2 as the second return.Now, log, logs are going to have diminishing returns so eventually, eventhough I put money in the second one, which gives me incrementally the betterreturn, I'll end up getting lesser and lesser and so at some point, the firstproject will become more competitive. Now, the constraint tells me the totalamount of money that I have is just 12. If this, if there were no constraints, Iwould solve this problem easily. But this constraint makes my problemharder. It's a convex problem because log is aconcave function and trying to maximize a concave function with respect to somelinear constraints. And this is a convex problem so in theory,this is easy. So, in order to get rid of theconstraints, what we do is we multiply it by a variable and add it to the objective.So, I've got 2 log 1 plus x1, 4 log 1 plus x2.This is just the objective. Here is my multiplier and it's, it has amean which is sometimes called the Lagrange multiplier because Lagrange wasthe first, first mathematician who came up with using this idea.Try take the Lagrange multiplier, v, multiply it to the constraints x1 plus x2minus 12, what's happened to the minus 12, I moved the 12 on to the other side thatbecomes my constraint and subtract it from the objective.Now, I throw away the constraints. Remember, we had done something verysimilar to this in the module linear optimization.We dualized the constraints, multiplied them by a quantity that is a multiplierwhich had to have some sort of particular sign.In this particular case, I threw away the signs as well.We can be anything and then I threw away the constraints, I relaxed and it justoptimized the objective, in order to get the dual linear problem.I'm doing the same thing here. I've got a nonlinear objective, I'msubtracting a multiplier times the constraint and then, I'm going to throwaway the constraints and pretend that this is an unconstrained problem.In order, I know that this problem is convex so in order to get the optimumpoint, all I have to do is find the gradient and find its solution.So, I take the gradient of this Lagrangian function.From here, I get 2 over 1 plus x1. From here, I get minus v.That's the partial derivative with respect to x1.Partial derivative with respect to x2, I get 4 divided by 1 plus x2 minus v, fromthis one, and that is equal to 0. If I solve this, I get x 1 is equal to 2or v minus 1, x2 is equal to 4 over v minus 1.How do I get this v? I know that the optimal solution, x1 plusx2, must equal 12, so I plug it in to the equations, and I end up getting anequation that says, 6 over v must equal 14, or v must equal 3 over 7.Once I know the value of v, I plug it back into the expression for x, I get x isequal to 11 over 3 and 25 over 3. So intuitively, it makes sense, you'regoing to invest more in the second, second opportunity, because it has a higherreturn. But as you scale up that return, as youscale up your investment, you have diminishing return, so at some point, itbecomes profitable to go to the first one, and the correct balance is in the ratio 11is to 25. And look how easily we were able to solvefor this problem by including a Lagrange multiplier, taking the gradients, and thensolving it to find what x1 and x2 is. The last piece of this module will show ushow to apply this for a particular problem, which comes up over and overagain in financial engineering, which is portfolio selection.Now, what's going on here, I've got a bunch of assets, so my x belongs to R tothe n. It has n different assets, so it's avector with n components, what does this constraint say?If I take the vector of all ones and multiply it to x, I get 1.This multiplication just gives me the sum of j going from 1 through n of xj.So, if I add up all the components of my portfolio, I have 1 dollar to invest.And what do I want to do? I want to choose a portfolio thatmaximizes my return minus a risk aversion parameter lambda times the variance.This is the return or the mean return on my portfolio, v transpose xv, gives me thevariance of my portfolio. And I want to do the portfolio x, whichsums to 1, and which maximize the, the risk adjusted return.Again, the constraints makes this problem harder, so I'm going to take theconstraints, multiply it by a Lagrange multiplier, and put it into the objective.Here's my objective, mu transpose x minus lambda times x transpose vx minus v times1 transpose x minus 1. Again, a convex problem, it has noconstraints, I'm going to take the derivative and set it equal to 0.If I take the gradient with respect to x, I get mu from here.Just to make this thing a little bit clearer, let me get rid of this.This mu is coming from the gradient of that quantity.Minus 2 lambda vx is coming from the gradient of the second quantity.V times 1 is coming from the gradient of this quantity.I set it equal to 0. Now, I solve for x.What is x? X is 1 over 2 lambda v inverse mu minusv1. What do I do?I take this minus 2 lambda vx term onto the other side so this minus becomes plus.And I take the 1 over 2 lambda, divided, take the inverse of the v, multiply itonto the other side, I get x. So now again, like in the simple examplethat we saw before, I now have x in terms of v.How do I get the v? Plug it into the constraints.1 transpose x, must equal 1. I put the equation here, I get 1 transposev inverse mu minus v1 must equal 2 lambda, v is just a scalar.I rearrange terms, I get v is equal to 1 transpose v inverse mu minus 2 lambdadivided by 1 transpose v inverse 1. I know the value of v now, I can plug it,plug that value v here, and get expressions for x.And again, this complicated portfolio selection problem has been solved by justtaking Lagrange multipliers. We will use this in the course to showhow, by using this technique, we can generate efficient frontiers, we cancharacterize what the shape of these frontiers are, we can say that any pointof this efficient frontier can be generated by a small set of mutual fundsand that, ultimately, will lead to the capital asset pricing model, which is avery important methodology for pricing assets in the market.

