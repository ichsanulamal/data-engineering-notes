{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas requests beautifulsoup4 spacy\n",
    "\n",
    "python -m spacy download xx_ent_wiki_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Kelakar Prabowo soal Harap-harap Cemas Dapat Dukungan dari LDII', 'topic_subtitle': 'Pemilu 2019', 'read_time': <div class=\"read__time\"><a href=\"https://www.kompas.com\">Kompas.com</a> - 11/10/2018, 19:09 WIB</div>, 'writers': ['\\nKristian Erdianto,\\nSabrina Asril\\n'], 'read_content': 'JAKARTA, KOMPAS.com - Calon Presiden nomor urut 02 Prabowo Subianto sempat berkelakar saat berpidato pada Rapat Kerja Nasional (Rakernas) Lembaga Dakwah Islam Indonesia (LDII) di Pondok Pesantren Minhajurrosyidin Pondok Gede, Jakarta Timur, Kamis (11/10/2018).\\n Ia menegaskan bahwa kehadirannya di rakernas bukan sebagai bentuk untuk meminta dukungan pada Pilpres 2019 mendatang. Namun, ia tak memungkiri juga berharap dukungan dari LDII.\\n\"Saya ini sudah ditetapkan sebagai calon presiden dan saya menghormati LDII, di rakernas saudara saya tidak akan datang minta dukungan. Saya tidak mau, itu hak saudara,\" ujar Prabowo.\\n\"Nah kalau di dalam hati saya berharap LDII mendukung saya, ya itu hak saya, boleh kan? Orang kan boleh berharap sambil cemas-cemas begitu,\" ucap dia yang membuat peserta rakernas dan bertepuk tangan.\\nBaca juga: Prabowo Sebut Indonesia Menjalankan Ekonomi Kebodohan\\n Dalam acara tersebut, Prabowo sempat memaparkan kritik dan pandangannya terkait beberapa persoalan di bidang ekonomi.\\n Ia juga memaparkan sejumlah data yang menunjukkan kesenjangan di masyarakat.\\n \"Ya itu bahan saudara untuk merenungkan, biar saudara ambil keputusan di hatimu, dialog dengan diri sendiri,\" tuturnya.\\n Selain itu, ia juga menegaskan bahwa dirinya tidak meminta dukungan saat mengunjungi pesantren dan ulama.\\nBaca juga: Sekjen Gerindra: Pilpres 2019 Jadi Pemilu Terberat bagi Prabowo\\nDiketahui, pekan lalu Prabowo sempat bersilaturahim dengan beberapa ulama pimpinan pondok pesantren di Jawa Tengah.\\n\"Saya ke pesantren tidak pernah minta Pak Kiai dukung saya. Minta doa, boleh,\" kata Ketua Umum Partai Gerindra itu.\\n\"Saya menyampaikan pandangan saya, saudara-saudara menilai Prabowo masuk akal atau tidak atau hanya bombastis. Sesudah itu silakan, yang terbaik untuk rakyat, yang menjadi keputusan rakyat kita harus hormati,\" tuturnya.\\n '}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Make a request to the webpage\n",
    "url = 'https://nasional.kompas.com/read/2018/10/11/19092051/kelakar-prabowo-soal-harap-harap-cemas-dapat-dukungan-dari-ldii'  # Replace with the actual URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Initialize an empty dictionary\n",
    "scraped_data = {}\n",
    "\n",
    "scraped_data['title'] = soup.find(class_='read__title').text\n",
    "scraped_data['topic_subtitle'] = soup.select_one('.topicSubtitle ul li a').text\n",
    "scraped_data['read_time'] = soup.select_one('.read__time')\n",
    "scraped_data['writers'] = [h6.text for h6 in soup.select('.credit-title-name')]\n",
    "scraped_data['read_content'] = '\\n'.join(p.text for p in soup.select('.read__content p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dictionary to a Pandas DataFrame\n",
    "df = pd.DataFrame([scraped_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('scraped_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'xx_ent_wiki_sm'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mal\\Documents\\projects\\data-f-around\\indonesia-religious-diversity-analysis\\main.ipynb Cell 8\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mal/Documents/projects/data-f-around/indonesia-religious-diversity-analysis/main.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mspacy\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mal/Documents/projects/data-f-around/indonesia-religious-diversity-analysis/main.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Load the Indonesian model for spaCy\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mal/Documents/projects/data-f-around/indonesia-religious-diversity-analysis/main.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m nlp \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mxx_ent_wiki_sm\u001b[39m\u001b[39m'\u001b[39m)  \u001b[39m# This is the small Indonesian model\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mal/Documents/projects/data-f-around/indonesia-religious-diversity-analysis/main.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Assuming 'read_content' is the variable containing the scraped content\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mal/Documents/projects/data-f-around/indonesia-religious-diversity-analysis/main.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m doc \u001b[39m=\u001b[39m nlp(read_content)\n",
      "File \u001b[1;32mc:\\Users\\mal\\anaconda3\\Lib\\site-packages\\spacy\\__init__.py:54\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\n\u001b[0;32m     31\u001b[0m     name: Union[\u001b[39mstr\u001b[39m, Path],\n\u001b[0;32m     32\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     config: Union[Dict[\u001b[39mstr\u001b[39m, Any], Config] \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mSimpleFrozenDict(),\n\u001b[0;32m     38\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Language:\n\u001b[0;32m     39\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[39m    name (str): Package name or model path.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m util\u001b[39m.\u001b[39mload_model(\n\u001b[0;32m     55\u001b[0m         name,\n\u001b[0;32m     56\u001b[0m         vocab\u001b[39m=\u001b[39mvocab,\n\u001b[0;32m     57\u001b[0m         disable\u001b[39m=\u001b[39mdisable,\n\u001b[0;32m     58\u001b[0m         enable\u001b[39m=\u001b[39menable,\n\u001b[0;32m     59\u001b[0m         exclude\u001b[39m=\u001b[39mexclude,\n\u001b[0;32m     60\u001b[0m         config\u001b[39m=\u001b[39mconfig,\n\u001b[0;32m     61\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\mal\\anaconda3\\Lib\\site-packages\\spacy\\util.py:449\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[0;32m    448\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE941\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname, full\u001b[39m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[39m# type: ignore[index]\u001b[39;00m\n\u001b[1;32m--> 449\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE050\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname))\n",
      "\u001b[1;31mOSError\u001b[0m: [E050] Can't find model 'xx_ent_wiki_sm'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the Indonesian model for spaCy\n",
    "nlp = spacy.load('xx_ent_wiki_sm')  # This is the small Indonesian model\n",
    "\n",
    "# Assuming 'read_content' is the variable containing the scraped content\n",
    "doc = nlp(read_content)\n",
    "\n",
    "# Extract entities\n",
    "entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "\n",
    "print(entities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
